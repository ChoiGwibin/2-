# -*- coding: utf-8 -*-
"""예측성능향상_수도라벨링_원본.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hQ1W_AnEL-_h42SCJ1tDtXQTPWy5J4wz
"""

# 라이브러리 및 환경 설정
!pip install pandas matplotlib seaborn Pillow tqdm torchmetrics albumentations ultralytics pycocotools PyYAML

import os
import json
import torch
import pandas as pd
import numpy as np
import cv2
import re
import yaml
import shutil
import glob
import seaborn as sns
import random
from pathlib import Path
import matplotlib.patches as patches
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import torchvision
from torchvision.ops import box_iou
from PIL import Image
from tqdm import tqdm
from collections import Counter
from zipfile import ZipFile
from torchvision import transforms as T
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from sklearn.model_selection import train_test_split
from ultralytics import YOLO
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval

# 구글 드라이브 마운트
from google.colab import drive
drive.mount('/content/drive')

# 한글 폰트 설치
!apt-get update -qq
!apt-get install fonts-nanum -qq > /dev/null
!fc-cache -fv

# 폰트 경로 설정
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'

# 폰트 매니저에 폰트 추가 및 설정
fm.fontManager.addfont(font_path)
plt.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
plt.rcParams['axes.unicode_minus'] = False

plt.figure(figsize=(6, 3))
plt.title("한글 제목 테스트")
plt.xlabel("X축 라벨")
plt.ylabel("Y축 라벨")
plt.text(0.5, 0.5, "한글 테스트 문구", fontsize=14, ha='center')
plt.show()

# 데이터 다운로드 및 압축 해제
# Kaggle 설정
if not os.path.exists(os.path.expanduser("~/.kaggle/kaggle.json")):
    from google.colab import files
    !pip install kaggle -q
    uploaded = files.upload()

    !mkdir -p ~/.kaggle
    !cp kaggle.json ~/.kaggle/
    !chmod 600 ~/.kaggle/kaggle.json
    print("kaggle.json 설정 완료")
else:
    print("이미 kaggle.json 존재")

# Kaggle 데이터 다운로드 - Colab 로컬 디렉토리(/content)
dataset_path = '/content/ai04-level1-project.zip'

if not os.path.exists(dataset_path):
    !kaggle competitions download -c ai04-level1-project -p /content
    print("데이터 다운로드 완료:", dataset_path)
else:
    print("이미 데이터셋 존재:", dataset_path)

# 압축 해제 - Colab 로컬 디렉토리(/content)
extract_dir = '/content/ai04-level1-project'

if not os.path.exists(extract_dir) or not os.listdir(extract_dir):
    with ZipFile(dataset_path, 'r') as zipf:
        zipf.extractall(extract_dir)
    print('압축 해제 완료:', extract_dir)
else:
    print('이미 압축 해제된 폴더가 존재:', extract_dir)

# 데이터 로드 및 전처리
def load_and_preprocess_data(json_dir, image_dir):
    # glob 패턴을 수정하여 모든 하위 디렉토리를 재귀적으로 검색
    json_files = glob.glob(os.path.join(json_dir, '**', '*.json'), recursive=True)
    print(f"총 {len(json_files)}개의 JSON 파일을 찾았습니다.")
    all_annotations = []

    for json_file in tqdm(json_files, desc="JSON 파일 처리 중"):
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if not data.get('images'):
            continue

        image_info = data['images'][0]
        image_id = image_info['id']
        file_name = image_info['file_name']
        image_path = os.path.join(image_dir, file_name)

        if 'annotations' in data and data['annotations']:
            for anno in data['annotations']:
                if 'bbox' in anno and anno['bbox'] and len(anno['bbox']) == 4:
                    all_annotations.append({
                        'image_id': image_id,
                        'image_path': image_path,
                        'file_name': file_name,
                        'width': image_info['width'],
                        'height': image_info['height'],
                        'dl_name': image_info['dl_name'],
                        'drug_shape': image_info.get('drug_shape'),
                        'color_class1': image_info.get('color_class1'),
                        'line_front': image_info.get('line_front'),
                        'bbox': anno['bbox'],
                        'category_id': anno['category_id'],
                        'area': anno['area']
                    })
    print(f"총 {len(all_annotations)}개의 유효한 어노테이션 데이터를 로드했습니다.")
    return pd.DataFrame(all_annotations)

# 데이터 로드 및 검증
train_json_dir = '/content/ai04-level1-project/train_annotations'
train_image_dir = '/content/ai04-level1-project/train_images'
df = load_and_preprocess_data(train_json_dir, train_image_dir)

if df.empty:
    print("\n[오류] 데이터를 불러오지 못했습니다. train_json_dir 경로를 다시 확인해주세요.")
    print(f"지정된 경로: {train_json_dir}")
else:
    print("\n--- 데이터프레임 정보 ---")
    df.info()
    print("\n--- 데이터 샘플 (상위 5개) ---")
    print(df.head())

    # 클래스 분포 확인
    class_counts = df['dl_name'].value_counts()
    print(f"\n고유한 약품(클래스)의 수: {len(class_counts)}")

# 어노테이션 누락 데이터 전처리

# 이미지별 required_count 계산 함수
def get_required_count(file_name):
    prefix_part = file_name.split('_')[0]  # "K-001900-010224-016551-031705"
    prefixes_raw = prefix_part.split('-')[1:]   # ['001900', '010224', '016551', '031705']
    return len(prefixes_raw)

# DataFrame에 required_count 컬럼 추가
df['required_count'] = df['file_name'].apply(get_required_count)

# 이미지별 실제 어노테이션 개수 집계
actual_counts = df.groupby('file_name').size().reset_index(name='actual_count')

# df와 merge
df = df.merge(actual_counts, on='file_name')

# required_count == actual_count인 경우만 필터링
df_complete = df[df['required_count'] == df['actual_count']].copy()

print(f"원본 데이터셋 크기: {len(df)}")
print(f"완전한 어노테이션을 가진 데이터셋 크기: {len(df_complete)}")

# 클래스 분포 다시 확인
print("\n--- 클래스 분포 (완전한 어노테이션만) ---")
print(df_complete['dl_name'].value_counts().head())

# 일부 샘플 확인
df_complete.head()

# dl_name을 기준으로 정렬된 클래스 이름 리스트 생성
class_names = sorted(df['dl_name'].unique())

# dl_name과 원본 category_id를 매핑
name_to_cat_id_map = df.drop_duplicates('dl_name').set_index('dl_name')['category_id'].to_dict()

# YOLO 인덱스(0, 1, 2...) -> 원본 category_id 매핑 생성
idx_to_class = {i: name for i, name in enumerate(class_names)}
yolo_idx_to_original_cat_id = {i: name_to_cat_id_map[name] for i, name in idx_to_class.items()}

print("\n--- YOLO 인덱스 -> 원본 Category ID 매핑 생성 완료 ---")
# 예시 출력 (생성된 매핑의 일부를 확인)
print({k: yolo_idx_to_original_cat_id[k] for k in list(yolo_idx_to_original_cat_id)[:5]})


# 클래스 이름과 인덱스 매핑
class_to_idx = {name: i for i, name in enumerate(class_names)}

# 데이터셋 정보를 담은 딕셔너리
dataset_info = {
    'path': '/content/pill_dataset',
    'train': 'train/images',
    'val': 'val/images',
    'names': idx_to_class
}

# YAML 파일로 저장
yaml_path = '/content/pill_dataset.yaml'
with open(yaml_path, 'w') as f:
    yaml.dump(dataset_info, f)

print(f"YAML 파일이 생성되었습니다: {yaml_path}")

# 데이터셋 분할 및 YOLO 형식으로 변환
def split_and_convert_to_yolo(df, output_dir, class_to_idx):
    if os.path.exists(output_dir):
        print(f"'{output_dir}' 디렉토리가 이미 존재하여 기존 데이터를 사용합니다.")
        return

    # Train/Validation 분할
    train_df, val_df = train_test_split(df.groupby('image_id').head(1), test_size=0.2, random_state=42)
    train_ids = set(train_df['image_id'])
    val_ids = set(val_df['image_id'])

    # 디렉토리 생성
    os.makedirs(os.path.join(output_dir, 'train', 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'train', 'labels'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'val', 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'val', 'labels'), exist_ok=True)

    # 데이터 복사 및 라벨 생성
    for _, row in tqdm(df.iterrows(), total=len(df), desc="YOLO 형식으로 변환 중"):
        image_id = row['image_id']
        subset = 'train' if image_id in train_ids else 'val'

        # 이미지 복사
        image_path = row['image_path']
        shutil.copy(image_path, os.path.join(output_dir, subset, 'images', row['file_name']))

        # 라벨 파일 생성
        label_path = os.path.join(output_dir, subset, 'labels', os.path.splitext(row['file_name'])[0] + '.txt')
        with open(label_path, 'a') as f:
            class_id = class_to_idx[row['dl_name']]
            x_center = (row['bbox'][0] + row['bbox'][2] / 2) / row['width']
            y_center = (row['bbox'][1] + row['bbox'][3] / 2) / row['height']
            width = row['bbox'][2] / row['width']
            height = row['bbox'][3] / row['height']
            f.write(f"{class_id} {x_center} {y_center} {width} {height}\n")

# 실행
yolo_dataset_dir = '/content/pill_dataset'
split_and_convert_to_yolo(df_complete, yolo_dataset_dir, class_to_idx)

# 모델 로드
model = YOLO('yolov8s.pt')

# 학습
model.train(
    data=yaml_path,
    epochs=50,
    patience=10,
    batch=16,
    imgsz=640,
    project='pill_detection',
    name='yolov8s_pill_detection'
)

# --- 1. 학습 완료 후 모델 저장 경로 ---
# YOLOv8은 기본적으로 project/name/weights/best.pt에 저장
project_name = 'pill_detection'
run_name = 'yolov8s_pill_detection'
best_pt_path = f'./{project_name}/{run_name}/weights/best.pt'

# --- 2. Google Drive 저장 경로 ---
drive_model_dir = f'./drive/MyDrive/Project/model/{run_name}'
Path(drive_model_dir).mkdir(parents=True, exist_ok=True)  # 폴더 생성

# --- 3. 복사 실행 ---
if os.path.exists(best_pt_path):
    destination_path = os.path.join(drive_model_dir, 'best.pt')
    shutil.copy2(best_pt_path, destination_path)
    print(f"모델 복사 완료(드라이브)!")
    print(f" 소스: {best_pt_path}")
    print(f" 목적지: {destination_path}")
else:
    print(f"best.pt 파일을 찾을 수 없습니다: {best_pt_path}")

# 저장된 모델 불러오기
# --- 1. 학습 완료 후 모델 저장 경로 ---
# YOLOv8은 기본적으로 project/name/weights/best.pt에 저장
project_name = 'pill_detection'
run_name = 'yolov8m_pill_detection'
drive_model_path = f'/content/drive/MyDrive/Project/model/{run_name}/best.pt'

# --- 2. 모델 불러올 경로 ---
best_pt_dir = f'./{project_name}/{run_name}/weights/'
Path(best_pt_dir).mkdir(parents=True, exist_ok=True)  # 폴더 생성

# --- 3. 복사 실행 ---
if os.path.exists(drive_model_path):
    destination_path = os.path.join(best_pt_dir, 'best.pt')
    shutil.copy2(drive_model_path, destination_path)
    print(f"모델 복사 완료(드라이브)!")
    print(f" 소스: {drive_model_path}")
    print(f" 목적지: {destination_path}")
else:
    print(f"best.pt 파일을 찾을 수 없습니다: {drive_model_path}")

# ===============================
# 모델 예측 및 결과 저장
# ===============================

# -------------------------------
# 1. 모델 로드
# -------------------------------
# Assuming the best.pt path for the second training is available
model_path = '/content/pill_detection/yolov8s_pill_detection/weights/best.pt'
model = YOLO(model_path)

# -------------------------------
# 2. 테스트 이미지 경로
# -------------------------------
test_image_dir = '/content/ai04-level1-project/test_images'
test_image_paths = sorted(glob.glob(os.path.join(test_image_dir, '*.png')))

# 랜덤 5개 이미지 ID 선택 (시각화용)
all_image_ids = [int(os.path.splitext(os.path.basename(p))[0]) for p in test_image_paths]
visualize_sample_ids = set(random.sample(all_image_ids, min(5, len(all_image_ids))))
print(f"전체 테스트 이미지: {len(test_image_paths)}장")
print(f"시각화 대상 (랜덤 5개): {sorted(visualize_sample_ids)}")

# -------------------------------
# 3. 예측 결과 저장 리스트
# -------------------------------
predictions = []
annotation_id_counter = 1

# -------------------------------
# 4. 시각화 결과 저장 폴더
# -------------------------------
vis_output_dir = '/content/drive/MyDrive/Project/vis_results/yolov8s_result'
os.makedirs(vis_output_dir, exist_ok=True)

# -------------------------------
# 5. 후처리 함수 정의
# -------------------------------
import torch
from torchvision.ops import box_iou

def apply_postprocessing(boxes, iou_thr=0.5):
    """
    같은 객체에서 여러 클래스가 예측되었을 경우
    confidence가 높은 박스만 남기도록 후처리
    (Simple approach - not a full NMS)
    """
    filtered_boxes = []
    # Sort boxes by confidence in descending order
    sorted_boxes = sorted(boxes, key=lambda x: x.conf[0].item(), reverse=True)

    for box in sorted_boxes:
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        score = box.conf[0].item()
        cls = int(box.cls[0])

        keep = True
        current_box_tensor = torch.tensor([[x1, y1, x2, y2]]) # Explicitly create a [1, 4] tensor

        for fb in filtered_boxes:
             # Calculate IoU between current box and one filtered box
             # Ensure fb["xyxy"] is a list or tensor compatible with torch.tensor
             fb_tensor = torch.tensor([fb["xyxy"]]) # Ensure [1, 4] tensor for filtered box
             iou_val = box_iou(current_box_tensor, fb_tensor)[0][0].item()

             if iou_val > iou_thr:
                 # If current box overlaps significantly with an already kept box
                 # And the existing box has higher or equal confidence, skip the current box
                 if score <= fb["score"]: # Keep the one with higher confidence or the first one encountered
                     keep = False
                     break # Stop checking against other filtered boxes


        if keep:
            filtered_boxes.append({"xyxy": [x1, y1, x2, y2], "score": score, "cls": cls}) # Store xyxy as a list

    return filtered_boxes # Return list of dictionaries


# -------------------------------
# 6. 중복 제거 후 매핑 사전 생성
# -------------------------------
if 'df_complete' not in locals():
    print("Error: df_complete not found. Please run previous cells.")
else:
    category_id_to_name = df_complete.drop_duplicates('category_id').set_index('category_id')['dl_name'].to_dict()

    # Ensure yolo_idx_to_original_cat_id is available from previous cells
    if 'yolo_idx_to_original_cat_id' not in globals() and 'yolo_idx_to_original_cat_id' not in locals():
         print("Error: yolo_idx_to_original_cat_id mapping not found. Please run previous cells.")
         # Exit or handle the error appropriately, e.g., by skipping prediction
         test_image_paths = [] # Prevent prediction loop from running


    # 예시 출력 (매핑 확인)
    print("생성된 category_id → dl_name 매핑:")
    # Check if yolo_idx_to_original_cat_id exists before printing
    if 'yolo_idx_to_original_cat_id' in globals() or 'yolo_idx_to_original_cat_id' in locals():
        for cat_id, name in list(yolo_idx_to_original_cat_id.items())[:5]: # Print from yolo_idx mapping
            original_cat_id = yolo_idx_to_original_cat_id.get(cat_id, -1)
            pill_name = category_id_to_name.get(original_cat_id, f"Unknown({original_cat_id})")
            print(f"  YOLO Index {cat_id} → Original Category ID {original_cat_id} → {pill_name}")
    else:
         print("  Mapping not available.")


    # -------------------------------
    # 7. 전체 이미지에 대해 예측 수행
    # -------------------------------
    for img_path in tqdm(test_image_paths, desc="전체 이미지 예측 중"):
        image_id = int(os.path.splitext(os.path.basename(img_path))[0])

        # Model prediction (initial filtering with confidence)
        # Pass a higher confidence threshold to reduce the number of initial boxes
        # before custom post-processing, if desired.
        # Let's keep the conf/iou from the previous successful run for consistency.
        results = model.predict(img_path, conf=0.3, verbose=False)

        # OpenCV로 원본 이미지 불러오기
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # img_height, img_width = img.shape[:2] # Not directly used in this block

        # ---------------------------
        # 후처리 적용
        # ---------------------------
        filtered_boxes = []
        if len(results) > 0 and results[0] is not None and results[0].boxes is not None:
            boxes = results[0].boxes
            filtered_boxes = apply_postprocessing(boxes, iou_thr=0.5) # Apply post-processing


        # ---------------------------
        # 예측 결과 저장
        # ---------------------------
        for fb in filtered_boxes:
            x1, y1, x2, y2 = fb["xyxy"] # xyxy is stored as a list
            bbox_x = x1
            bbox_y = y1
            bbox_w = x2 - x1
            bbox_h = y2 - y1

            predicted_yolo_idx = fb["cls"]
            # Ensure yolo_idx_to_original_cat_id is available globally or locally
            if 'yolo_idx_to_original_cat_id' not in globals() and 'yolo_idx_to_original_cat_id' not in locals():
                print("Error: yolo_idx_to_original_cat_id not found during prediction saving.")
                continue

            original_category_id = yolo_idx_to_original_cat_id.get(predicted_yolo_idx, -1)
            if original_category_id == -1:
                # print(f"Warning: Unknown YOLO index {predicted_yolo_idx} for image {image_id}. Skipping saving.")
                continue

            # pill_name = category_id_to_name.get(original_category_id, f"Unknown({original_category_id})") # Not needed for saving
            score = fb["score"]

            predictions.append([
                annotation_id_counter,
                image_id,
                original_category_id,
                bbox_x,
                bbox_y,
                bbox_w,
                bbox_h,
                score
            ])
            annotation_id_counter += 1

        # ---------------------------
        # 랜덤 5개 이미지에 대해 비교 시각화
        # ---------------------------
        if image_id in visualize_sample_ids:
            fig, axes = plt.subplots(1, 2, figsize=(16, 8))
            fig.suptitle(f'Image ID: {image_id}', fontsize=16)

            # 좌측: 모델 예측 결과 (후처리 적용 후)
            axes[0].imshow(img)
            axes[0].set_title('Model Prediction (Post-processed)')
            axes[0].axis('off')

            for fb in filtered_boxes:
                x1, y1, x2, y2 = fb["xyxy"]
                score = fb["score"]
                predicted_yolo_idx = fb["cls"]
                original_category_id = yolo_idx_to_original_cat_id.get(predicted_yolo_idx, -1)
                pill_name = category_id_to_name.get(original_category_id, f"Unknown({original_category_id})")

                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,
                                     edgecolor='lime', facecolor='none')
                axes[0].add_patch(rect)
                axes[0].text(x1, y1-5, f"{pill_name} {score:.2f}",
                             fontsize=10, color='black', fontweight='bold',
                             bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.8))

            # 우측: CSV 저장된 결과만 표시 (Should match the left side after this cell runs)
            axes[1].imshow(img.copy()) # Use a copy to avoid drawing on the same image object
            axes[1].set_title('From CSV Data (Re-visualized)')
            axes[1].axis('off')

            for fb in filtered_boxes:
                x1, y1, x2, y2 = fb["xyxy"]
                score = fb["score"]
                predicted_yolo_idx = fb["cls"]
                original_category_id = yolo_idx_to_original_cat_id.get(predicted_yolo_idx, -1)
                pill_name = category_id_to_name.get(original_category_id, f"Unknown({original_category_id})")

                rect_csv = plt.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,
                                         edgecolor='red', facecolor='none')
                axes[1].add_patch(rect_csv)
                axes[1].text(x1, y1-5, f"{pill_name} {score:.2f}",
                             fontsize=10, color='white', fontweight='bold',
                             bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.8))


            # 저장
            subplot_save_path = os.path.join(vis_output_dir, f"{image_id}_comparison.png")
            plt.savefig(subplot_save_path, dpi=100, bbox_inches='tight')
            plt.close(fig) # Close figure to free memory

    print(f"\n전체 예측 완료 | 시각화 저장 완료 (랜덤 5개 이미지): {vis_output_dir}")

    # -------------------------------
    # 8. CSV 파일 저장
    # -------------------------------
    submission_df = pd.DataFrame(
        predictions,
        columns=['annotation_id', 'image_id', 'category_id', 'bbox_x', 'bbox_y', 'bbox_w', 'bbox_h', 'score']
    )

    file_name = 'pred_yolov8s'
    submission_path = f'./drive/MyDrive/Project/csv/{file_name}.csv'
    Path('./drive/MyDrive/Project/csv').mkdir(parents=True, exist_ok=True)
    submission_df.to_csv(submission_path, index=False)

    print(f"\n제출 파일 생성 완료 (전체 예측): {submission_path}")
    print(submission_df.head())

    # 저장된 CSV 불러와서 확인
    df_check = pd.read_csv(submission_path)
    print("\n 불러온 CSV 데이터 확인:")
    display(df_check.head())
    print("총 예측 개수:", len(df_check))

# 시각화
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# 이미지 경로 설정
vis_output_dir = '/content/drive/MyDrive/Project/vis_results/yolov8s_result'

# PNG 이미지 파일 목록 가져오기 (정렬)
image_files = sorted([f for f in os.listdir(vis_output_dir) if f.endswith('.png')])

# 최대 4개만 선택
selected_images = image_files[:4]

# 서브플롯 설정
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Vis Results - Sample Images (4)', fontsize=16)

# 이미지 출력
for i, img_file in enumerate(selected_images):
    img_path = os.path.join(vis_output_dir, img_file)
    img = mpimg.imread(img_path)

    ax = axes[i//2, i%2]
    ax.imshow(img)
    ax.set_title(img_file, fontsize=10)
    ax.axis('off')

plt.tight_layout()
plt.show()

# 선택된 이미지 파일명 출력 (참고용)
print("\n표시된 이미지 파일:")
for f in selected_images:
    print(f"  - {f}")

# ==============================
# 수도라벨링 + 최종 데이터셋 생성
# ==============================

# 1. 경로 설정
MODEL_PATH = '/content/pill_detection/yolov8s_pill_detection/weights/best.pt'
IMAGE_DIR = '/content/ai04-level1-project/train_images'
OUTPUT_DIR = '/content/pseudo_dataset'
FINAL_DATASET = '/content/final_dataset'

# 폴더 생성
Path(f"{OUTPUT_DIR}/images").mkdir(parents=True, exist_ok=True)
Path(f"{OUTPUT_DIR}/labels").mkdir(parents=True, exist_ok=True)
for split in ['train', 'val']:
    Path(f"{FINAL_DATASET}/images/{split}").mkdir(parents=True, exist_ok=True)
    Path(f"{FINAL_DATASET}/labels/{split}").mkdir(parents=True, exist_ok=True)

print("폴더 구조 생성 완료")

# 2. 모델 로드
model = YOLO(MODEL_PATH)
print(f"모델 로드 완료: {MODEL_PATH}")

# 3. df_complete 기반 완전한 이미지 목록
if 'df_complete' not in locals():
    raise Exception("df_complete를 찾을 수 없습니다. 이전 전처리 코드를 실행해주세요.")

complete_file_names = set(df_complete['file_name'].unique())
print(f"완전한 어노테이션 이미지 수: {len(complete_file_names)}")

# 4. 수도라벨링 대상 이미지
all_image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith(('.png', '.jpg', '.jpeg'))]
test_image_names = [f for f in all_image_files if f not in complete_file_names]
print(f"수도라벨링 대상 이미지 수: {len(test_image_names)}")

# 5. 클래스 매핑 생성
sorted_categories = df_complete[['category_id', 'dl_name']].drop_duplicates().sort_values('category_id')
class_names = sorted_categories['dl_name'].tolist()
original_cat_ids_sorted = sorted_categories['category_id'].tolist()

yolo_idx_to_original_cat_id = {i: original_cat_ids_sorted[i] for i in range(len(class_names))}
original_cat_id_to_yolo_idx = {v: k for k, v in yolo_idx_to_original_cat_id.items()}

# 클래스 이름 → YOLO 인덱스 매핑 (대소문자/공백 무시)
name_to_class_id = {}
for idx, name in enumerate(class_names):
    clean_name = name.strip().lower()
    name_to_class_id[clean_name] = idx
    name_to_class_id[name] = idx

print(f"클래스 이름 로드 완료: {len(class_names)}개")
print("상위 5개 클래스:")
for i, name in enumerate(class_names[:5]):
    print(f"  {i}: {name}")

# classes.txt 저장
classes_txt_path = '/content/classes.txt'
with open(classes_txt_path, 'w', encoding='utf-8') as f:
    for name in class_names:
        f.write(name + '\n')
print(f"classes.txt 저장 완료: {classes_txt_path}")

# 6. 수도라벨링 수행
generated_count = 0
passed_validation_count = 0
failed_validation_count = 0

for img_name in tqdm(test_image_names, desc="수도라벨링 중"):
    img_path = os.path.join(IMAGE_DIR, img_name)
    if not os.path.exists(img_path):
        continue

    img = cv2.imread(img_path)
    if img is None:
        continue

    h, w = img.shape[:2]

    prefix_part = img_name.split('_')[0]
    prefixes_raw = prefix_part.split('-')[1:]
    required_label_count = len(prefixes_raw)

    results = model.predict(img_path, conf=0.3, verbose=False)

    label_name = os.path.splitext(img_name)[0] + ".txt"
    label_path = os.path.join(OUTPUT_DIR, 'labels', label_name)

    detection_count = 0
    detected_labels = []

    for result in results:
        boxes = result.boxes
        for box in boxes:
            predicted_yolo_idx = int(box.cls[0])
            conf = float(box.conf[0])
            x_center, y_center, width, height = box.xywhn[0].tolist()

            # score 0.7 이상만 처리
            if conf < 0.7:
              continue

            original_cat_id = yolo_idx_to_original_cat_id.get(predicted_yolo_idx, -1)
            if original_cat_id == -1:
                continue

            detected_labels.append((original_cat_id, x_center, y_center, width, height))
            detection_count += 1

    if detection_count == required_label_count and required_label_count > 0:
        with open(label_path, 'w', encoding='utf-8') as f:
            for original_cat_id, x_center, y_center, width, height in detected_labels:
                yolo_idx = original_cat_id_to_yolo_idx.get(original_cat_id, -1)
                if yolo_idx != -1:
                    f.write(f"{yolo_idx} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")

        img_dst_path = os.path.join(OUTPUT_DIR, 'images', img_name)
        shutil.copy2(img_path, img_dst_path)

        generated_count += 1
        passed_validation_count += 1
    else:
        failed_validation_count += 1

print(f"\n수도라벨링 완료!")
print(f"  검증 통과: {passed_validation_count}")
print(f"  검증 실패: {failed_validation_count}")
print(f"  저장 위치: {OUTPUT_DIR}")

# 7. COCO 형식 JSON 처리 함수
def convert_and_copy_annotations(file_names, split, original_cat_id_to_yolo_idx):
    copied_count = 0
    image_dir = '/content/ai04-level1-project/train_images'
    annotation_base_dir = '/content/ai04-level1-project/train_annotations'

    for fname in tqdm(file_names, desc=f"완전한 데이터 ({split}) 처리 중"):
        # 이미지 복사
        img_src = os.path.join(image_dir, fname)
        img_dst = os.path.join(FINAL_DATASET, 'images', split, fname)
        if not os.path.exists(img_src):
            continue
        shutil.copy2(img_src, img_dst)

        # JSON 경로 구성
        prefix_part = fname.split('_')[0]  # "K-001900-010224-016551-031705"
        annotation_folder_name = prefix_part + "_json"
        annotation_folder_path_base = os.path.join(annotation_base_dir, annotation_folder_name)

        if not os.path.exists(annotation_folder_path_base):
            continue

        # 접두사 목록
        prefixes_raw = prefix_part.split('-')[1:]  # ['001900', '010224', ...]

        # 라벨 파일 경로
        label_name = os.path.splitext(fname)[0] + ".txt"
        label_path = os.path.join(FINAL_DATASET, 'labels', split, label_name)

        # 이미지 크기
        img = cv2.imread(img_src)
        if img is None:
            continue
        img_h, img_w = img.shape[:2]

        annotations = []
        json_processed = False

        for prefix_raw in prefixes_raw:
            subfolder_name = f"K-{prefix_raw}"
            subfolder_path = os.path.join(annotation_folder_path_base, subfolder_name)
            if not os.path.exists(subfolder_path):
                continue

            # JSON 파일명: 이미지명과 동일 (확장자만 .json)
            json_filename = fname.replace('.png', '.json')  # 확장자 변경
            json_path = os.path.join(subfolder_path, json_filename)

            if not os.path.exists(json_path):
                continue

            json_processed = True

            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                    # COCO 형식 확인
                    if 'annotations' not in data or 'images' not in data or 'categories' not in data:
                        print(f"COCO 형식 아님: {json_path}")
                        continue

                    # 카테고리 매핑 생성 (이 JSON 파일 내)
                    category_map = {}
                    for cat in data['categories']:
                        category_map[cat['id']] = cat['name']

                    # 어노테이션 처리
                    for ann in data['annotations']:
                        cat_id = ann['category_id']
                        class_name = category_map.get(cat_id, "")

                        if not class_name:
                            continue

                        # 클래스 이름 → YOLO 인덱스
                        yolo_idx = -1
                        for clean_key in name_to_class_id:
                            if isinstance(clean_key, str) and clean_key.lower() == class_name.strip().lower():
                                yolo_idx = name_to_class_id[clean_key]
                                break

                        if yolo_idx == -1:
                            print(f"클래스 매칭 실패: '{class_name}' in {json_path}")
                            continue

                        # bbox: [x, y, width, height]
                        if len(ann['bbox']) != 4:
                            continue

                        x, y, w_bbox, h_bbox = ann['bbox']

                        # YOLO 정규화
                        x_center = x + w_bbox / 2
                        y_center = y + h_bbox / 2

                        x_center_norm = x_center / img_w
                        y_center_norm = y_center / img_h
                        w_norm = w_bbox / img_w
                        h_norm = h_bbox / img_h

                        # 범위 검사
                        if not (0 <= x_center_norm <= 1 and 0 <= y_center_norm <= 1 and
                                0 <= w_norm <= 1 and 0 <= h_norm <= 1):
                            continue

                        annotations.append((yolo_idx, x_center_norm, y_center_norm, w_norm, h_norm))

            except Exception as e:
                print(f"JSON 파싱 오류 {json_path}: {e}")
                continue

        if not json_processed:
            print(f"{fname}: 해당하는 JSON 파일을 찾을 수 없음")
            continue

        if len(annotations) == 0:
            print(f"{fname}: 유효한 어노테이션이 없음 → 라벨 파일 생성 생략")
            continue

        # 라벨 파일 저장
        with open(label_path, 'w', encoding='utf-8') as f:
            for cls_id, x_center, y_center, width, height in annotations:
                f.write(f"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")

        copied_count += 1

    return copied_count

# ==============================
# 8. 완전한 데이터 처리
# ==============================
print("\n완전한 데이터 처리 시작...")

unique_complete_files = df_complete['file_name'].drop_duplicates().tolist()
train_files, val_files = train_test_split(
    unique_complete_files,
    test_size=0.2,
    random_state=42,
    shuffle=True
)

print(f"분할 완료: Train {len(train_files)}, Val {len(val_files)}")

train_copied = convert_and_copy_annotations(train_files, 'train', original_cat_id_to_yolo_idx)
val_copied = convert_and_copy_annotations(val_files, 'val', original_cat_id_to_yolo_idx)

print(f"완전한 데이터 처리 완료: Train {train_copied}, Val {val_copied}")

# 9. 수도라벨 데이터 병합
PSEUDO_DATASET = OUTPUT_DIR
pseudo_img_dir = f"{PSEUDO_DATASET}/images"
pseudo_lbl_dir = f"{PSEUDO_DATASET}/labels"
final_train_img_dir = f"{FINAL_DATASET}/images/train"
final_train_lbl_dir = f"{FINAL_DATASET}/labels/train"

pseudo_copied_count = 0
if os.path.exists(pseudo_img_dir):
    for fname in tqdm(os.listdir(pseudo_img_dir), desc="수도라벨 병합 중"):
        if fname.endswith(('.png', '.jpg', '.jpeg')):
            label_name = os.path.splitext(fname)[0] + ".txt"
            src_label_path = os.path.join(pseudo_lbl_dir, label_name)

            if os.path.exists(src_label_path) and os.path.getsize(src_label_path) > 0:
                shutil.copy2(os.path.join(pseudo_img_dir, fname), os.path.join(final_train_img_dir, fname))
                shutil.copy2(src_label_path, os.path.join(final_train_lbl_dir, label_name))
                pseudo_copied_count += 1

print(f"수도라벨 병합 완료: {pseudo_copied_count}개")

# 10. 최종 통계 출력
def count_files(dir_path, extension):
    if not os.path.exists(dir_path):
        return 0
    return len([f for f in os.listdir(dir_path) if f.endswith(extension)])

print("\n=== 최종 데이터셋 통계 ===")

train_images_orig = len(train_files)
train_labels_orig = train_copied
val_images_orig = len(val_files)
val_labels_orig = val_copied

pseudo_images = pseudo_copied_count
pseudo_labels = pseudo_copied_count

train_images_final = count_files(f"{FINAL_DATASET}/images/train", '.png')
train_labels_final = count_files(f"{FINAL_DATASET}/labels/train", '.txt')
val_images_final = count_files(f"{FINAL_DATASET}/images/val", '.png')
val_labels_final = count_files(f"{FINAL_DATASET}/labels/val", '.txt')

print(f"\n[1] 완전한 데이터")
print(f"  Train: {train_images_orig}장 (이미지) / {train_labels_orig}개 (라벨)")
print(f"  Val: {val_images_orig}장 (이미지) / {val_labels_orig}개 (라벨)")

print(f"\n[2] 수도라벨 데이터")
print(f"  Train에 병합: {pseudo_images}장 / {pseudo_labels}개")

print(f"\n[3] 최종 병합 데이터")
print(f"  Train: {train_images_final}장 / {train_labels_final}개")
print(f"  Val: {val_images_final}장 / {val_labels_final}개")

print("\n" + "="*60)
print("최종 요약")
print("="*60)
print(f"{'구분':<20} {'Train 이미지':<12} {'Train 라벨':<12} {'Val 이미지':<12} {'Val 라벨':<12}")
print("-"*60)
print(f"{'완전한 데이터':<20} {train_images_orig:<12} {train_labels_orig:<12} {val_images_orig:<12} {val_labels_orig:<12}")
print(f"{'수도라벨 데이터':<20} {pseudo_images:<12} {pseudo_labels:<12} {'-':<12} {'-':<12}")
print(f"{'최종 병합 데이터':<20} {train_images_final:<12} {train_labels_final:<12} {val_images_final:<12} {val_labels_final:<12}")
print("="*60)

print(f"\n모든 작업 완료! 최종 데이터셋: {FINAL_DATASET}")

# 수도라벨 데이터 중 상위 10개를 시각화해서 품질 확인
import random
from PIL import Image, ImageDraw, ImageFont

pseudo_img_dir = '/content/final_dataset/images/train'
pseudo_lbl_dir = '/content/final_dataset/labels/train'

# classes.txt 불러오기 (YOLO 인덱스 → 알약명 매핑)
classes_txt_path = '/content/classes.txt'
with open(classes_txt_path, 'r', encoding='utf-8') as f:
    idx_to_name = [line.strip() for line in f.readlines()]

# 수도라벨 중 일부 선택
sample_images = random.sample([
    f for f in os.listdir(pseudo_img_dir)
    if os.path.exists(os.path.join(pseudo_lbl_dir, f.replace('.png', '.txt')))
], min(10, len(os.listdir(pseudo_img_dir))))

for img_name in sample_images:
    img_path = os.path.join(pseudo_img_dir, img_name)
    lbl_path = os.path.join(pseudo_lbl_dir, img_name.replace('.png', '.txt'))

    img = Image.open(img_path)
    draw = ImageDraw.Draw(img)

    with open(lbl_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            cls_id = int(parts[0])
            x_center, y_center, w, h = map(float, parts[1:5])

            # YOLO → 픽셀 좌표 변환
            W, H = img.size
            x1 = (x_center - w/2) * W
            y1 = (y_center - h/2) * H
            x2 = (x_center + w/2) * W
            y2 = (y_center + h/2) * H

            # 클래스명 가져오기
            class_name = idx_to_name[cls_id] if cls_id < len(idx_to_name) else f"Unknown({cls_id})"

            # 박스 + 라벨 그리기
            draw.rectangle([x1, y1, x2, y2], outline="red", width=3)
            draw.text((x1, y1-20), class_name, fill="red")

    display(img)
    print(f"라벨 파일: {lbl_path}")

# ==============================
# final_dataset 기반 YOLO YAML 생성
# ==============================

import os
import yaml
from pathlib import Path

# --- 1. 기존 df_complete 기반 클래스 이름 유지 ---
# (수도라벨도 동일한 클래스 이름 사용)
if 'df_complete' not in locals():
    raise Exception("df_complete가 없습니다. 이전 전처리 코드를 먼저 실행해주세요.")

# dl_name 기준 정렬된 클래스 이름 리스트
class_names = sorted(df['dl_name'].unique())

# dl_name → 원본 category_id 매핑 (기존과 동일하게 유지)
name_to_cat_id_map = df.drop_duplicates('dl_name').set_index('dl_name')['category_id'].to_dict()

# YOLO 인덱스 → 원본 category_id 매핑 (기존과 동일)
idx_to_class = {i: name for i, name in enumerate(class_names)}
yolo_idx_to_original_cat_id = {i: name_to_cat_id_map[name] for i, name in idx_to_class.items()}

print("\n--- YOLO 인덱스 → 원본 Category ID 매핑 ---")
print({k: yolo_idx_to_original_cat_id[k] for k in list(yolo_idx_to_original_cat_id)[:5]})

# --- 2. final_dataset 경로 설정 ---
FINAL_DATASET_PATH = '/content/final_dataset'

# YOLO 학습용 데이터셋 경로 구조
dataset_info = {
    'path': FINAL_DATASET_PATH,
    'train': 'images/train',
    'val': 'images/val',
    'names': idx_to_class
}

print("\n--- 생성할 dataset.yaml 내용 ---")
print(f"path: {dataset_info['path']}")
print(f"train: {dataset_info['train']}")
print(f"val: {dataset_info['val']}")
print("names:")
for i, name in idx_to_class.items():
    print(f"  {i}: {name}")

# --- 3. YAML 파일 저장 ---
yaml_path = '/content/pill_dataset_final.yaml'
Path(yaml_path).parent.mkdir(parents=True, exist_ok=True)

with open(yaml_path, 'w', encoding='utf-8') as f:
    yaml.dump(dataset_info, f, allow_unicode=True, default_flow_style=False)

print(f"\n YAML 파일 생성 완료: {yaml_path}")

# --- 4. (옵션) final_dataset 통계 확인 ---
def count_files(dir_path, extension):
    if not os.path.exists(dir_path):
        return 0
    return len([f for f in os.listdir(dir_path) if f.endswith(extension)])

train_images = count_files(f"{FINAL_DATASET_PATH}/images/train", '.png')
train_labels = count_files(f"{FINAL_DATASET_PATH}/labels/train", '.txt')
val_images = count_files(f"{FINAL_DATASET_PATH}/images/val", '.png')
val_labels = count_files(f"{FINAL_DATASET_PATH}/labels/val", '.txt')

print(f"\n final_dataset 통계")
print(f"Train: {train_images}장 이미지, {train_labels}개 라벨")
print(f"Val: {val_images}장 이미지, {val_labels}개 라벨")

yaml_path

# 모델 로드
model = YOLO('yolov8s.pt')

# 학습
model.train(
    data=yaml_path,
    epochs=50,
    patience=10,
    batch=16,
    imgsz=640,
    project='pill_detection',
    name='yolov8s_pill_detection_pseudo'
)

# --- 1. 학습 완료 후 모델 저장 경로 ---
# YOLOv8은 기본적으로 project/name/weights/best.pt에 저장
project_name = 'pill_detection'
run_name = 'yolov8n_pill_detection_pseudo'
best_pt_path = f'./{project_name}/{run_name}/weights/best.pt'

# --- 2. Google Drive 저장 경로 ---
drive_model_dir = f'./drive/MyDrive/Project/model/{run_name}'
Path(drive_model_dir).mkdir(parents=True, exist_ok=True)  # 폴더 생성

# --- 3. 복사 실행 ---
if os.path.exists(best_pt_path):
    destination_path = os.path.join(drive_model_dir, 'best.pt')
    shutil.copy2(best_pt_path, destination_path)
    print(f"모델 복사 완료(드라이브)!")
    print(f" 소스: {best_pt_path}")
    print(f" 목적지: {destination_path}")
else:
    print(f"best.pt 파일을 찾을 수 없습니다: {best_pt_path}")

# ===============================
# 모델 예측 및 결과 저장
# ===============================

# -------------------------------
# 1. 모델 로드
# -------------------------------
# Assuming the best.pt path for the second training is available
model_path = '/content/pill_detection/yolov8s_pill_detection_pseudo/weights/best.pt'
model = YOLO(model_path)

# -------------------------------
# 2. 테스트 이미지 경로
# -------------------------------
test_image_dir = '/content/ai04-level1-project/test_images'
test_image_paths = sorted(glob.glob(os.path.join(test_image_dir, '*.png')))

# 랜덤 5개 이미지 ID 선택 (시각화용)
all_image_ids = [int(os.path.splitext(os.path.basename(p))[0]) for p in test_image_paths]
visualize_sample_ids = set(random.sample(all_image_ids, min(5, len(all_image_ids))))
print(f"전체 테스트 이미지: {len(test_image_paths)}장")
print(f"시각화 대상 (랜덤 5개): {sorted(visualize_sample_ids)}")

# -------------------------------
# 3. 예측 결과 저장 리스트
# -------------------------------
predictions = []
annotation_id_counter = 1

# -------------------------------
# 4. 시각화 결과 저장 폴더
# -------------------------------
vis_output_dir = '/content/drive/MyDrive/Project/vis_results/yolo_pseudo_result'
os.makedirs(vis_output_dir, exist_ok=True)

# -------------------------------
# 5. 후처리 함수 정의
# -------------------------------
import torch
from torchvision.ops import box_iou

def apply_postprocessing(boxes, iou_thr=0.5):
    """
    같은 객체에서 여러 클래스가 예측되었을 경우
    confidence가 높은 박스만 남기도록 후처리
    (Simple approach - not a full NMS)
    """
    filtered_boxes = []
    # Sort boxes by confidence in descending order
    sorted_boxes = sorted(boxes, key=lambda x: x.conf[0].item(), reverse=True)

    for box in sorted_boxes:
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        score = box.conf[0].item()
        cls = int(box.cls[0])

        keep = True
        current_box_tensor = torch.tensor([[x1, y1, x2, y2]]) # Explicitly create a [1, 4] tensor

        for fb in filtered_boxes:
             # Calculate IoU between current box and one filtered box
             # Ensure fb["xyxy"] is a list or tensor compatible with torch.tensor
             fb_tensor = torch.tensor([fb["xyxy"]]) # Ensure [1, 4] tensor for filtered box
             iou_val = box_iou(current_box_tensor, fb_tensor)[0][0].item()

             if iou_val > iou_thr:
                 # If current box overlaps significantly with an already kept box
                 # And the existing box has higher or equal confidence, skip the current box
                 if score <= fb["score"]: # Keep the one with higher confidence or the first one encountered
                     keep = False
                     break # Stop checking against other filtered boxes


        if keep:
            filtered_boxes.append({"xyxy": [x1, y1, x2, y2], "score": score, "cls": cls}) # Store xyxy as a list

    return filtered_boxes # Return list of dictionaries


# -------------------------------
# 6. 중복 제거 후 매핑 사전 생성
# -------------------------------
if 'df_complete' not in locals():
    print("Error: df_complete not found. Please run previous cells.")
else:
    category_id_to_name = df_complete.drop_duplicates('category_id').set_index('category_id')['dl_name'].to_dict()

    # Ensure yolo_idx_to_original_cat_id is available from previous cells
    if 'yolo_idx_to_original_cat_id' not in globals() and 'yolo_idx_to_original_cat_id' not in locals():
         print("Error: yolo_idx_to_original_cat_id mapping not found. Please run previous cells.")
         # Exit or handle the error appropriately, e.g., by skipping prediction
         test_image_paths = [] # Prevent prediction loop from running


    # 예시 출력 (매핑 확인)
    print("생성된 category_id → dl_name 매핑:")
    # Check if yolo_idx_to_original_cat_id exists before printing
    if 'yolo_idx_to_original_cat_id' in globals() or 'yolo_idx_to_original_cat_id' in locals():
        for cat_id, name in list(yolo_idx_to_original_cat_id.items())[:5]: # Print from yolo_idx mapping
            original_cat_id = yolo_idx_to_original_cat_id.get(cat_id, -1)
            pill_name = category_id_to_name.get(original_cat_id, f"Unknown({original_cat_id})")
            print(f"  YOLO Index {cat_id} → Original Category ID {original_cat_id} → {pill_name}")
    else:
         print("  Mapping not available.")


    # -------------------------------
    # 7. 전체 이미지에 대해 예측 수행
    # -------------------------------
    for img_path in tqdm(test_image_paths, desc="전체 이미지 예측 중"):
        image_id = int(os.path.splitext(os.path.basename(img_path))[0])

        # Model prediction (initial filtering with confidence)
        # Pass a higher confidence threshold to reduce the number of initial boxes
        # before custom post-processing, if desired.
        # Let's keep the conf/iou from the previous successful run for consistency.
        results = model.predict(img_path, conf=0.3, verbose=False)

        # OpenCV로 원본 이미지 불러오기
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # img_height, img_width = img.shape[:2] # Not directly used in this block

        # ---------------------------
        # 후처리 적용
        # ---------------------------
        filtered_boxes = []
        if len(results) > 0 and results[0] is not None and results[0].boxes is not None:
            boxes = results[0].boxes
            filtered_boxes = apply_postprocessing(boxes, iou_thr=0.5) # Apply post-processing


        # ---------------------------
        # 예측 결과 저장
        # ---------------------------
        for fb in filtered_boxes:
            x1, y1, x2, y2 = fb["xyxy"] # xyxy is stored as a list
            bbox_x = x1
            bbox_y = y1
            bbox_w = x2 - x1
            bbox_h = y2 - y1

            predicted_yolo_idx = fb["cls"]
            # Ensure yolo_idx_to_original_cat_id is available globally or locally
            if 'yolo_idx_to_original_cat_id' not in globals() and 'yolo_idx_to_original_cat_id' not in locals():
                print("Error: yolo_idx_to_original_cat_id not found during prediction saving.")
                continue

            original_category_id = yolo_idx_to_original_cat_id.get(predicted_yolo_idx, -1)
            if original_category_id == -1:
                # print(f"Warning: Unknown YOLO index {predicted_yolo_idx} for image {image_id}. Skipping saving.")
                continue

            # pill_name = category_id_to_name.get(original_category_id, f"Unknown({original_category_id})") # Not needed for saving
            score = fb["score"]

            predictions.append([
                annotation_id_counter,
                image_id,
                original_category_id,
                bbox_x,
                bbox_y,
                bbox_w,
                bbox_h,
                score
            ])
            annotation_id_counter += 1

        # ---------------------------
        # 랜덤 5개 이미지에 대해 비교 시각화
        # ---------------------------
        if image_id in visualize_sample_ids:
            fig, axes = plt.subplots(1, 2, figsize=(16, 8))
            fig.suptitle(f'Image ID: {image_id}', fontsize=16)

            # 좌측: 모델 예측 결과 (후처리 적용 후)
            axes[0].imshow(img)
            axes[0].set_title('Model Prediction (Post-processed)')
            axes[0].axis('off')

            for fb in filtered_boxes:
                x1, y1, x2, y2 = fb["xyxy"]
                score = fb["score"]
                predicted_yolo_idx = fb["cls"]
                original_category_id = yolo_idx_to_original_cat_id.get(predicted_yolo_idx, -1)
                pill_name = category_id_to_name.get(original_category_id, f"Unknown({original_category_id})")

                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,
                                     edgecolor='lime', facecolor='none')
                axes[0].add_patch(rect)
                axes[0].text(x1, y1-5, f"{pill_name} {score:.2f}",
                             fontsize=10, color='black', fontweight='bold',
                             bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.8))

            # 우측: CSV 저장된 결과만 표시 (Should match the left side after this cell runs)
            axes[1].imshow(img.copy()) # Use a copy to avoid drawing on the same image object
            axes[1].set_title('From CSV Data (Re-visualized)')
            axes[1].axis('off')

            for fb in filtered_boxes:
                x1, y1, x2, y2 = fb["xyxy"]
                score = fb["score"]
                predicted_yolo_idx = fb["cls"]
                original_category_id = yolo_idx_to_original_cat_id.get(predicted_yolo_idx, -1)
                pill_name = category_id_to_name.get(original_category_id, f"Unknown({original_category_id})")

                rect_csv = plt.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,
                                         edgecolor='red', facecolor='none')
                axes[1].add_patch(rect_csv)
                axes[1].text(x1, y1-5, f"{pill_name} {score:.2f}",
                             fontsize=10, color='white', fontweight='bold',
                             bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.8))


            # 저장
            subplot_save_path = os.path.join(vis_output_dir, f"{image_id}_comparison.png")
            plt.savefig(subplot_save_path, dpi=100, bbox_inches='tight')
            plt.close(fig) # Close figure to free memory

    print(f"\n✅ 전체 예측 완료 | 시각화 저장 완료 (랜덤 5개 이미지): {vis_output_dir}")

    # -------------------------------
    # 8. CSV 파일 저장
    # -------------------------------
    submission_df = pd.DataFrame(
        predictions,
        columns=['annotation_id', 'image_id', 'category_id', 'bbox_x', 'bbox_y', 'bbox_w', 'bbox_h', 'score']
    )

    file_name = 'pred_pseudo' # Or submission.csv as before
    submission_path = f'/content/drive/MyDrive/Project/csv/{file_name}.csv'
    Path('/content/drive/MyDrive/Project/csv').mkdir(parents=True, exist_ok=True)
    submission_df.to_csv(submission_path, index=False)

    print(f"\n✅ 제출 파일 생성 완료 (전체 예측): {submission_path}")
    print(submission_df.head())

    # 저장된 CSV 불러와서 확인
    df_check = pd.read_csv(submission_path)
    print("\n 불러온 CSV 데이터 확인:")
    display(df_check.head())
    print("총 예측 개수:", len(df_check))

# 시각화
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# 이미지 경로 설정
vis_output_dir = '/content/drive/MyDrive/Project/vis_results/yolo_pseudo_result'

# PNG 이미지 파일 목록 가져오기 (정렬)
image_files = sorted([f for f in os.listdir(vis_output_dir) if f.endswith('.png')])

# 최대 4개만 선택
selected_images = image_files[:4]

# 서브플롯 설정
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Vis Results - Sample Images (4)', fontsize=16)

# 이미지 출력
for i, img_file in enumerate(selected_images):
    img_path = os.path.join(vis_output_dir, img_file)
    img = mpimg.imread(img_path)

    ax = axes[i//2, i%2]
    ax.imshow(img)
    ax.set_title(img_file, fontsize=10)
    ax.axis('off')

plt.tight_layout()
plt.show()

# 선택된 이미지 파일명 출력 (참고용)
print("\n표시된 이미지 파일:")
for f in selected_images:
    print(f"  - {f}")

