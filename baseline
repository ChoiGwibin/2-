# 최귀빈
# ------------------------------------------------------------------ 1. 라이브러리 및 환경 설정 ------------------------------------------------------------------
# 라이브러리 및 환경 설정
!pip install pandas matplotlib seaborn Pillow tqdm torchmetrics albumentations ultralytics pycocotools PyYAML

import os
import json
import torch
import pandas as pd
import numpy as np
import cv2
import re
import yaml
import shutil
import glob
import seaborn as sns
import matplotlib.patches as patches
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import torchvision
from PIL import Image
from tqdm import tqdm
from collections import Counter
from zipfile import ZipFile
from torchvision import transforms as T
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from sklearn.model_selection import train_test_split
from ultralytics import YOLO
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval

# ------------------------------------------------------------------ 2. 데이터 준비 ------------------------------------------------------------------
# Kaggle 설정
if not os.path.exists(os.path.expanduser("~/.kaggle/kaggle.json")):
    from google.colab import files
    !pip install kaggle -q
    uploaded = files.upload()

    !mkdir -p ~/.kaggle
    !cp kaggle.json ~/.kaggle/
    !chmod 600 ~/.kaggle/kaggle.json
    print("kaggle.json 설정 완료")
else:
    print("이미 kaggle.json 존재")

# Kaggle 데이터 다운로드
dataset_path = '/content/drive/MyDrive/Project/ai04-level1-project.zip'

if not os.path.exists(dataset_path):
    !kaggle competitions download -c ai04-level1-project -p /content
    print("데이터 다운로드 완료:", dataset_path)
else:
    print("이미 데이터셋 존재:", dataset_path)

# Kaggle 데이터 압축 해제
extract_dir = '/content/drive/MyDrive/Project/ai04-level1-project'

if not os.path.exists(extract_dir) or not os.listdir(extract_dir):
    with ZipFile(dataset_path, 'r') as zipf:
        zipf.extractall(extract_dir)
    print('압축 해제 완료:', extract_dir)
else:
    print('이미 압축 해제된 폴더가 존재:', extract_dir)

# ------------------------------------------------------------------ 3. 한글 폰트 설정 ------------------------------------------------------------------
# 한글 폰트 설치
!apt-get update -qq
!apt-get install fonts-nanum -qq > /dev/null
!fc-cache -fv

# 폰트 경로 설정
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'

# 폰트 매니저에 폰트 추가 및 설정
fm.fontManager.addfont(font_path)
plt.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
plt.rcParams['axes.unicode_minus'] = False

# ------------------------------------------------------------------ 4. 데이터 탐색 및 분석(EDA) ------------------------------------------------------------------
def load_and_prepare_data(image_dir, annotation_dir):
    """
    Args:
        image_dir (str): 훈련 이미지 파일이 있는 디렉토리 경로
        annotation_dir (str): 훈련 어노테이션(JSON) 파일이 있는 디렉토리 경로

    Returns:
        pandas.DataFrame: 이미지와 어노테이션 정보가 결합된 데이터프레임
    """
    json_paths = []
    for root, _, files in os.walk(annotation_dir):
        for file in files:
            if file.endswith('.json'):
                json_paths.append(os.path.join(root, file))

    print(f"총 {len(json_paths)}개의 JSON 파일을 찾았습니다.")

    all_data = []

    for json_path in tqdm(json_paths, desc="JSON 파일 처리 중"):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # 이미지 정보 추출
            image_info = data['images'][0]
            image_id = image_info['id']
            file_name = image_info['file_name']
            image_path = os.path.join(image_dir, file_name)

            # 어노테이션 정보 추출
            for ann in data['annotations']:
                if ann['image_id'] == image_id and 'bbox' in ann and len(ann['bbox']) == 4:
                    all_data.append({
                        'image_id': image_id,
                        'image_path': image_path,
                        'file_name': file_name,
                        'width': image_info['width'],
                        'height': image_info['height'],
                        'dl_name': image_info.get('dl_name', 'N/A'), # 제품명
                        'drug_shape': image_info.get('drug_shape', 'N/A'), # 알약 모양
                        'color_class1': image_info.get('color_class1', 'N/A'), # 색상
                        'line_front': image_info.get('line_front', 'N/A'), # 분할선(앞)
                        'bbox': ann['bbox'],
                        'category_id': ann['category_id'],
                        'area': ann['area']
                    })
        except Exception as e:
            print(f"파일 처리 중 오류 발생: {json_path}, 오류: {e}")

    df = pd.DataFrame(all_data)
    print(f"총 {len(df)}개의 유효한 어노테이션 데이터를 로드했습니다.")
    return df

def visualize_eda(df):
    """
    Args:
        df (pandas.DataFrame): 분석할 데이터프레임
    """
    if df.empty:
        print("데이터프레임이 비어있어 EDA를 진행할 수 없습니다.")
        return

    print("\n--- 데이터 EDA 시작 ---")

    # 1. 약품 종류(클래스) 분포 확인
    plt.figure(figsize=(15, 8))
    class_counts = df['dl_name'].value_counts().head(30) # 상위 30개만 표시
    sns.barplot(x=class_counts.values, y=class_counts.index, palette='viridis')
    plt.title('상위 30개 약품 종류(클래스) 분포')
    plt.xlabel('샘플 수')
    plt.ylabel('약품명')
    plt.tight_layout()
    plt.show()

    # 2. 이미지 크기 분포 확인
    plt.figure(figsize=(12, 6))
    sns.scatterplot(data=df.drop_duplicates(subset=['file_name']), x='width', y='height')
    plt.title('이미지 너비와 높이 분포')
    plt.xlabel('너비 (pixels)')
    plt.ylabel('높이 (pixels)')
    plt.grid(True)
    plt.show()

    # 3. 바운딩 박스(bbox) 분석
    df['bbox_width'] = df['bbox'].apply(lambda x: x[2])
    df['bbox_height'] = df['bbox'].apply(lambda x: x[3])

    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    sns.histplot(df['bbox_width'], bins=50, kde=True)
    plt.title('바운딩 박스 너비 분포')

    plt.subplot(1, 2, 2)
    sns.histplot(df['bbox_height'], bins=50, kde=True)
    plt.title('바운딩 박스 높이 분포')
    plt.tight_layout()
    plt.show()

def visualize_sample_with_all_bboxes(df, num_images=5):
    """
    Args:
        df (pandas.DataFrame): 데이터프레임
        num_images (int): 시각화할 이미지 수
    """
    if df.empty:
        print("데이터프레임이 비어있어 샘플 시각화를 할 수 없습니다.")
        return

    # 중복되지 않는 이미지 경로를 랜덤하게 선택
    unique_image_paths = df['image_path'].unique()
    if len(unique_image_paths) < num_images:
        num_images = len(unique_image_paths)

    sampled_paths = np.random.choice(unique_image_paths, num_images, replace=False)

    for image_path in sampled_paths:
        # 현재 이미지에 해당하는 모든 어노테이션(바운딩 박스)을 필터링
        image_annotations = df[df['image_path'] == image_path]

        if not os.path.exists(image_path):
            print(f"이미지 파일을 찾을 수 없습니다: {image_path}")
            continue

        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # 이미지의 대표 라벨과 파일명 가져오기 (해당 이미지의 첫 번째 어노테이션 정보 사용)
        main_label = image_annotations.iloc[0]['dl_name']
        file_name = image_annotations.iloc[0]['file_name']

        # 해당 이미지의 모든 바운딩 박스를 그리기
        for _, row in image_annotations.iterrows():
            bbox = row['bbox']
            x, y, w, h = [int(c) for c in bbox]

            # 바운딩 박스 그리기 (파란색, 두께 2)
            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)

        plt.figure(figsize=(10, 10))
        plt.imshow(image)
        plt.title(f"이미지 대표 약품명: {main_label}\n파일: {file_name}\n(총 {len(image_annotations)}개의 바운딩 박스 발견)")
        plt.axis('off')
        plt.show()


if __name__ == '__main__':
    BASE_PATH = "/content/drive/MyDrive/Project/ai04-level1-project"
    TRAIN_IMAGE_DIR = os.path.join(BASE_PATH, "train_images")
    TRAIN_ANNOTATION_DIR = os.path.join(BASE_PATH, "train_annotations")

    # 데이터 로드 및 전처리
    df = load_and_prepare_data(TRAIN_IMAGE_DIR, TRAIN_ANNOTATION_DIR)

    # 데이터프레임 정보 출력
    if not df.empty:
        print("\n--- 데이터프레임 정보 ---")
        print(df.info())
        print("\n--- 데이터 샘플 (상위 5개) ---")
        print(df.head())
        print(f"\n고유한 약품(클래스)의 수: {df['dl_name'].nunique()}")

    # EDA 시각화
    visualize_eda(df)

    # 샘플 이미지와 바운딩 박스 시각화 (수정된 함수 호출)
    visualize_sample_with_all_bboxes(df, num_images=5)

def load_and_prepare_data(image_dir, annotation_dir):
    """
    이미지 및 어노테이션 데이터를 로드하여 Pandas DataFrame을 생성합니다.
    """
    json_paths = []
    for root, _, files in os.walk(annotation_dir):
        for file in files:
            if file.endswith('.json'):
                json_paths.append(os.path.join(root, file))
    print(f"총 {len(json_paths)}개의 JSON 파일을 찾았습니다.")

    all_data = []
    for json_path in tqdm(json_paths, desc="JSON 파일 처리 중"):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if not data.get('images'):
                print(f"경고: 'images' 키를 찾을 수 없습니다: {json_path}")
                continue

            image_info = data['images'][0]
            image_id = image_info['id']
            file_name = image_info['file_name']
            image_path = os.path.join(image_dir, file_name)

            for ann in data.get('annotations', []):
                if ann.get('image_id') == image_id and 'bbox' in ann and len(ann['bbox']) == 4:
                    all_data.append({
                        'image_path': image_path,
                        'file_name': file_name,
                        'width': image_info['width'],
                        'height': image_info['height'],
                        'dl_name': image_info.get('dl_name', 'N/A'),
                        'bbox': ann['bbox'],
                    })
        except Exception as e:
            print(f"파일 처리 중 오류 발생: {json_path}, 오류: {e}")

    df = pd.DataFrame(all_data)
    if df.empty:
        print("경고: 유효한 어노테이션 데이터를 로드하지 못했습니다.")
    else:
        print(f"총 {len(df)}개의 유효한 어노테이션 데이터를 로드했습니다.")
    return df


# ------------------------------------------------------------------ 5. YOLO 데이터셋 변환 및 학습 ------------------------------------------------------------------
# YOLO 데이터셋 변환을 위한 함수
def convert_to_yolo_format(bbox, img_width, img_height):
    """
    COCO 바운딩 박스 형식을 YOLO 형식으로 변환합니다.
    """
    x, y, w, h = bbox
    x_center = (x + w / 2) / img_width
    y_center = (y + h / 2) / img_height
    norm_w = w / img_width
    norm_h = h / img_height
    return x_center, y_center, norm_w, norm_h


def process_and_save_dataset(df, image_files, split_type, class_to_id, output_dir):
    """
    주어진 파일 목록에 대해 이미지 복사 및 라벨 파일 생성을 수행합니다.
    """
    img_output_dir = os.path.join(output_dir, 'images', split_type)
    lbl_output_dir = os.path.join(output_dir, 'labels', split_type)

    os.makedirs(img_output_dir, exist_ok=True)
    os.makedirs(lbl_output_dir, exist_ok=True)

    for file_name in tqdm(image_files, desc=f"Processing {split_type} set"):
        annotations = df[df['file_name'] == file_name]
        if annotations.empty:
            continue

        # 1. 이미지 파일 복사
        source_img_path = annotations.iloc[0]['image_path']
        if os.path.exists(source_img_path):
            shutil.copy(source_img_path, img_output_dir)
        else:
            print(f"경고: 이미지 파일을 찾을 수 없습니다: {source_img_path}")
            continue

        # 2. 라벨 파일 생성
        label_file_name = os.path.splitext(file_name)[0] + '.txt'
        label_file_path = os.path.join(lbl_output_dir, label_file_name)

        with open(label_file_path, 'w', encoding='utf-8') as f:
            for _, row in annotations.iterrows():
                class_name = row['dl_name']
                if class_name not in class_to_id:
                    continue
                class_id = class_to_id[class_name]

                img_width = row['width']
                img_height = row['height']
                bbox = row['bbox']

                x_center, y_center, w_norm, h_norm = convert_to_yolo_format(bbox, img_width, img_height)

                f.write(f"{class_id} {x_center} {y_center} {w_norm} {h_norm}\n")


if __name__ == '__main__':
    BASE_PATH = "/content/drive/MyDrive/Project/ai04-level1-project"
    TRAIN_IMAGE_DIR = os.path.join(BASE_PATH, "train_images")
    TRAIN_ANNOTATION_DIR = os.path.join(BASE_PATH, "train_annotations")

    # 생성될 데이터셋이 저장될 경로
    OUTPUT_DATASET_DIR = os.path.join(BASE_PATH, "pill_dataset_yolo")

    # 데이터 로드
    df = load_and_prepare_data(TRAIN_IMAGE_DIR, TRAIN_ANNOTATION_DIR)

    if not df.empty:
        # 클래스 매핑 생성
        class_names = sorted(df['dl_name'].unique().tolist())
        class_to_id = {name: i for i, name in enumerate(class_names)}
        print(f"\n총 {len(class_names)}개의 클래스를 발견했습니다.")

        # 데이터 분할
        unique_image_files = df['file_name'].unique()
        train_files, val_files = train_test_split(unique_image_files, test_size=0.2, random_state=42)
        print(f"훈련 세트: {len(train_files)}개 이미지, 검증 세트: {len(val_files)}개 이미지")

        # 데이터셋 처리 및 저장
        process_and_save_dataset(df, train_files, 'train', class_to_id, OUTPUT_DATASET_DIR)
        process_and_save_dataset(df, val_files, 'val', class_to_id, OUTPUT_DATASET_DIR)

        # class_mapping.csv 파일 생성
        class_df = pd.DataFrame(list(class_to_id.items()), columns=['class_name', 'class_id'])
        class_df = class_df[['class_id', 'class_name']] # 컬럼 순서 변경
        csv_path = os.path.join(OUTPUT_DATASET_DIR, 'class_mapping.csv')
        class_df.to_csv(csv_path, index=False, encoding='utf-8-sig')

        print(f"\nYOLO 데이터셋 생성이 완료되었습니다. 경로: {OUTPUT_DATASET_DIR}")
        print(f"클래스 매핑 CSV 파일이 생성되었습니다. 경로: {csv_path}")

if __name__ == '__main__':
    BASE_PATH = "/content/drive/MyDrive/Project/ai04-level1-project"

    # class_mapping.csv가 있는 폴더 경로
    DATASET_YOLO_DIR = os.path.join(BASE_PATH, "pill_dataset_yolo")

    CSV_PATH = os.path.join(DATASET_YOLO_DIR, 'class_mapping.csv')
    YAML_PATH = os.path.join(BASE_PATH, 'dataset.yaml') # 최종 생성될 yaml 파일 경로

    # class_mapping.csv 파일 읽기
    try:
        class_df = pd.read_csv(CSV_PATH)
        # class_id를 기준으로 정렬하여 순서를 보장합니다.
        class_df = class_df.sort_values(by='class_id').reset_index(drop=True)
        print(f"'{CSV_PATH}' 파일에서 {len(class_df)}개의 클래스를 성공적으로 로드했습니다.")
    except FileNotFoundError:
        print(f"오류: '{CSV_PATH}' 파일을 찾을 수 없습니다.")
        print("데이터 전처리 스크립트를 먼저 실행하여 class_mapping.csv 파일을 생성했는지 확인해주세요.")
        exit()

    # YAML 파일에 쓸 names 리스트 생성 (YOLOv8 형식)
    class_names_list = class_df['class_name'].tolist()

    # dataset.yaml 파일에 들어갈 전체 데이터 구조 정의
    yaml_data = {
        'path': DATASET_YOLO_DIR,  # 데이터셋 루트 폴더의 절대 경로
        'train': 'images/train',      # 학습 이미지 폴더 (상대 경로)
        'val': 'images/val',          # 검증 이미지 폴더 (상대 경로)
        'names': class_names_list     # 클래스 이름 리스트
    }

    # dataset.yaml 파일 저장
    try:
        with open(YAML_PATH, 'w', encoding='utf-8') as f:
            # allow_unicode=True: 한글 깨짐 방지, sort_keys=False: 순서 유지
            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False)
        print(f"\n성공적으로 '{YAML_PATH}' 파일을 생성/업데이트했습니다.")
        print("파일 내용을 확인해보세요:")
        print("---")
        print(yaml.dump(yaml_data, allow_unicode=True, sort_keys=False))
        print("---\n이제 이 파일을 사용하여 YOLOv8 학습을 진행할 수 있습니다.")
    except Exception as e:
        print(f"YAML 파일 저장 중 오류 발생: {e}")

if __name__ == '__main__':
    # 데이터셋 설정 파일(.yaml)의 경로
    DATASET_YAML_PATH = "/content/drive/MyDrive/Project/ai04-level1-project/dataset_final.yaml"

    # 'yolov8n.pt': nano 모델, 가장 작고 빠름
    # 'yolov8s.pt': small 모델
    # 'yolov8m.pt': medium 모델
    # 'yolov8l.pt': large 모델
    # 'yolov8x.pt': extra-large 모델, 가장 크고 정확하지만 느림
    MODEL_NAME = 'yolov8n.pt'

    # 학습 관련 하이퍼파라미터 설정
    EPOCHS = 100  # 전체 데이터셋을 몇 번 반복 학습할지 결정 (에포크)
    IMAGE_SIZE = 640  # 학습에 사용할 이미지 크기
    BATCH_SIZE = 16  # 한 번에 몇 개의 이미지를 학습할지 결정 (배치 사이즈)
    PROJECT_NAME = 'pill_detection_results' # 학습 결과가 저장될 프로젝트 폴더 이름
    RUN_NAME = 'yolov8n_run1' # 이번 학습의 실행 이름

    # YOLO 모델 로드
    # 미리 학습된(pre-trained) 모델을 로드합니다.
    # 만약 로컬에 해당 모델 파일이 없으면 자동으로 다운로드됩니다.
    print(f"'{MODEL_NAME}' 모델을 로드합니다...")
    model = YOLO(MODEL_NAME)

    # 데이터셋 경로 유효성 검사
    if not os.path.exists(DATASET_YAML_PATH):
        print(f"오류: 데이터셋 설정 파일을 찾을 수 없습니다 -> {DATASET_YAML_PATH}")
    else:
        # 모델 학습 시작
        print("모델 학습을 시작합니다...")
        try:
            results = model.train(
                data=DATASET_YAML_PATH,
                epochs=EPOCHS,
                imgsz=IMAGE_SIZE,
                batch=BATCH_SIZE,
                project=PROJECT_NAME,
                name=RUN_NAME,
                patience=30, # 30 에포크 동안 성능 개선이 없으면 조기 종료
                verbose=True # 학습 과정 상세히 출력
            )
            print("모델 학습이 성공적으로 완료되었습니다!")
            print(f"학습 결과는 '{PROJECT_NAME}/{RUN_NAME}' 폴더에 저장되었습니다.")

        except Exception as e:
            print(f"학습 중 오류가 발생했습니다: {e}")

# ------------------------------------------------------------------ 6. 추론 및 제출 파일 생성 ------------------------------------------------------------------
def generate_submission_file(trained_model_path, test_image_dir, output_csv_path, conf_threshold=0.001):
    """
    훈련된 YOLO 모델로 테스트 이미지에 대한 예측을 수행하고,
    대회 제출 형식에 맞는 submission.csv 파일을 생성합니다.

    Args:
        trained_model_path (str): 훈련된 YOLO 모델(.pt) 파일 경로.
        test_image_dir (str): 예측을 수행할 테스트 이미지들이 있는 디렉토리 경로.
        output_csv_path (str): 생성될 submission.csv 파일의 저장 경로.
        conf_threshold (float): 예측 시 사용할 최소 confidence 점수 임계값.
    """
    print(f"모델 로드 중: {trained_model_path}")
    model = YOLO(trained_model_path)

    test_image_files = [f for f in os.listdir(test_image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"총 {len(test_image_files)}개의 테스트 이미지 파일을 찾았습니다.")

    submission_data = []
    annotation_id_counter = 1

    for image_file in tqdm(test_image_files, desc="테스트 이미지 예측 중"):
        image_path = os.path.join(test_image_dir, image_file)

        # 모델 예측 수행
        results = model.predict(source=image_path, conf=conf_threshold, verbose=False)
        result = results[0]  # 첫 번째 이미지 결과

        # image_id 추출 (예: 'test_001.jpg' -> 1)
        try:
            image_id = int(os.path.splitext(image_file)[0].split('_')[-1])
        except ValueError:
            print(f"경고: 파일명에서 image_id를 추출할 수 없습니다: {image_file}. 이 파일을 건너뜁니다.")
            continue

        # 각 예측 결과(bounding box)에 대해 정보 추출
        for box in result.boxes:
            class_id = int(box.cls[0])
            score = float(box.conf[0])

            # Bounding box 좌표를 xyxy 형식으로 가져옴
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()

            # COCO 형식 [x, y, w, h]로 변환
            bbox_x = float(x1)
            bbox_y = float(y1)
            bbox_w = float(x2 - x1)
            bbox_h = float(y2 - y1)

            submission_data.append({
                'annotation_id': annotation_id_counter,
                'image_id': image_id,
                'category_id': class_id,
                'bbox_x': bbox_x,
                'bbox_y': bbox_y,
                'bbox_w': bbox_w,
                'bbox_h': bbox_h,
                'score': score
            })
            annotation_id_counter += 1

    if not submission_data:
        print("경고: 유효한 예측 결과를 찾지 못했습니다. CSV 파일이 생성되지 않습니다.")
        return

    # DataFrame 생성 및 CSV 파일로 저장
    submission_df = pd.DataFrame(submission_data)

    # 컬럼 순서 지정
    column_order = ['annotation_id', 'image_id', 'category_id', 'bbox_x', 'bbox_y', 'bbox_w', 'bbox_h', 'score']
    submission_df = submission_df[column_order]

    submission_df.to_csv(output_csv_path, index=False)
    print(f"\n제출 파일 생성이 완료되었습니다. 경로: {output_csv_path}")
    print(f"총 {len(submission_df)}개의 객체 예측이 저장되었습니다.")


if __name__ == '__main__':
    TRAINED_MODEL_PATH = "/content/pill_detection_results/yolov8n_run1/weights/best.pt"
    TEST_IMAGE_DIR = "/content/drive/MyDrive/Project/ai04-level1-project/test_images"
    OUTPUT_CSV_PATH = "/content/drive/MyDrive/Project/ai04-level1-project/pill_dataset_yolo/submission.csv"

    # 함수 실행
    if not os.path.exists(TRAINED_MODEL_PATH) or not os.path.isdir(TEST_IMAGE_DIR):
         print("오류: 스크립트 하단의 경로 변수(TRAINED_MODEL_PATH, TEST_IMAGE_DIR)가 올바르게 설정되었는지 확인해주세요.")
    else:
        generate_submission_file(
            trained_model_path=TRAINED_MODEL_PATH,
            test_image_dir=TEST_IMAGE_DIR,
            output_csv_path=OUTPUT_CSV_PATH
        )

if __name__ == '__main__':
    # 학습 완료된 모델(.pt 파일)의 경로
    TRAINED_MODEL_PATH = "/content/pill_detection_results/yolov8n_run1/weights/best.pt"

    # 예측을 수행할 테스트 이미지들이 있는 폴더 경로
    TEST_IMAGE_DIR = "/content/drive/MyDrive/Project/ai04-level1-project/test_images"

    # 최종 제출용 submission.csv 파일을 저장할 경로
    OUTPUT_CSV_PATH = "/content/drive/MyDrive/Project/ai04-level1-project/submission.csv"

    # 신뢰도 임계값 설정 (이 값보다 높은 신뢰도를 가진 객체만 결과에 포함)
    CONFIDENCE_THRESHOLD = 0.25

    print("설정된 경로를 확인합니다...")
    if not os.path.exists(TRAINED_MODEL_PATH):
        print(f"오류: 학습된 모델 파일을 찾을 수 없습니다. 경로를 확인해주세요: {TRAINED_MODEL_PATH}")
        exit()
    if not os.path.isdir(TEST_IMAGE_DIR):
        print(f"오류: 테스트 이미지 폴더를 찾을 수 없습니다. 경로를 확인해주세요: {TEST_IMAGE_DIR}")
        exit()

    # 1. 학습된 YOLOv8 모델 로드
    print(f"모델을 로드합니다: {TRAINED_MODEL_PATH}")
    model = YOLO(TRAINED_MODEL_PATH)

    # 2. 테스트 이미지 파일 목록 가져오기
    test_image_files = [f for f in os.listdir(TEST_IMAGE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"총 {len(test_image_files)}개의 테스트 이미지를 찾았습니다.")

    # 3. 예측 결과 저장을 위한 리스트 초기화
    submission_data = []
    annotation_id_counter = 1

    # 4. 각 테스트 이미지에 대해 예측 수행
    for image_name in tqdm(test_image_files, desc="테스트 이미지 예측 중"):
        image_path = os.path.join(TEST_IMAGE_DIR, image_name)

        # 모델 예측 실행
        results = model.predict(image_path, conf=CONFIDENCE_THRESHOLD, verbose=False)

        # 파일명에서 숫자(image_id) 추출
        match = re.search(r'\d+', image_name)
        if not match:
            print(f"경고: 파일명 '{image_name}'에서 image_id(숫자)를 추출할 수 없습니다. 건너뜁니다.")
            continue
        image_id = int(match.group())

        # 예측 결과 처리
        boxes = results[0].boxes
        for box in boxes:
            # 바운딩 박스 좌표 (xywh 형식)
            x, y, w, h = box.xywh[0].tolist()

            # 클래스 ID와 신뢰도 점수
            class_id = int(box.cls[0])
            score = float(box.conf[0])

            # --- 가장 중요한 부분: 좌표를 정수로 변환 ---
            bbox_x = int(x - w / 2) # 좌측 상단 x
            bbox_y = int(y - h / 2) # 좌측 상단 y
            bbox_w = int(w)
            bbox_h = int(h)

            submission_data.append({
                "annotation_id": annotation_id_counter,
                "image_id": image_id,
                "category_id": class_id,
                "bbox_x": bbox_x,
                "bbox_y": bbox_y,
                "bbox_w": bbox_w,
                "bbox_h": bbox_h,
                "score": score
            })
            annotation_id_counter += 1

    # 5. 결과를 DataFrame으로 변환 후 CSV 파일로 저장
    if not submission_data:
        print("경고: 유효한 예측 결과를 찾지 못했습니다. CSV 파일이 비어있을 수 있습니다.")

    submission_df = pd.DataFrame(submission_data)

    # 요구사항에 맞게 컬럼 순서 지정
    submission_df = submission_df[["annotation_id", "image_id", "category_id", "bbox_x", "bbox_y", "bbox_w", "bbox_h", "score"]]

    submission_df.to_csv(OUTPUT_CSV_PATH, index=False)
    print(f"\n제출 파일 생성이 완료되었습니다: {OUTPUT_CSV_PATH}")
    print("CSV 파일의 처음 5개 행:")
    print(submission_df.head())

def load_and_process_annotations(image_dir, annotation_dir):
    """
    JSON 어노테이션을 읽고 새로운 규칙에 따라 ID를 처리하여 DataFrame으로 반환합니다.
    """
    # os.listdir 대신 os.walk를 사용하여 모든 하위 폴더를 탐색
    json_paths = []
    for root, _, files in os.walk(annotation_dir):
        for file in files:
            if file.endswith('.json'):
                json_paths.append(os.path.join(root, file))

    # 찾은 JSON 파일의 개수를 바로 출력하여 확인
    print(f"총 {len(json_paths)}개의 JSON 파일을 찾았습니다.")

    all_data = []
    class_mapping = {}

    for json_path in tqdm(json_paths, desc="JSON 파일 분석 중"):
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if not data.get('images'):
            continue

        image_info = data['images'][0]
        # category_id를 dl_idx 값으로 사용
        category_id = image_info.get('dl_idx')
        if category_id is None:
            print(f"경고: 'dl_idx'를 찾을 수 없습니다. 파일 건너뜀: {json_path}")
            continue

        dl_name = image_info.get('dl_name', 'N/A')
        class_mapping[category_id] = dl_name

        for ann in data.get('annotations', []):
            # 유효성 검사
            if 'bbox' in ann and isinstance(ann['bbox'], list) and len(ann['bbox']) == 4:
                all_data.append({
                    'image_path': os.path.join(image_dir, image_info['file_name']),
                    'file_name': image_info['file_name'],
                    'width': image_info['width'],
                    'height': image_info['height'],
                    'category_id': category_id,
                    'bbox': ann['bbox'],
                })

    df = pd.DataFrame(all_data)
    if not df.empty:
        print(f"\n총 {len(df)}개의 유효한 어노테이션을 로드했습니다.")
    else:
        print("\n경고: JSON 파일들을 찾았으나, 유효한 bbox 어노테이션이 포함된 데이터를 찾지 못했습니다.")
    return df, class_mapping

def convert_to_yolo_format(bbox, img_width, img_height):
    x, y, w, h = bbox
    return ((x + w / 2) / img_width, (y + h / 2) / img_height, w / img_width, h / img_height)

def create_yolo_dataset(df, image_files, split_type, output_dir):
    img_output_dir = os.path.join(output_dir, 'images', split_type)
    lbl_output_dir = os.path.join(output_dir, 'labels', split_type)
    os.makedirs(img_output_dir, exist_ok=True)
    os.makedirs(lbl_output_dir, exist_ok=True)

    for file_name in tqdm(image_files, desc=f"{split_type} 세트 생성 중"):
        annotations = df[df['file_name'] == file_name]
        if annotations.empty: continue

        source_path = annotations.iloc[0]['image_path']
        if os.path.exists(source_path):
            shutil.copy(source_path, img_output_dir)
        else:
            print(f"경고: 원본 이미지 파일을 찾을 수 없습니다. 건너뜁니다: {source_path}")
            continue

        label_path = os.path.join(lbl_output_dir, os.path.splitext(file_name)[0] + '.txt')
        with open(label_path, 'w', encoding='utf-8') as f:
            for _, row in annotations.iterrows():
                yolo_bbox = convert_to_yolo_format(row['bbox'], row['width'], row['height'])
                f.write(f"{row['category_id']} {' '.join(map(str, yolo_bbox))}\n")

if __name__ == '__main__':
    BASE_PATH = "/content/drive/MyDrive/Project/ai04-level1-project"
    TRAIN_IMAGE_DIR = os.path.join(BASE_PATH, "train_images")
    TRAIN_ANNOTATION_DIR = os.path.join(BASE_PATH, "train_annotations")
    OUTPUT_DATASET_DIR = os.path.join(BASE_PATH, "pill_dataset_yolo_v2")

    df, class_mapping = load_and_process_annotations(TRAIN_IMAGE_DIR, TRAIN_ANNOTATION_DIR)

    if not df.empty:
        unique_images = df['file_name'].unique()
        train_files, val_files = train_test_split(unique_images, test_size=0.2, random_state=42)

        create_yolo_dataset(df, train_files, 'train', OUTPUT_DATASET_DIR)
        create_yolo_dataset(df, val_files, 'val', OUTPUT_DATASET_DIR)

        class_df = pd.DataFrame(list(class_mapping.items()), columns=['category_id', 'class_name']).sort_values('category_id')
        csv_path = os.path.join(OUTPUT_DATASET_DIR, 'class_mapping_v2.csv')
        class_df.to_csv(csv_path, index=False, encoding='utf-8-sig')

        print(f"\nYOLO v2 데이터셋 생성이 완료되었습니다: {OUTPUT_DATASET_DIR}")
        print(f"새로운 클래스 매핑 파일: {csv_path}")

if __name__ == '__main__':
    BASE_PATH = "/content/drive/MyDrive/Project/ai04-level1-project"
    DATASET_YOLO_DIR = os.path.join(BASE_PATH, "pill_dataset_yolo_v2")

    CSV_PATH = os.path.join(DATASET_YOLO_DIR, 'class_mapping_v2.csv')
    YAML_PATH = os.path.join(BASE_PATH, 'dataset_v2.yaml')

    try:
        class_df = pd.read_csv(CSV_PATH)
        # category_id를 키, class_name을 값으로 하는 딕셔너리 생성
        class_names_dict = pd.Series(class_df.class_name.values, index=class_df.category_id).to_dict()
        print(f"'{CSV_PATH}' 파일에서 {len(class_names_dict)}개 클래스 매핑을 로드했습니다.")
    except FileNotFoundError:
        print(f"오류: '{CSV_PATH}'를 찾을 수 없습니다. 1단계 스크립트를 먼저 실행하세요.")
        exit()

    yaml_data = {
        'path': os.path.abspath(DATASET_YOLO_DIR),
        'train': 'images/train',
        'val': 'images/val',
        'names': class_names_dict
    }

    with open(YAML_PATH, 'w', encoding='utf-8') as f:
        yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=True)

    print(f"\n성공적으로 '{YAML_PATH}' 파일을 생성했습니다.")
    print("--- YAML 파일 내용 미리보기 ---")
    print(yaml.dump(yaml_data, allow_unicode=True, sort_keys=True))
    print("----------------------------")

if __name__ == '__main__':
    # 생성한 데이터셋 설정 파일(.yaml)의 경로
    DATASET_YAML_PATH = "/content/drive/MyDrive/Project/ai04-level1-project/dataset_final.yaml"

    # 학습에 사용할 YOLOv8 모델 선택
    # 'yolov8n.pt': nano 모델, 가장 작고 빠름 (첫 시도에 추천)
    # 'yolov8s.pt': small 모델
    # 'yolov8m.pt': medium 모델
    MODEL_NAME = 'yolov8n.pt'

    # 학습 관련 하이퍼파라미터 설정
    EPOCHS = 100      # 전체 데이터셋을 몇 번 반복 학습할지 결정 (에포크)
    IMAGE_SIZE = 640  # 학습에 사용할 이미지 크기
    BATCH_SIZE = 16   # 한 번에 몇 개의 이미지를 학습할지 결정 (배치 사이즈)

    # 학습 결과가 저장될 폴더 이름 설정
    PROJECT_NAME = 'pill_detection_results' # 학습 결과가 저장될 프로젝트 폴더 이름
    RUN_NAME = 'yolov8n_run_v2' # 이번 학습의 실행 이름 (이전 학습과 구분)

    # YOLO 모델 로드
    print(f"'{MODEL_NAME}' 모델을 로드합니다...")
    model = YOLO(MODEL_NAME)

    # 데이터셋 경로 유효성 검사
    if not os.path.exists(DATASET_YAML_PATH):
        print(f"오류: 데이터셋 설정 파일을 찾을 수 없습니다 -> {DATASET_YAML_PATH}")
    else:
        # 모델 학습 시작
        print("모델 학습을 시작합니다...")
        try:
            results = model.train(
                data=DATASET_YAML_PATH,
                epochs=EPOCHS,
                imgsz=IMAGE_SIZE,
                batch=BATCH_SIZE,
                project=PROJECT_NAME,
                name=RUN_NAME,
                patience=30, # 30 에포크 동안 성능 개선이 없으면 조기 종료
                verbose=True # 학습 과정 상세히 출력
            )
            print("\n모델 학습이 성공적으로 완료되었습니다!")
            print(f"학습 결과는 '{PROJECT_NAME}/{RUN_NAME}' 폴더에 저장되었습니다.")

        except Exception as e:
            print(f"\n학습 중 오류가 발생했습니다: {e}")

def create_id_mapping(annotation_dir):
    """
    학습 어노테이션 폴더를 스캔하여 'new_id -> dl_idx' 매핑을 생성합니다.
    이 함수는 prepare_dataset_final.py의 ID 생성 로직과 동일해야 합니다.
    """
    print("ID 매핑 테이블을 생성합니다...")
    json_paths = []
    for root, _, files in os.walk(annotation_dir):
        for file in files:
            if file.endswith('.json'):
                json_paths.append(os.path.join(root, file))

    original_dl_indices = set()
    for json_path in tqdm(json_paths, desc="어노테이션 스캔 중"):
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if data.get('images'):
            dl_idx = data['images'][0].get('dl_idx')
            if dl_idx is not None:
                original_dl_indices.add(dl_idx)

    # 정렬하여 일관된 순서를 보장
    sorted_unique_dl_idx = sorted(list(original_dl_indices))

    # new_id(0부터 시작)를 key로, 원래 dl_idx를 value로 하는 딕셔너리 생성
    new_id_to_dl_idx = {new_id: dl_idx for new_id, dl_idx in enumerate(sorted_unique_dl_idx)}

    print(f"총 {len(new_id_to_dl_idx)}개의 클래스에 대한 ID 매핑을 완료했습니다.")
    return new_id_to_dl_idx

def predict_and_generate_submission(model_path, test_image_dir, annotation_dir, output_csv_path):
    """
    테스트 이미지에 대한 예측을 수행하고 최종 제출용 CSV 파일을 생성합니다.
    """
    # 1. ID 매핑 생성
    new_id_to_dl_idx = create_id_mapping(annotation_dir)

    # 2. 학습된 모델 로드
    print(f"\n학습된 모델을 로드합니다: {model_path}")
    model = YOLO(model_path)

    # 3. 예측 수행 및 결과 저장
    submission_data = []
    annotation_id_counter = 1

    test_image_files = [f for f in os.listdir(test_image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    for file_name in tqdm(test_image_files, desc="테스트 이미지 예측 중"):
        image_path = os.path.join(test_image_dir, file_name)

        # 이미지 파일명에서 숫자 부분(image_id) 추출
        match = re.search(r'\d+', os.path.splitext(file_name)[0])
        if not match:
            continue
        image_id = int(match.group())

        # 모델 예측
        results = model.predict(image_path, verbose=False)

        for result in results:
            boxes = result.boxes
            for box in boxes:
                # 바운딩 박스 좌표 (x, y, w, h)
                x, y, w, h = map(int, box.xywh[0])

                # 예측된 new_class_id와 신뢰도 점수
                predicted_new_id = int(box.cls[0])
                score = float(box.conf[0])

                # new_class_id를 원래의 category_id(dl_idx)로 변환
                if predicted_new_id in new_id_to_dl_idx:
                    original_category_id = new_id_to_dl_idx[predicted_new_id]
                else:
                    # 매핑에 없는 경우 건너뛰기 (오류 방지)
                    continue

                submission_data.append({
                    'annotation_id': annotation_id_counter,
                    'image_id': image_id,
                    'category_id': original_category_id,
                    'bbox_x': x,
                    'bbox_y': y,
                    'bbox_w': w,
                    'bbox_h': h,
                    'score': score
                })
                annotation_id_counter += 1

    # 4. CSV 파일로 저장
    if not submission_data:
        print("\n경고: 예측된 객체가 하나도 없어 submission.csv 파일을 생성할 수 없습니다.")
        return

    df_submission = pd.DataFrame(submission_data)
    # 컬럼 순서 지정
    df_submission = df_submission[['annotation_id', 'image_id', 'category_id', 'bbox_x', 'bbox_y', 'bbox_w', 'bbox_h', 'score']]
    df_submission.to_csv(output_csv_path, index=False)

    print(f"\n최종 제출 파일 생성이 완료되었습니다: {output_csv_path}")
    print(f"총 {len(df_submission)}개의 객체를 CSV 파일에 저장했습니다.")

if __name__ == '__main__':
    BASE_PATH = "/content/drive/MyDrive/Project/ai04-level1-project"

    # 1. 방금 학습으로 생성된 best.pt 파일의 전체 경로
    TRAINED_MODEL_PATH = os.path.join("/content/pill_detection_results/yolov8n_run_v22/weights/best.pt")

    # 2. 테스트 이미지가 들어있는 폴더 경로
    TEST_IMAGE_DIR = os.path.join(BASE_PATH, "test_images")

    # 3. ID 매핑 생성을 위한 '학습용' 어노테이션 폴더 경로
    TRAIN_ANNOTATION_DIR = os.path.join(BASE_PATH, "train_annotations")

    # 4. 최종 생성될 submission.csv 파일의 경로와 이름
    OUTPUT_CSV_PATH = os.path.join(BASE_PATH, "submission_final.csv")

    predict_and_generate_submission(
        model_path=TRAINED_MODEL_PATH,
        test_image_dir=TEST_IMAGE_DIR,
        annotation_dir=TRAIN_ANNOTATION_DIR,
        output_csv_path=OUTPUT_CSV_PATH
    )

# ------------------------------------------------------------------ 7. 통합 데이터 준비 스크립트 ------------------------------------------------------------------
def prepare_final_dataset(base_path):
    """
    모든 데이터 준비 및 YAML 생성 과정을 통합하여 처리하는 최종 함수.
    """
    train_image_dir = os.path.join(base_path, "train_images")
    train_annotation_dir = os.path.join(base_path, "train_annotations")
    output_dataset_dir = os.path.join(base_path, "pill_dataset_yolo_final") # 최종 데이터셋 폴더
    final_yaml_path = os.path.join(base_path, 'dataset_final.yaml') # 최종 YAML 파일

    # 1. 모든 JSON 파일을 탐색하여 어노테이션 정보 로드
    json_paths = []
    for root, _, files in os.walk(train_annotation_dir):
        for file in files:
            if file.endswith('.json'):
                json_paths.append(os.path.join(root, file))

    print(f"총 {len(json_paths)}개의 JSON 파일을 찾았습니다.")

    all_data = []
    # 원본 dl_idx와 dl_name을 수집하여 매핑 테이블 생성
    original_class_info = {}
    for json_path in tqdm(json_paths, desc="1/4: JSON 파일 분석 중"):
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if not data.get('images'): continue

        image_info = data['images'][0]
        original_dl_idx = image_info.get('dl_idx')
        if original_dl_idx is None: continue

        original_class_info[original_dl_idx] = image_info.get('dl_name', 'N/A')

        for ann in data.get('annotations', []):
            if 'bbox' in ann and isinstance(ann['bbox'], list) and len(ann['bbox']) == 4:
                all_data.append({
                    'image_path': os.path.join(train_image_dir, image_info['file_name']),
                    'file_name': image_info['file_name'],
                    'width': image_info['width'],
                    'height': image_info['height'],
                    'dl_idx': original_dl_idx,
                    'bbox': ann['bbox'],
                })

    df = pd.DataFrame(all_data)
    if df.empty:
        print("오류: 유효한 어노테이션을 찾지 못했습니다. 스크립트를 종료합니다.")
        return

    # 2. dl_idx를 0부터 시작하는 새로운 class_id로 변환
    unique_dl_idx = sorted(original_class_info.keys())
    dl_idx_to_new_id = {dl_idx: new_id for new_id, dl_idx in enumerate(unique_dl_idx)}
    df['new_class_id'] = df['dl_idx'].map(dl_idx_to_new_id)

    print(f"\n총 {len(df)}개의 유효한 어노테이션을 로드했습니다.")
    print(f"{len(unique_dl_idx)}개의 고유 클래스를 발견하여 0~{len(unique_dl_idx)-1} 범위의 새 ID로 매핑했습니다.")

    # 3. YOLO 라벨 파일 생성 및 이미지 복사
    unique_images = df['file_name'].unique()
    train_files, val_files = train_test_split(unique_images, test_size=0.2, random_state=42)

    for split_type, files in [('train', train_files), ('val', val_files)]:
        img_output_dir = os.path.join(output_dataset_dir, 'images', split_type)
        lbl_output_dir = os.path.join(output_dataset_dir, 'labels', split_type)
        os.makedirs(img_output_dir, exist_ok=True)
        os.makedirs(lbl_output_dir, exist_ok=True)

        for file_name in tqdm(files, desc=f"2/4: {split_type} 세트 생성 중"):
            annotations = df[df['file_name'] == file_name]
            if annotations.empty: continue

            source_path = annotations.iloc[0]['image_path']
            if os.path.exists(source_path):
                shutil.copy(source_path, img_output_dir)
            else:
                continue

            label_path = os.path.join(lbl_output_dir, os.path.splitext(file_name)[0] + '.txt')
            with open(label_path, 'w', encoding='utf-8') as f:
                for _, row in annotations.iterrows():
                    x, y, w, h = row['bbox']
                    img_w, img_h = row['width'], row['height']
                    yolo_bbox = ((x + w / 2) / img_w, (y + h / 2) / img_h, w / img_w, h / img_h)
                    # 라벨 파일에 'new_class_id'를 씀
                    f.write(f"{row['new_class_id']} {' '.join(map(str, yolo_bbox))}\n")

    # 4. 최종 YAML 파일 생성
    # YAML의 names 필드를 리스트 형태로 생성
    new_id_to_name = {new_id: original_class_info[dl_idx] for dl_idx, new_id in dl_idx_to_new_id.items()}
    class_name_list = [new_id_to_name[i] for i in range(len(new_id_to_name))]

    yaml_data = {
        'path': os.path.abspath(output_dataset_dir),
        'train': 'images/train',
        'val': 'images/val',
        'names': class_name_list
    }

    with open(final_yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False)

    print(f"\n3/4: 최종 데이터셋 생성이 완료되었습니다: {output_dataset_dir}")
    print(f"4/4: 최종 YAML 파일 생성이 완료되었습니다: {final_yaml_path}")

if __name__ == '__main__':
    BASE_PATH = "/content/drive/MyDrive/Project/ai04-level1-project"
    prepare_final_dataset(BASE_PATH)
