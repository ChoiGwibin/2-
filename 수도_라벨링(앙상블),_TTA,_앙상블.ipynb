{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChoiGwibin/2-/blob/main/%EC%88%98%EB%8F%84_%EB%9D%BC%EB%B2%A8%EB%A7%81(%EC%95%99%EC%83%81%EB%B8%94)%2C_TTA%2C_%EC%95%99%EC%83%81%EB%B8%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck9u87qShIMl"
      },
      "source": [
        "# 라이브러리 및 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A7R4iFmyOGC",
        "outputId": "ba54851e-32dc-43f4-9cc4-c8bf176c3099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CJY02Ek8MhyR",
        "outputId": "69bfd081-023f-417b-b05d-e98710bf82fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.203-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.9)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.0.11)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.203-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, ultralytics-thop, torchmetrics, ultralytics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2 ultralytics-8.3.203 ultralytics-thop-2.0.17\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "# 라이브러리 및 환경 설정\n",
        "!pip install pandas matplotlib seaborn Pillow tqdm torchmetrics albumentations ultralytics pycocotools PyYAML\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import re\n",
        "import yaml\n",
        "import shutil\n",
        "import glob\n",
        "import seaborn as sns\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from zipfile import ZipFile\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryByvs-PhM_e"
      },
      "source": [
        "# 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n3xH8xv5Hwhz",
        "outputId": "4cb0b35a-e284-4144-93bc-bfeebadb29ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFHg5fGfHyui",
        "outputId": "e4cc5e7d-3c8d-42cc-9192-41c2a05b28a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ai04-level1-project.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  ai04-level1-project.zip\n",
            "replace test_images/1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'wonhu1'\n",
        "os.environ['KAGGLE_KEY'] = 'bc6670ea96ac607125d9b0d289990f91'\n",
        "\n",
        "# Drive 내에서 데이터 다운로드\n",
        "!kaggle competitions download -c ai04-level1-project -p /content/drive/MyDrive/pill_project/\n",
        "!cd /content/drive/MyDrive/pill_project && unzip ai04-level1-project.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC5lLSytH4Zq",
        "outputId": "ee076120-6662-4a05-f32d-2d18b4e4249d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Drive 내 데이터 확인 ===\n",
            "프로젝트 폴더: ['ai04-level1-project.zip', 'pill_dataset', 'test_images', 'train_annotations', 'train_images', 'pill_dataset.yaml', 'yolov8n.pt', 'ensemble_models', 'yolov8s.pt', 'pill_dataset_clean', 'pill_clean.yaml', 'ensemble_clean']\n",
            "train_images: 1489개 이미지\n",
            "train_annotations: 4526개 JSON 파일\n",
            "test_images: 843개 이미지\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Drive 내 데이터 구조 확인\n",
        "drive_base = '/content/drive/MyDrive/pill_project'\n",
        "\n",
        "print(\"=== Drive 내 데이터 확인 ===\")\n",
        "print(f\"프로젝트 폴더: {os.listdir(drive_base)}\")\n",
        "\n",
        "# train_images 확인\n",
        "train_images_dir = os.path.join(drive_base, 'train_images')\n",
        "if os.path.exists(train_images_dir):\n",
        "    image_count = len([f for f in os.listdir(train_images_dir) if f.endswith('.png')])\n",
        "    print(f\"train_images: {image_count}개 이미지\")\n",
        "else:\n",
        "    print(\"train_images 폴더가 없습니다.\")\n",
        "\n",
        "# train_annotations 확인\n",
        "train_annotations_dir = os.path.join(drive_base, 'train_annotations')\n",
        "if os.path.exists(train_annotations_dir):\n",
        "    json_files = []\n",
        "    for root, dirs, files in os.walk(train_annotations_dir):\n",
        "        json_files.extend([f for f in files if f.endswith('.json')])\n",
        "    print(f\"train_annotations: {len(json_files)}개 JSON 파일\")\n",
        "else:\n",
        "    print(\"train_annotations 폴더가 없습니다.\")\n",
        "\n",
        "# test_images 확인\n",
        "test_images_dir = os.path.join(drive_base, 'test_images')\n",
        "if os.path.exists(test_images_dir):\n",
        "    test_count = len([f for f in os.listdir(test_images_dir) if f.endswith('.png')])\n",
        "    print(f\"test_images: {test_count}개 이미지\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "wRfjn0ai93ta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm3iR1yb-7lp",
        "outputId": "1207449d-9bf2-4257-f43a-fcd3f41828a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON 디렉토리 존재: True\n",
            "이미지 디렉토리 존재: True\n",
            "총 4526개의 JSON 파일을 찾았습니다.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "JSON 파일 처리 중: 100%|██████████| 4526/4526 [25:54<00:00,  2.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 이미지: 1489장\n",
            "어노테이션 있는 이미지: 1489장\n",
            "어노테이션 없는 이미지: 0장\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "어노테이션 없는 이미지 처리: 0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 4526개의 데이터를 로드했습니다.\n",
            "- 어노테이션 있음: 4526개\n",
            "- 어노테이션 없음: 0개\n",
            "\n",
            "어노테이션 있는 데이터: 4526개\n",
            "완전한 어노테이션 데이터: 2406개\n",
            "완전한 어노테이션 이미지: 639장\n",
            "불완전한 어노테이션 이미지: 850장\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Drive 경로용 수정된 데이터 로드 함수\n",
        "\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_all_images_and_annotations(json_dir, image_dir):\n",
        "    \"\"\"\n",
        "    모든 이미지를 로드하고, 어노테이션 유무를 구분 (Drive 경로용)\n",
        "    \"\"\"\n",
        "    # 1. JSON 파일에서 어노테이션 데이터 수집\n",
        "    json_files = glob.glob(os.path.join(json_dir, '**', '*.json'), recursive=True)\n",
        "    print(f\"총 {len(json_files)}개의 JSON 파일을 찾았습니다.\")\n",
        "\n",
        "    annotated_data = []\n",
        "    image_info_dict = {}  # 이미지 정보 저장용\n",
        "\n",
        "    for json_file in tqdm(json_files, desc=\"JSON 파일 처리 중\"):\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if not data.get('images'):\n",
        "            continue\n",
        "\n",
        "        image_info = data['images'][0]\n",
        "        image_id = image_info['id']\n",
        "        file_name = image_info['file_name']\n",
        "        image_path = os.path.join(image_dir, file_name)\n",
        "\n",
        "        # 이미지 기본 정보 저장\n",
        "        image_info_dict[file_name] = {\n",
        "            'image_id': image_id,\n",
        "            'image_path': image_path,\n",
        "            'file_name': file_name,\n",
        "            'width': image_info['width'],\n",
        "            'height': image_info['height'],\n",
        "            'dl_name': image_info['dl_name'],\n",
        "            'drug_shape': image_info.get('drug_shape'),\n",
        "            'color_class1': image_info.get('color_class1'),\n",
        "            'line_front': image_info.get('line_front'),\n",
        "        }\n",
        "\n",
        "        # 어노테이션이 있는 경우\n",
        "        if 'annotations' in data and data['annotations']:\n",
        "            for anno in data['annotations']:\n",
        "                if 'bbox' in anno and anno['bbox'] and len(anno['bbox']) == 4:\n",
        "                    annotated_data.append({\n",
        "                        **image_info_dict[file_name],  # 이미지 기본 정보\n",
        "                        'bbox': anno['bbox'],\n",
        "                        'category_id': anno['category_id'],\n",
        "                        'area': anno['area'],\n",
        "                        'has_annotation': True\n",
        "                    })\n",
        "\n",
        "    # 2. 전체 이미지 파일 목록 가져오기\n",
        "    all_image_files = glob.glob(os.path.join(image_dir, '*.png'))\n",
        "    all_image_names = [os.path.basename(f) for f in all_image_files]\n",
        "\n",
        "    # 3. 어노테이션이 없는 이미지들 찾기\n",
        "    annotated_image_names = set(image_info_dict.keys())\n",
        "    unlabeled_image_names = set(all_image_names) - annotated_image_names\n",
        "\n",
        "    print(f\"전체 이미지: {len(all_image_names)}장\")\n",
        "    print(f\"어노테이션 있는 이미지: {len(annotated_image_names)}장\")\n",
        "    print(f\"어노테이션 없는 이미지: {len(unlabeled_image_names)}장\")\n",
        "\n",
        "    # 4. 어노테이션 없는 이미지들도 DataFrame에 추가 (bbox 없이)\n",
        "    unlabeled_data = []\n",
        "    for img_name in tqdm(unlabeled_image_names, desc=\"어노테이션 없는 이미지 처리\"):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        if os.path.exists(img_path):\n",
        "            # 이미지 크기 읽기\n",
        "            img = cv2.imread(img_path)\n",
        "            height, width = img.shape[:2] if img is not None else (640, 640)\n",
        "\n",
        "            unlabeled_data.append({\n",
        "                'image_id': None,  # ID 없음\n",
        "                'image_path': img_path,\n",
        "                'file_name': img_name,\n",
        "                'width': width,\n",
        "                'height': height,\n",
        "                'dl_name': None,  # 약품 이름 없음\n",
        "                'drug_shape': None,\n",
        "                'color_class1': None,\n",
        "                'line_front': None,\n",
        "                'bbox': None,  # bbox 없음\n",
        "                'category_id': None,\n",
        "                'area': None,\n",
        "                'has_annotation': False  # 어노테이션 없음을 표시\n",
        "            })\n",
        "\n",
        "    # 5. 모든 데이터 합치기\n",
        "    all_data = annotated_data + unlabeled_data\n",
        "    df_all = pd.DataFrame(all_data)\n",
        "\n",
        "    print(f\"총 {len(all_data)}개의 데이터를 로드했습니다.\")\n",
        "    print(f\"- 어노테이션 있음: {len(annotated_data)}개\")\n",
        "    print(f\"- 어노테이션 없음: {len(unlabeled_data)}개\")\n",
        "\n",
        "    return df_all\n",
        "\n",
        "# Drive 경로 설정\n",
        "DRIVE_BASE = '/content/drive/MyDrive/pill_project'\n",
        "train_json_dir = os.path.join(DRIVE_BASE, 'train_annotations')\n",
        "train_image_dir = os.path.join(DRIVE_BASE, 'train_images')\n",
        "\n",
        "# 경로 확인\n",
        "print(f\"JSON 디렉토리 존재: {os.path.exists(train_json_dir)}\")\n",
        "print(f\"이미지 디렉토리 존재: {os.path.exists(train_image_dir)}\")\n",
        "\n",
        "# 데이터 로드 실행\n",
        "if os.path.exists(train_json_dir) and os.path.exists(train_image_dir):\n",
        "    df_all = load_all_images_and_annotations(train_json_dir, train_image_dir)\n",
        "\n",
        "    # 어노테이션이 있는 데이터만 추출\n",
        "    df = df_all[df_all['has_annotation'] == True].copy()\n",
        "    print(f\"\\n어노테이션 있는 데이터: {len(df)}개\")\n",
        "\n",
        "    # 완전성 검사를 위한 추가 처리\n",
        "    def get_required_count(file_name):\n",
        "        \"\"\"파일명에서 기대되는 객체 개수를 계산\"\"\"\n",
        "        prefix_part = file_name.split('_')[0]\n",
        "        prefixes_raw = prefix_part.split('-')[1:]\n",
        "        return len(prefixes_raw)\n",
        "\n",
        "    # DataFrame에 required_count 컬럼 추가\n",
        "    df['required_count'] = df['file_name'].apply(get_required_count)\n",
        "\n",
        "    # 이미지별 실제 어노테이션 개수 집계\n",
        "    actual_counts = df.groupby('file_name').size().reset_index(name='actual_count')\n",
        "    df = df.merge(actual_counts, on='file_name')\n",
        "\n",
        "    # 완전한 어노테이션만 필터링\n",
        "    df_complete = df[df['required_count'] == df['actual_count']].copy()\n",
        "\n",
        "    print(f\"완전한 어노테이션 데이터: {len(df_complete)}개\")\n",
        "    print(f\"완전한 어노테이션 이미지: {df_complete['file_name'].nunique()}장\")\n",
        "\n",
        "    # 불완전한 이미지 리스트 생성\n",
        "    incomplete_df = df[df['required_count'] != df['actual_count']]\n",
        "    incomplete_image_list = incomplete_df['file_name'].unique().tolist()\n",
        "    print(f\"불완전한 어노테이션 이미지: {len(incomplete_image_list)}장\")\n",
        "\n",
        "else:\n",
        "    print(\"필요한 디렉토리가 존재하지 않습니다.\")\n",
        "    print(f\"train_annotations: {train_json_dir}\")\n",
        "    print(f\"train_images: {train_image_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9SzeVkQOKyr"
      },
      "outputs": [],
      "source": [
        "# 수정된 데이터 로드 함수 - 모든 이미지 포함\n",
        "def load_all_images_and_annotations(json_dir, image_dir):\n",
        "    \"\"\"\n",
        "    모든 이미지를 로드하고, 어노테이션 유무를 구분\n",
        "    \"\"\"\n",
        "    # 1. JSON 파일에서 어노테이션 데이터 수집\n",
        "    json_files = glob.glob(os.path.join(json_dir, '**', '*.json'), recursive=True)\n",
        "    print(f\"총 {len(json_files)}개의 JSON 파일을 찾았습니다.\")\n",
        "\n",
        "    annotated_data = []\n",
        "    image_info_dict = {}  # 이미지 정보 저장용\n",
        "\n",
        "    for json_file in tqdm(json_files, desc=\"JSON 파일 처리 중\"):\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if not data.get('images'):\n",
        "            continue\n",
        "\n",
        "        image_info = data['images'][0]\n",
        "        image_id = image_info['id']\n",
        "        file_name = image_info['file_name']\n",
        "        image_path = os.path.join(image_dir, file_name)\n",
        "\n",
        "        # 이미지 기본 정보 저장\n",
        "        image_info_dict[file_name] = {\n",
        "            'image_id': image_id,\n",
        "            'image_path': image_path,\n",
        "            'file_name': file_name,\n",
        "            'width': image_info['width'],\n",
        "            'height': image_info['height'],\n",
        "            'dl_name': image_info['dl_name'],\n",
        "            'drug_shape': image_info.get('drug_shape'),\n",
        "            'color_class1': image_info.get('color_class1'),\n",
        "            'line_front': image_info.get('line_front'),\n",
        "        }\n",
        "\n",
        "        # 어노테이션이 있는 경우\n",
        "        if 'annotations' in data and data['annotations']:\n",
        "            for anno in data['annotations']:\n",
        "                if 'bbox' in anno and anno['bbox'] and len(anno['bbox']) == 4:\n",
        "                    annotated_data.append({\n",
        "                        **image_info_dict[file_name],  # 이미지 기본 정보\n",
        "                        'bbox': anno['bbox'],\n",
        "                        'category_id': anno['category_id'],\n",
        "                        'area': anno['area'],\n",
        "                        'has_annotation': True\n",
        "                    })\n",
        "\n",
        "    # 2. 전체 이미지 파일 목록 가져오기\n",
        "    all_image_files = glob.glob(os.path.join(image_dir, '*.png'))\n",
        "    all_image_names = [os.path.basename(f) for f in all_image_files]\n",
        "\n",
        "    # 3. 어노테이션이 없는 이미지들 찾기\n",
        "    annotated_image_names = set(image_info_dict.keys())\n",
        "    unlabeled_image_names = set(all_image_names) - annotated_image_names\n",
        "\n",
        "    print(f\"전체 이미지: {len(all_image_names)}장\")\n",
        "    print(f\"어노테이션 있는 이미지: {len(annotated_image_names)}장\")\n",
        "    print(f\"어노테이션 없는 이미지: {len(unlabeled_image_names)}장\")\n",
        "\n",
        "    # 4. 어노테이션 없는 이미지들도 DataFrame에 추가 (bbox 없이)\n",
        "    unlabeled_data = []\n",
        "    for img_name in tqdm(unlabeled_image_names, desc=\"어노테이션 없는 이미지 처리\"):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        if os.path.exists(img_path):\n",
        "            # 이미지 크기 읽기\n",
        "            img = cv2.imread(img_path)\n",
        "            height, width = img.shape[:2] if img is not None else (640, 640)\n",
        "\n",
        "            unlabeled_data.append({\n",
        "                'image_id': None,  # ID 없음\n",
        "                'image_path': img_path,\n",
        "                'file_name': img_name,\n",
        "                'width': width,\n",
        "                'height': height,\n",
        "                'dl_name': None,  # 약품 이름 없음\n",
        "                'drug_shape': None,\n",
        "                'color_class1': None,\n",
        "                'line_front': None,\n",
        "                'bbox': None,  # bbox 없음\n",
        "                'category_id': None,\n",
        "                'area': None,\n",
        "                'has_annotation': False  # 어노테이션 없음을 표시\n",
        "            })\n",
        "\n",
        "    # 5. 모든 데이터 합치기\n",
        "    all_data = annotated_data + unlabeled_data\n",
        "    df_all = pd.DataFrame(all_data)\n",
        "\n",
        "    print(f\"총 {len(all_data)}개의 데이터를 로드했습니다.\")\n",
        "    print(f\"- 어노테이션 있음: {len(annotated_data)}개\")\n",
        "    print(f\"- 어노테이션 없음: {len(unlabeled_data)}개\")\n",
        "\n",
        "    return df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqo5Q7hpLiCZ",
        "outputId": "8b06a37c-43c1-4697-e79f-9c25c5437d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON 디렉토리: /content/drive/MyDrive/pill_project/train_annotations\n",
            "이미지 디렉토리: /content/drive/MyDrive/pill_project/train_images\n",
            "JSON 디렉토리 존재: True\n",
            "이미지 디렉토리 존재: True\n",
            "총 4526개의 JSON 파일을 찾았습니다.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "JSON 파일 처리 중: 100%|██████████| 4526/4526 [00:15<00:00, 287.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 이미지: 1489장\n",
            "어노테이션 있는 이미지: 1489장\n",
            "어노테이션 없는 이미지: 0장\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "어노테이션 없는 이미지 처리: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 4526개의 데이터를 로드했습니다.\n",
            "- 어노테이션 있음: 4526개\n",
            "- 어노테이션 없음: 0개\n",
            "\n",
            "=== 어노테이션 있는 데이터로 완전성 검사 시작 ===\n",
            "어노테이션 데이터: 4526개\n",
            "파일명에서 기대 객체 수 계산 중...\n",
            "이미지별 실제 어노테이션 개수 집계 중...\n",
            "\n",
            "=== 어노테이션 완전성 분석 ===\n",
            "전체 이미지 수: 1489장\n",
            "완전한 어노테이션 이미지: 639장 (42.9%)\n",
            "불완전한 어노테이션 이미지: 850장 (57.1%)\n",
            "\n",
            "=== 데이터 필터링 결과 ===\n",
            "원본 어노테이션 데이터: 4526개\n",
            "완전한 어노테이션 데이터: 2406개\n",
            "제거된 데이터: 2120개\n",
            "\n",
            "=== 불완전한 어노테이션 분석 ===\n",
            "기대 vs 실제 어노테이션 개수 분포:\n",
            "  기대 3개 -> 실제 1개: 36장 이미지\n",
            "  기대 3개 -> 실제 2개: 108장 이미지\n",
            "  기대 4개 -> 실제 1개: 28장 이미지\n",
            "  기대 4개 -> 실제 2개: 194장 이미지\n",
            "  기대 4개 -> 실제 3개: 484장 이미지\n",
            "\n",
            "불완전한 어노테이션 예시 (상위 5개):\n",
            "                                           file_name  required_count  \\\n",
            "0  K-001900-010224-016551-031705_0_2_0_2_70_000_2...               4   \n",
            "1  K-001900-010224-016551-031705_0_2_0_2_75_000_2...               4   \n",
            "2  K-001900-010224-016551-031705_0_2_0_2_90_000_2...               4   \n",
            "3  K-001900-010224-016551-033009_0_2_0_2_70_000_2...               4   \n",
            "4  K-001900-010224-016551-033009_0_2_0_2_75_000_2...               4   \n",
            "\n",
            "   actual_count  \n",
            "0             3  \n",
            "1             2  \n",
            "2             3  \n",
            "3             2  \n",
            "4             2  \n",
            "\n",
            "=== 완전한 어노테이션 데이터의 클래스 분포 ===\n",
            "고유한 약품 클래스 수: 73\n",
            "\n",
            "상위 10개 클래스:\n",
            "dl_name\n",
            "기넥신에프정(은행엽엑스)(수출용)    255\n",
            "일양하이트린정 2mg           150\n",
            "보령부스파정 5mg             97\n",
            "뮤테란캡슐 100mg            88\n",
            "가바토파정 100mg            82\n",
            "아토젯정 10/40mg           72\n",
            "동아가바펜틴정 800mg          64\n",
            "크레스토정 20mg             59\n",
            "리바로정 4mg               59\n",
            "트윈스타정 40/5mg           55\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== 클래스별 이미지 수 ===\n",
            "상위 10개 클래스별 이미지 수:\n",
            "dl_name\n",
            "기넥신에프정(은행엽엑스)(수출용)    255\n",
            "일양하이트린정 2mg           150\n",
            "보령부스파정 5mg             97\n",
            "뮤테란캡슐 100mg            88\n",
            "가바토파정 100mg            82\n",
            "아토젯정 10/40mg           72\n",
            "동아가바펜틴정 800mg          64\n",
            "크레스토정 20mg             59\n",
            "리바로정 4mg               59\n",
            "트윈스타정 40/5mg           55\n",
            "Name: file_name, dtype: int64\n",
            "\n",
            "=== 최종 데이터셋 정보 ===\n",
            "사용 가능한 완전한 어노테이션 데이터: 2406개\n",
            "고유 이미지 수: 639장\n",
            "평균 객체 수/이미지: 3.77개\n",
            "\n",
            "=== 완전한 어노테이션 데이터 샘플 ===\n",
            "                                            file_name         dl_name  \\\n",
            "15  K-001900-016548-018110-021026_0_2_0_2_70_000_2...      보령부스파정 5mg   \n",
            "17  K-001900-016548-018110-021026_0_2_0_2_75_000_2...      보령부스파정 5mg   \n",
            "19  K-001900-016548-018110-021026_0_2_0_2_70_000_2...     가바토파정 100mg   \n",
            "20  K-001900-016548-018110-021026_0_2_0_2_75_000_2...     가바토파정 100mg   \n",
            "21  K-001900-016548-018110-021026_0_2_0_2_70_000_2...  란스톤엘에프디티정 30mg   \n",
            "\n",
            "    required_count  actual_count                  bbox  \n",
            "15               4             4  [173, 279, 201, 141]  \n",
            "17               4             4  [596, 854, 212, 148]  \n",
            "19               4             4  [140, 866, 240, 240]  \n",
            "20               4             4  [579, 158, 232, 224]  \n",
            "21               4             4  [628, 845, 323, 306]  \n",
            "\n",
            "=== 수도 라벨링 대상 ===\n",
            "불완전한 어노테이션을 가진 이미지: 850장\n",
            "이 이미지들을 수도 라벨링으로 보완할 수 있습니다.\n",
            "\n",
            "=== 변수 저장 완료 ===\n",
            "df_complete: 2406개 데이터\n",
            "incomplete_image_list: 850장 이미지\n",
            "Drive 기반 데이터 처리 완료!\n"
          ]
        }
      ],
      "source": [
        "# Drive 경로용 완전한 데이터 처리 코드\n",
        "\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Drive 경로 설정\n",
        "DRIVE_BASE = '/content/drive/MyDrive/pill_project'\n",
        "\n",
        "# 수정된 데이터 로드 함수 - 모든 이미지 포함\n",
        "def load_all_images_and_annotations(json_dir, image_dir):\n",
        "    \"\"\"\n",
        "    모든 이미지를 로드하고, 어노테이션 유무를 구분\n",
        "    \"\"\"\n",
        "    # 1. JSON 파일에서 어노테이션 데이터 수집\n",
        "    json_files = glob.glob(os.path.join(json_dir, '**', '*.json'), recursive=True)\n",
        "    print(f\"총 {len(json_files)}개의 JSON 파일을 찾았습니다.\")\n",
        "\n",
        "    annotated_data = []\n",
        "    image_info_dict = {}  # 이미지 정보 저장용\n",
        "\n",
        "    for json_file in tqdm(json_files, desc=\"JSON 파일 처리 중\"):\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if not data.get('images'):\n",
        "            continue\n",
        "\n",
        "        image_info = data['images'][0]\n",
        "        image_id = image_info['id']\n",
        "        file_name = image_info['file_name']\n",
        "        image_path = os.path.join(image_dir, file_name)\n",
        "\n",
        "        # 이미지 기본 정보 저장\n",
        "        image_info_dict[file_name] = {\n",
        "            'image_id': image_id,\n",
        "            'image_path': image_path,\n",
        "            'file_name': file_name,\n",
        "            'width': image_info['width'],\n",
        "            'height': image_info['height'],\n",
        "            'dl_name': image_info['dl_name'],\n",
        "            'drug_shape': image_info.get('drug_shape'),\n",
        "            'color_class1': image_info.get('color_class1'),\n",
        "            'line_front': image_info.get('line_front'),\n",
        "        }\n",
        "\n",
        "        # 어노테이션이 있는 경우\n",
        "        if 'annotations' in data and data['annotations']:\n",
        "            for anno in data['annotations']:\n",
        "                if 'bbox' in anno and anno['bbox'] and len(anno['bbox']) == 4:\n",
        "                    annotated_data.append({\n",
        "                        **image_info_dict[file_name],  # 이미지 기본 정보\n",
        "                        'bbox': anno['bbox'],\n",
        "                        'category_id': anno['category_id'],\n",
        "                        'area': anno['area'],\n",
        "                        'has_annotation': True\n",
        "                    })\n",
        "\n",
        "    # 2. 전체 이미지 파일 목록 가져오기\n",
        "    all_image_files = glob.glob(os.path.join(image_dir, '*.png'))\n",
        "    all_image_names = [os.path.basename(f) for f in all_image_files]\n",
        "\n",
        "    # 3. 어노테이션이 없는 이미지들 찾기\n",
        "    annotated_image_names = set(image_info_dict.keys())\n",
        "    unlabeled_image_names = set(all_image_names) - annotated_image_names\n",
        "\n",
        "    print(f\"전체 이미지: {len(all_image_names)}장\")\n",
        "    print(f\"어노테이션 있는 이미지: {len(annotated_image_names)}장\")\n",
        "    print(f\"어노테이션 없는 이미지: {len(unlabeled_image_names)}장\")\n",
        "\n",
        "    # 4. 어노테이션 없는 이미지들도 DataFrame에 추가 (bbox 없이)\n",
        "    unlabeled_data = []\n",
        "    for img_name in tqdm(unlabeled_image_names, desc=\"어노테이션 없는 이미지 처리\"):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        if os.path.exists(img_path):\n",
        "            # 이미지 크기 읽기\n",
        "            img = cv2.imread(img_path)\n",
        "            height, width = img.shape[:2] if img is not None else (640, 640)\n",
        "\n",
        "            unlabeled_data.append({\n",
        "                'image_id': None,  # ID 없음\n",
        "                'image_path': img_path,\n",
        "                'file_name': img_name,\n",
        "                'width': width,\n",
        "                'height': height,\n",
        "                'dl_name': None,  # 약품 이름 없음\n",
        "                'drug_shape': None,\n",
        "                'color_class1': None,\n",
        "                'line_front': None,\n",
        "                'bbox': None,  # bbox 없음\n",
        "                'category_id': None,\n",
        "                'area': None,\n",
        "                'has_annotation': False  # 어노테이션 없음을 표시\n",
        "            })\n",
        "\n",
        "    # 5. 모든 데이터 합치기\n",
        "    all_data = annotated_data + unlabeled_data\n",
        "    df_all = pd.DataFrame(all_data)\n",
        "\n",
        "    print(f\"총 {len(all_data)}개의 데이터를 로드했습니다.\")\n",
        "    print(f\"- 어노테이션 있음: {len(annotated_data)}개\")\n",
        "    print(f\"- 어노테이션 없음: {len(unlabeled_data)}개\")\n",
        "\n",
        "    return df_all\n",
        "\n",
        "# Drive 기반 데이터 로드\n",
        "train_json_dir = os.path.join(DRIVE_BASE, 'train_annotations')\n",
        "train_image_dir = os.path.join(DRIVE_BASE, 'train_images')\n",
        "\n",
        "print(f\"JSON 디렉토리: {train_json_dir}\")\n",
        "print(f\"이미지 디렉토리: {train_image_dir}\")\n",
        "print(f\"JSON 디렉토리 존재: {os.path.exists(train_json_dir)}\")\n",
        "print(f\"이미지 디렉토리 존재: {os.path.exists(train_image_dir)}\")\n",
        "\n",
        "# 데이터 로드 실행\n",
        "df_all = load_all_images_and_annotations(train_json_dir, train_image_dir)\n",
        "\n",
        "# 어노테이션이 있는 데이터만 추출 (이후 완전성 검사를 위해)\n",
        "df = df_all[df_all['has_annotation'] == True].copy()\n",
        "\n",
        "print(f\"\\n=== 어노테이션 있는 데이터로 완전성 검사 시작 ===\")\n",
        "print(f\"어노테이션 데이터: {len(df)}개\")\n",
        "\n",
        "# 어노테이션 누락 데이터 전처리\n",
        "\n",
        "# 이미지별 required_count 계산 함수\n",
        "def get_required_count(file_name):\n",
        "    \"\"\"\n",
        "    파일명에서 기대되는 객체 개수를 계산\n",
        "    예: K-001900-010224-016551-031705_... -> 4개 객체 기대\n",
        "    \"\"\"\n",
        "    prefix_part = file_name.split('_')[0]  # \"K-001900-010224-016551-031705\"\n",
        "    prefixes_raw = prefix_part.split('-')[1:]   # ['001900', '010224', '016551', '031705']\n",
        "    return len(prefixes_raw)\n",
        "\n",
        "# DataFrame에 required_count 컬럼 추가\n",
        "print(\"파일명에서 기대 객체 수 계산 중...\")\n",
        "df['required_count'] = df['file_name'].apply(get_required_count)\n",
        "\n",
        "# 이미지별 실제 어노테이션 개수 집계\n",
        "print(\"이미지별 실제 어노테이션 개수 집계 중...\")\n",
        "actual_counts = df.groupby('file_name').size().reset_index(name='actual_count')\n",
        "\n",
        "# df와 merge\n",
        "df = df.merge(actual_counts, on='file_name')\n",
        "\n",
        "# 완전성 분석\n",
        "print(\"\\n=== 어노테이션 완전성 분석 ===\")\n",
        "complete_images = df[df['required_count'] == df['actual_count']]['file_name'].nunique()\n",
        "incomplete_images = df[df['required_count'] != df['actual_count']]['file_name'].nunique()\n",
        "total_images = df['file_name'].nunique()\n",
        "\n",
        "print(f\"전체 이미지 수: {total_images}장\")\n",
        "print(f\"완전한 어노테이션 이미지: {complete_images}장 ({complete_images/total_images*100:.1f}%)\")\n",
        "print(f\"불완전한 어노테이션 이미지: {incomplete_images}장 ({incomplete_images/total_images*100:.1f}%)\")\n",
        "\n",
        "# required_count == actual_count인 경우만 필터링\n",
        "df_complete = df[df['required_count'] == df['actual_count']].copy()\n",
        "\n",
        "print(f\"\\n=== 데이터 필터링 결과 ===\")\n",
        "print(f\"원본 어노테이션 데이터: {len(df)}개\")\n",
        "print(f\"완전한 어노테이션 데이터: {len(df_complete)}개\")\n",
        "print(f\"제거된 데이터: {len(df) - len(df_complete)}개\")\n",
        "\n",
        "# 불완전한 데이터 분석\n",
        "if incomplete_images > 0:\n",
        "    print(\"\\n=== 불완전한 어노테이션 분석 ===\")\n",
        "    incomplete_analysis = df[df['required_count'] != df['actual_count']].groupby(['file_name', 'required_count', 'actual_count']).size().reset_index(name='count')\n",
        "    incomplete_summary = incomplete_analysis.groupby(['required_count', 'actual_count']).size().reset_index(name='image_count')\n",
        "\n",
        "    print(\"기대 vs 실제 어노테이션 개수 분포:\")\n",
        "    for _, row in incomplete_summary.iterrows():\n",
        "        print(f\"  기대 {row['required_count']}개 -> 실제 {row['actual_count']}개: {row['image_count']}장 이미지\")\n",
        "\n",
        "    # 샘플 출력 (에러 수정)\n",
        "    print(\"\\n불완전한 어노테이션 예시 (상위 5개):\")\n",
        "    sample_incomplete = df[df['required_count'] != df['actual_count']].groupby('file_name').first().head()\n",
        "    sample_incomplete = sample_incomplete.reset_index()  # 인덱스 리셋하여 file_name을 컬럼으로 복원\n",
        "    print(sample_incomplete[['file_name', 'required_count', 'actual_count']])\n",
        "\n",
        "# 완전한 데이터의 클래스 분포 확인\n",
        "if len(df_complete) > 0:\n",
        "    print(\"\\n=== 완전한 어노테이션 데이터의 클래스 분포 ===\")\n",
        "    class_counts_complete = df_complete['dl_name'].value_counts()\n",
        "    print(f\"고유한 약품 클래스 수: {len(class_counts_complete)}\")\n",
        "    print(\"\\n상위 10개 클래스:\")\n",
        "    print(class_counts_complete.head(10))\n",
        "\n",
        "    # 클래스별 이미지 수도 확인\n",
        "    print(\"\\n=== 클래스별 이미지 수 ===\")\n",
        "    images_per_class = df_complete.groupby('dl_name')['file_name'].nunique().sort_values(ascending=False)\n",
        "    print(\"상위 10개 클래스별 이미지 수:\")\n",
        "    print(images_per_class.head(10))\n",
        "\n",
        "# 최종 데이터셋 정보\n",
        "print(\"\\n=== 최종 데이터셋 정보 ===\")\n",
        "print(f\"사용 가능한 완전한 어노테이션 데이터: {len(df_complete)}개\")\n",
        "print(f\"고유 이미지 수: {df_complete['file_name'].nunique()}장\")\n",
        "print(f\"평균 객체 수/이미지: {len(df_complete)/df_complete['file_name'].nunique():.2f}개\")\n",
        "\n",
        "# 샘플 데이터 확인\n",
        "print(\"\\n=== 완전한 어노테이션 데이터 샘플 ===\")\n",
        "print(df_complete[['file_name', 'dl_name', 'required_count', 'actual_count', 'bbox']].head())\n",
        "\n",
        "# 불완전한 데이터를 수도 라벨링 대상으로 분리\n",
        "if incomplete_images > 0:\n",
        "    df_incomplete = df[df['required_count'] != df['actual_count']].copy()\n",
        "    incomplete_image_list = df_incomplete['file_name'].unique()\n",
        "\n",
        "    print(f\"\\n=== 수도 라벨링 대상 ===\")\n",
        "    print(f\"불완전한 어노테이션을 가진 이미지: {len(incomplete_image_list)}장\")\n",
        "    print(\"이 이미지들을 수도 라벨링으로 보완할 수 있습니다.\")\n",
        "else:\n",
        "    print(\"\\n모든 이미지가 완전한 어노테이션을 가지고 있습니다.\")\n",
        "    incomplete_image_list = []\n",
        "\n",
        "# 결과 반환용 변수들 (전역 변수로 저장)\n",
        "globals()['df_complete'] = df_complete\n",
        "globals()['incomplete_image_list'] = incomplete_image_list\n",
        "if incomplete_images > 0:\n",
        "    globals()['df_incomplete'] = df_incomplete\n",
        "\n",
        "print(f\"\\n=== 변수 저장 완료 ===\")\n",
        "print(f\"df_complete: {len(df_complete)}개 데이터\")\n",
        "print(f\"incomplete_image_list: {len(incomplete_image_list)}장 이미지\")\n",
        "print(\"Drive 기반 데이터 처리 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfNud7HvAp5T"
      },
      "source": [
        "# TTA, 앙상블 해보기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "waFBarhe9hP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "k0N5HcFYAwgo",
        "outputId": "560780db-976c-4011-9742-1f602aa1f3d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_complete' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3195888270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# 클래스 매핑 (기존 df_complete 사용)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_complete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dl_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0midx_to_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_complete' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Drive 경로 설정\n",
        "DRIVE_BASE = '/content/drive/MyDrive/pill_project'\n",
        "\n",
        "# 완전한 어노테이션 데이터만 사용하여 YOLO 데이터셋 생성\n",
        "def create_clean_yolo_dataset(df_complete, output_dir, class_to_idx):\n",
        "    \"\"\"완전한 어노테이션만으로 깨끗한 데이터셋 생성\"\"\"\n",
        "    print(f\"완전한 어노테이션 데이터로 데이터셋 생성: {len(df_complete)}개\")\n",
        "\n",
        "    # 디렉토리 생성\n",
        "    for subset in ['train', 'val']:\n",
        "        os.makedirs(os.path.join(output_dir, subset, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, subset, 'labels'), exist_ok=True)\n",
        "\n",
        "    # 이미지별로 그룹화\n",
        "    unique_images = df_complete['file_name'].unique()\n",
        "    train_images, val_images = train_test_split(unique_images, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Train: {len(train_images)}장, Val: {len(val_images)}장\")\n",
        "\n",
        "    # Train 데이터 처리\n",
        "    for file_name in tqdm(train_images, desc=\"Train 데이터 생성\"):\n",
        "        img_annotations = df_complete[df_complete['file_name'] == file_name]\n",
        "\n",
        "        # 이미지 복사\n",
        "        src_path = img_annotations.iloc[0]['image_path']\n",
        "        dst_path = os.path.join(output_dir, 'train', 'images', file_name)\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "\n",
        "        # 라벨 파일 생성\n",
        "        label_path = os.path.join(output_dir, 'train', 'labels',\n",
        "                                  os.path.splitext(file_name)[0] + '.txt')\n",
        "        with open(label_path, 'w') as f:\n",
        "            for _, row in img_annotations.iterrows():\n",
        "                class_id = class_to_idx[row['dl_name']]\n",
        "                bbox = row['bbox']\n",
        "\n",
        "                # YOLO 형식 변환\n",
        "                x_center = (bbox[0] + bbox[2] / 2) / row['width']\n",
        "                y_center = (bbox[1] + bbox[3] / 2) / row['height']\n",
        "                width = bbox[2] / row['width']\n",
        "                height = bbox[3] / row['height']\n",
        "\n",
        "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    # Val 데이터 처리\n",
        "    for file_name in tqdm(val_images, desc=\"Val 데이터 생성\"):\n",
        "        img_annotations = df_complete[df_complete['file_name'] == file_name]\n",
        "\n",
        "        src_path = img_annotations.iloc[0]['image_path']\n",
        "        dst_path = os.path.join(output_dir, 'val', 'images', file_name)\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "\n",
        "        label_path = os.path.join(output_dir, 'val', 'labels',\n",
        "                                  os.path.splitext(file_name)[0] + '.txt')\n",
        "        with open(label_path, 'w') as f:\n",
        "            for _, row in img_annotations.iterrows():\n",
        "                class_id = class_to_idx[row['dl_name']]\n",
        "                bbox = row['bbox']\n",
        "\n",
        "                x_center = (bbox[0] + bbox[2] / 2) / row['width']\n",
        "                y_center = (bbox[1] + bbox[3] / 2) / row['height']\n",
        "                width = bbox[2] / row['width']\n",
        "                height = bbox[3] / row['height']\n",
        "\n",
        "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    print(\"데이터셋 생성 완료\")\n",
        "\n",
        "# 클래스 매핑 (기존 df_complete 사용)\n",
        "class_names = sorted(df_complete['dl_name'].unique())\n",
        "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "idx_to_class = {i: name for i, name in enumerate(class_names)}\n",
        "\n",
        "# 깨끗한 데이터셋 생성\n",
        "clean_dataset_dir = os.path.join(DRIVE_BASE, 'pill_dataset_clean')\n",
        "create_clean_yolo_dataset(df_complete, clean_dataset_dir, class_to_idx)\n",
        "\n",
        "# YAML 파일 생성\n",
        "dataset_info = {\n",
        "    'path': clean_dataset_dir,\n",
        "    'train': 'train/images',\n",
        "    'val': 'val/images',\n",
        "    'names': idx_to_class\n",
        "}\n",
        "\n",
        "yaml_path = os.path.join(DRIVE_BASE, 'pill_clean.yaml')\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(dataset_info, f)\n",
        "\n",
        "print(f\"YAML 파일 생성: {yaml_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "_lYWLCc39p4M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "tv47q87dAzHS",
        "outputId": "45f1de9e-bff6-48f3-88ce-89ee038a9644"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DRIVE_BASE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2885647472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# 앙상블 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mensemble_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDRIVE_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ensemble_clean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mensemble_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ensemble_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DRIVE_BASE' is not defined"
          ]
        }
      ],
      "source": [
        "# 앙상블을 위한 다양한 모델 학습\n",
        "def train_ensemble_models(yaml_path, output_dir, num_models=3):\n",
        "    \"\"\"다양한 설정으로 여러 모델 학습\"\"\"\n",
        "    models_info = []\n",
        "\n",
        "    print(f\"\\n=== {num_models}개 앙상블 모델 학습 시작 ===\\n\")\n",
        "\n",
        "    # 모델 1: YOLOv8n (기본 설정)\n",
        "    print(\"모델 1/3: YOLOv8n 기본 설정\")\n",
        "    model1 = YOLO('yolov8n.pt')\n",
        "    model1.train(\n",
        "        data=yaml_path,\n",
        "        epochs=30,\n",
        "        batch=16,\n",
        "        imgsz=640,\n",
        "        seed=42,\n",
        "        project=output_dir,\n",
        "        name='ensemble_model1',\n",
        "        verbose=True,\n",
        "        patience=10\n",
        "    )\n",
        "    models_info.append(os.path.join(output_dir, 'ensemble_model1/weights/best.pt'))\n",
        "\n",
        "    # 모델 2: YOLOv8s (더 큰 모델)\n",
        "    print(\"\\n모델 2/3: YOLOv8s\")\n",
        "    model2 = YOLO('yolov8s.pt')\n",
        "    model2.train(\n",
        "        data=yaml_path,\n",
        "        epochs=30,\n",
        "        batch=12,\n",
        "        imgsz=640,\n",
        "        seed=123,\n",
        "        project=output_dir,\n",
        "        name='ensemble_model2',\n",
        "        verbose=True,\n",
        "        patience=10\n",
        "    )\n",
        "    models_info.append(os.path.join(output_dir, 'ensemble_model2/weights/best.pt'))\n",
        "\n",
        "    # 모델 3: YOLOv8n (다른 seed + augmentation)\n",
        "    print(\"\\n모델 3/3: YOLOv8n 강한 증강\")\n",
        "    model3 = YOLO('yolov8n.pt')\n",
        "    model3.train(\n",
        "        data=yaml_path,\n",
        "        epochs=30,\n",
        "        batch=16,\n",
        "        imgsz=640,\n",
        "        seed=456,\n",
        "        hsv_h=0.02,\n",
        "        hsv_s=0.7,\n",
        "        hsv_v=0.4,\n",
        "        degrees=10,\n",
        "        translate=0.1,\n",
        "        scale=0.5,\n",
        "        flipud=0.5,\n",
        "        mosaic=1.0,\n",
        "        project=output_dir,\n",
        "        name='ensemble_model3',\n",
        "        verbose=True,\n",
        "        patience=10\n",
        "    )\n",
        "    models_info.append(os.path.join(output_dir, 'ensemble_model3/weights/best.pt'))\n",
        "\n",
        "    print(f\"\\n앙상블 모델 학습 완료: {len(models_info)}개\")\n",
        "    return models_info\n",
        "\n",
        "# 앙상블 모델 학습\n",
        "ensemble_dir = os.path.join(DRIVE_BASE, 'ensemble_clean')\n",
        "ensemble_models = train_ensemble_models(yaml_path, ensemble_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 정의\n",
        "yaml_path = '/content/drive/MyDrive/pill_project/pill_dataset.yaml'\n",
        "ensemble_dir = '/content/drive/MyDrive/pill_project/ensemble_clean'\n",
        "\n",
        "# 모델 3: CPU로 학습 (설정 축소)\n",
        "print(\"모델 3: YOLOv8n 강한 증강 (CPU)\")\n",
        "model3 = YOLO('yolov8n.pt')\n",
        "model3.train(\n",
        "    data=yaml_path,\n",
        "    epochs=15,  # 30 → 15 (시간 단축)\n",
        "    batch=8,    # 16 → 8 (메모리 절약)\n",
        "    imgsz=640,\n",
        "    seed=456,\n",
        "    device='cpu',  # CPU 명시\n",
        "    workers=2,     # worker 수 줄이기\n",
        "    hsv_h=0.02,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    degrees=10,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    flipud=0.5,\n",
        "    mosaic=1.0,\n",
        "    project=ensemble_dir,\n",
        "    name='ensemble_model3',\n",
        "    verbose=True,\n",
        "    patience=10\n",
        ")\n",
        "\n",
        "model3_path = os.path.join(ensemble_dir, 'ensemble_model3/weights/best.pt')\n",
        "print(f\"모델3 학습 완료: {model3_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-kxBK7Jab6y",
        "outputId": "b41a9e89-51a6-43ea-d590-7318be66ffc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 3: YOLOv8n 강한 증강 (CPU)\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 16.5MB/s 0.4s\n",
            "Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (AMD EPYC 7B12)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/pill_project/pill_dataset.yaml, degrees=10, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=ensemble_model34, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/pill_project/ensemble_clean, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=456, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf': 100% ━━━━━━━━━━━━ 22.2MB 35.7MB/s 0.6s\n",
            "Overriding model.yaml nc=80 with nc=73\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    837205  ultralytics.nn.modules.head.Detect           [73, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,096,741 parameters, 3,096,725 gradients, 8.6 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.7±0.2 ms, read: 3.5±0.2 MB/s, size: 1802.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/train/labels.cache... 534 images, 0 backgrounds, 1 corrupt: 100% ━━━━━━━━━━━━ 534/534 726.5Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/pill_project/pill_dataset/train/images/K-003351-016262-018357_0_2_0_2_75_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.8878]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.7±0.4 ms, read: 73.9±159.3 MB/s, size: 1783.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/val/labels.cache... 151 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 151/151 215.6Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00013, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 3.3MB/s 0.2s\n",
            "\u001b[K       1/15         0G      1.447       4.79      1.381         40        640: 100% ━━━━━━━━━━━━ 67/67 0.1it/s 10:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.2it/s 51.4s\n",
            "                   all        151        560          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15         0G     0.8102      4.304      1.035         41        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 13.1s\n",
            "                   all        151        560      0.707     0.0686     0.0926     0.0661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15         0G      0.813      3.811      1.057         27        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.8s\n",
            "                   all        151        560      0.706      0.125      0.135      0.102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15         0G     0.8095      3.385      1.086         35        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.8s\n",
            "                   all        151        560      0.855      0.121      0.167      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15         0G     0.7674      3.069      1.082         31        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.8s\n",
            "                   all        151        560      0.725      0.191      0.224      0.166\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15         0G     0.6436      2.623       1.03         18        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.8s\n",
            "                   all        151        560      0.654      0.276       0.34      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15         0G     0.6096      2.396      1.005         19        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.7it/s 13.7s\n",
            "                   all        151        560      0.705      0.342      0.416      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/15         0G     0.5892      2.161     0.9993         18        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.9s\n",
            "                   all        151        560      0.637      0.418      0.509      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/15         0G     0.5836      2.022      1.006         19        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.8s\n",
            "                   all        151        560       0.91      0.358      0.576       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/15         0G     0.5649      1.869      1.001         19        640: 100% ━━━━━━━━━━━━ 67/67 0.6it/s 2:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.9s\n",
            "                   all        151        560      0.776      0.464      0.616      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/15         0G     0.5544      1.775     0.9925         18        640: 100% ━━━━━━━━━━━━ 67/67 0.6it/s 2:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.5s\n",
            "                   all        151        560      0.609      0.609      0.652      0.584\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/15         0G     0.5326      1.671     0.9767         20        640: 100% ━━━━━━━━━━━━ 67/67 0.6it/s 2:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 13.1s\n",
            "                   all        151        560      0.681      0.616      0.681      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/15         0G     0.5324      1.611     0.9848         19        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.7it/s 13.9s\n",
            "                   all        151        560      0.648      0.672      0.693      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/15         0G     0.5267      1.592     0.9565         20        640: 100% ━━━━━━━━━━━━ 67/67 0.5it/s 2:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.9s\n",
            "                   all        151        560      0.661      0.646      0.698      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/15         0G     0.5213      1.577      0.977         20        640: 100% ━━━━━━━━━━━━ 67/67 0.6it/s 2:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.5s\n",
            "                   all        151        560      0.649       0.68      0.705      0.635\n",
            "\n",
            "15 epochs completed in 0.732 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34/weights/last.pt, 6.4MB\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34/weights/best.pt, 6.4MB\n",
            "\n",
            "Validating /content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34/weights/best.pt...\n",
            "Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (AMD EPYC 7B12)\n",
            "Model summary (fused): 72 layers, 3,091,487 parameters, 0 gradients, 8.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 0.8it/s 12.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48148 (\\N{HANGUL SYLLABLE BA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53664 (\\N{HANGUL SYLLABLE TO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54028 (\\N{HANGUL SYLLABLE PA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44544 (\\N{HANGUL SYLLABLE GEUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50500 (\\N{HANGUL SYLLABLE A}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48124 (\\N{HANGUL SYLLABLE MIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51656 (\\N{HANGUL SYLLABLE JIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52897 (\\N{HANGUL SYLLABLE KAEB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49808 (\\N{HANGUL SYLLABLE SYUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54004 (\\N{HANGUL SYLLABLE TIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53084 (\\N{HANGUL SYLLABLE KOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47536 (\\N{HANGUL SYLLABLE RIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50508 (\\N{HANGUL SYLLABLE AL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49464 (\\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47112 (\\N{HANGUL SYLLABLE RE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53944 (\\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45349 (\\N{HANGUL SYLLABLE NEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49888 (\\N{HANGUL SYLLABLE SIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50640 (\\N{HANGUL SYLLABLE E}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54532 (\\N{HANGUL SYLLABLE PEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51008 (\\N{HANGUL SYLLABLE EUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54665 (\\N{HANGUL SYLLABLE HAENG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50685 (\\N{HANGUL SYLLABLE YEOB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50641 (\\N{HANGUL SYLLABLE EG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49828 (\\N{HANGUL SYLLABLE SEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52636 (\\N{HANGUL SYLLABLE CUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50857 (\\N{HANGUL SYLLABLE YONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45209 (\\N{HANGUL SYLLABLE NAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49548 (\\N{HANGUL SYLLABLE SO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51320 (\\N{HANGUL SYLLABLE JOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45432 (\\N{HANGUL SYLLABLE NO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53356 (\\N{HANGUL SYLLABLE KEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45440 (\\N{HANGUL SYLLABLE NOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53581 (\\N{HANGUL SYLLABLE TEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45684 (\\N{HANGUL SYLLABLE NYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47700 (\\N{HANGUL SYLLABLE ME}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46300 (\\N{HANGUL SYLLABLE DEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50725 (\\N{HANGUL SYLLABLE OG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46972 (\\N{HANGUL SYLLABLE RA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53456 (\\N{HANGUL SYLLABLE TAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48372 (\\N{HANGUL SYLLABLE BO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53328 (\\N{HANGUL SYLLABLE KYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48337 (\\N{HANGUL SYLLABLE BYEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54172 (\\N{HANGUL SYLLABLE PEN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46976 (\\N{HANGUL SYLLABLE RAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53668 (\\N{HANGUL SYLLABLE TON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50648 (\\N{HANGUL SYLLABLE EL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54000 (\\N{HANGUL SYLLABLE TI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47113 (\\N{HANGUL SYLLABLE REG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48120 (\\N{HANGUL SYLLABLE MI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48652 (\\N{HANGUL SYLLABLE BEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51247 (\\N{HANGUL SYLLABLE JES}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48128 (\\N{HANGUL SYLLABLE MIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47016 (\\N{HANGUL SYLLABLE RAEM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52852 (\\N{HANGUL SYLLABLE KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54588 (\\N{HANGUL SYLLABLE PI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50864 (\\N{HANGUL SYLLABLE U}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47560 (\\N{HANGUL SYLLABLE MA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47589 (\\N{HANGUL SYLLABLE MAEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48512 (\\N{HANGUL SYLLABLE BU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50892 (\\N{HANGUL SYLLABLE WEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47924 (\\N{HANGUL SYLLABLE MU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54408 (\\N{HANGUL SYLLABLE PUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48036 (\\N{HANGUL SYLLABLE MYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53580 (\\N{HANGUL SYLLABLE TE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47161 (\\N{HANGUL SYLLABLE RYEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53588 (\\N{HANGUL SYLLABLE TEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47533 (\\N{HANGUL SYLLABLE RIG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49296 (\\N{HANGUL SYLLABLE BBI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53092 (\\N{HANGUL SYLLABLE KOM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50472 (\\N{HANGUL SYLLABLE SSI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49340 (\\N{HANGUL SYLLABLE SAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45224 (\\N{HANGUL SYLLABLE NAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44148 (\\N{HANGUL SYLLABLE GEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51312 (\\N{HANGUL SYLLABLE JO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49328 (\\N{HANGUL SYLLABLE SAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47336 (\\N{HANGUL SYLLABLE RU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45700 (\\N{HANGUL SYLLABLE NYUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44180 (\\N{HANGUL SYLLABLE GEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50024 (\\N{HANGUL SYLLABLE SSEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49436 (\\N{HANGUL SYLLABLE SEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48169 (\\N{HANGUL SYLLABLE BANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50052 (\\N{HANGUL SYLLABLE SSE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53000 (\\N{HANGUL SYLLABLE KEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51096 (\\N{HANGUL SYLLABLE JAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53444 (\\N{HANGUL SYLLABLE TAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48716 (\\N{HANGUL SYLLABLE BIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44600 (\\N{HANGUL SYLLABLE GIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50684 (\\N{HANGUL SYLLABLE YEOM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47476 (\\N{HANGUL SYLLABLE REU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48709 (\\N{HANGUL SYLLABLE BIG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50656 (\\N{HANGUL SYLLABLE EM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50612 (\\N{HANGUL SYLLABLE EO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53448 (\\N{HANGUL SYLLABLE TAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53364 (\\N{HANGUL SYLLABLE KEUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54168 (\\N{HANGUL SYLLABLE PE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50724 (\\N{HANGUL SYLLABLE O}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54008 (\\N{HANGUL SYLLABLE TIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50872 (\\N{HANGUL SYLLABLE UL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49483 (\\N{HANGUL SYLLABLE SES}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50577 (\\N{HANGUL SYLLABLE YANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54616 (\\N{HANGUL SYLLABLE HA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45572 (\\N{HANGUL SYLLABLE NU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51228 (\\N{HANGUL SYLLABLE JE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51064 (\\N{HANGUL SYLLABLE IN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54392 (\\N{HANGUL SYLLABLE PU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51333 (\\N{HANGUL SYLLABLE JONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44540 (\\N{HANGUL SYLLABLE GEUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45208 (\\N{HANGUL SYLLABLE NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48156 (\\N{HANGUL SYLLABLE BAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52992 (\\N{HANGUL SYLLABLE KE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45348 (\\N{HANGUL SYLLABLE NE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53216 (\\N{HANGUL SYLLABLE KU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54592 (\\N{HANGUL SYLLABLE PIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51232 (\\N{HANGUL SYLLABLE JEN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46272 (\\N{HANGUL SYLLABLE DYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50952 (\\N{HANGUL SYLLABLE WIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54176 (\\N{HANGUL SYLLABLE PEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54540 (\\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48148 (\\N{HANGUL SYLLABLE BA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53664 (\\N{HANGUL SYLLABLE TO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54028 (\\N{HANGUL SYLLABLE PA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44544 (\\N{HANGUL SYLLABLE GEUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50500 (\\N{HANGUL SYLLABLE A}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48124 (\\N{HANGUL SYLLABLE MIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51656 (\\N{HANGUL SYLLABLE JIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52897 (\\N{HANGUL SYLLABLE KAEB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49808 (\\N{HANGUL SYLLABLE SYUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54004 (\\N{HANGUL SYLLABLE TIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53084 (\\N{HANGUL SYLLABLE KOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47536 (\\N{HANGUL SYLLABLE RIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50508 (\\N{HANGUL SYLLABLE AL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49464 (\\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47112 (\\N{HANGUL SYLLABLE RE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53944 (\\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45349 (\\N{HANGUL SYLLABLE NEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49888 (\\N{HANGUL SYLLABLE SIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50640 (\\N{HANGUL SYLLABLE E}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54532 (\\N{HANGUL SYLLABLE PEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51008 (\\N{HANGUL SYLLABLE EUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54665 (\\N{HANGUL SYLLABLE HAENG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50685 (\\N{HANGUL SYLLABLE YEOB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50641 (\\N{HANGUL SYLLABLE EG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49828 (\\N{HANGUL SYLLABLE SEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52636 (\\N{HANGUL SYLLABLE CUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50857 (\\N{HANGUL SYLLABLE YONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45209 (\\N{HANGUL SYLLABLE NAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49548 (\\N{HANGUL SYLLABLE SO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51320 (\\N{HANGUL SYLLABLE JOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45432 (\\N{HANGUL SYLLABLE NO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53356 (\\N{HANGUL SYLLABLE KEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45440 (\\N{HANGUL SYLLABLE NOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53581 (\\N{HANGUL SYLLABLE TEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45684 (\\N{HANGUL SYLLABLE NYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47700 (\\N{HANGUL SYLLABLE ME}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46300 (\\N{HANGUL SYLLABLE DEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50725 (\\N{HANGUL SYLLABLE OG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46972 (\\N{HANGUL SYLLABLE RA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53456 (\\N{HANGUL SYLLABLE TAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48372 (\\N{HANGUL SYLLABLE BO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53328 (\\N{HANGUL SYLLABLE KYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48337 (\\N{HANGUL SYLLABLE BYEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54172 (\\N{HANGUL SYLLABLE PEN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46976 (\\N{HANGUL SYLLABLE RAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53668 (\\N{HANGUL SYLLABLE TON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50648 (\\N{HANGUL SYLLABLE EL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54000 (\\N{HANGUL SYLLABLE TI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47113 (\\N{HANGUL SYLLABLE REG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48120 (\\N{HANGUL SYLLABLE MI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48652 (\\N{HANGUL SYLLABLE BEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51247 (\\N{HANGUL SYLLABLE JES}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48128 (\\N{HANGUL SYLLABLE MIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47016 (\\N{HANGUL SYLLABLE RAEM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52852 (\\N{HANGUL SYLLABLE KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54588 (\\N{HANGUL SYLLABLE PI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50864 (\\N{HANGUL SYLLABLE U}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47560 (\\N{HANGUL SYLLABLE MA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47589 (\\N{HANGUL SYLLABLE MAEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48512 (\\N{HANGUL SYLLABLE BU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50892 (\\N{HANGUL SYLLABLE WEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47924 (\\N{HANGUL SYLLABLE MU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54408 (\\N{HANGUL SYLLABLE PUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48036 (\\N{HANGUL SYLLABLE MYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53580 (\\N{HANGUL SYLLABLE TE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47161 (\\N{HANGUL SYLLABLE RYEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53588 (\\N{HANGUL SYLLABLE TEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47533 (\\N{HANGUL SYLLABLE RIG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49296 (\\N{HANGUL SYLLABLE BBI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53092 (\\N{HANGUL SYLLABLE KOM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50472 (\\N{HANGUL SYLLABLE SSI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49340 (\\N{HANGUL SYLLABLE SAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45224 (\\N{HANGUL SYLLABLE NAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44148 (\\N{HANGUL SYLLABLE GEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51312 (\\N{HANGUL SYLLABLE JO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49328 (\\N{HANGUL SYLLABLE SAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47336 (\\N{HANGUL SYLLABLE RU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45700 (\\N{HANGUL SYLLABLE NYUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44180 (\\N{HANGUL SYLLABLE GEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50024 (\\N{HANGUL SYLLABLE SSEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49436 (\\N{HANGUL SYLLABLE SEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48169 (\\N{HANGUL SYLLABLE BANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50052 (\\N{HANGUL SYLLABLE SSE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53000 (\\N{HANGUL SYLLABLE KEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51096 (\\N{HANGUL SYLLABLE JAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53444 (\\N{HANGUL SYLLABLE TAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48716 (\\N{HANGUL SYLLABLE BIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44600 (\\N{HANGUL SYLLABLE GIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50684 (\\N{HANGUL SYLLABLE YEOM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47476 (\\N{HANGUL SYLLABLE REU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48709 (\\N{HANGUL SYLLABLE BIG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50656 (\\N{HANGUL SYLLABLE EM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50612 (\\N{HANGUL SYLLABLE EO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53448 (\\N{HANGUL SYLLABLE TAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53364 (\\N{HANGUL SYLLABLE KEUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54168 (\\N{HANGUL SYLLABLE PE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50724 (\\N{HANGUL SYLLABLE O}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54008 (\\N{HANGUL SYLLABLE TIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50872 (\\N{HANGUL SYLLABLE UL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49483 (\\N{HANGUL SYLLABLE SES}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50577 (\\N{HANGUL SYLLABLE YANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54616 (\\N{HANGUL SYLLABLE HA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45572 (\\N{HANGUL SYLLABLE NU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51228 (\\N{HANGUL SYLLABLE JE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51064 (\\N{HANGUL SYLLABLE IN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54392 (\\N{HANGUL SYLLABLE PU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51333 (\\N{HANGUL SYLLABLE JONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44540 (\\N{HANGUL SYLLABLE GEUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45208 (\\N{HANGUL SYLLABLE NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48156 (\\N{HANGUL SYLLABLE BAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52992 (\\N{HANGUL SYLLABLE KE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45348 (\\N{HANGUL SYLLABLE NE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53216 (\\N{HANGUL SYLLABLE KU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54592 (\\N{HANGUL SYLLABLE PIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51232 (\\N{HANGUL SYLLABLE JEN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46272 (\\N{HANGUL SYLLABLE DYU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50952 (\\N{HANGUL SYLLABLE WIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54176 (\\N{HANGUL SYLLABLE PEL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54540 (\\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        151        560      0.648      0.681      0.706      0.635\n",
            "           가바토파정 100mg         20         20      0.625          1      0.975      0.891\n",
            "             글리아타민연질캡슐          2          2      0.251      0.502      0.448      0.403\n",
            "        글리틴정(콜린알포세레이트)          1          1      0.124          1      0.332      0.332\n",
            "    기넥신에프정(은행엽엑스)(수출용)         40         40      0.965          1      0.995      0.883\n",
            "         낙소졸정 500/20mg          2          2      0.295          1      0.828      0.745\n",
            "             노바스크정 5mg         10         10      0.787          1      0.995      0.879\n",
            "              놀텍정 10mg          8          8          1      0.462      0.811      0.772\n",
            "          뉴로메드정(옥시라세탐)          4          4      0.189      0.645       0.21      0.189\n",
            "         다보타민큐정 10mg/병          6          6      0.657      0.167       0.57      0.506\n",
            "         동아가바펜틴정 800mg         23         23      0.546          1      0.959      0.893\n",
            "            라비에트정 20mg          6          6          1          0     0.0877      0.079\n",
            "        란스톤엘에프디티정 30mg          6          6          1          0      0.206      0.189\n",
            "                  레일라정          7          7      0.949          1      0.995      0.905\n",
            "        로수바미브정 10/20mg          8          8      0.834      0.875      0.949      0.862\n",
            "          로수젯정10/5밀리그램         14         14      0.907      0.701      0.922      0.785\n",
            "       리렉스펜정 300mg/PTP          3          3      0.513      0.333      0.599      0.543\n",
            "           리리카캡슐 150mg          2          2      0.139          1      0.995      0.895\n",
            "              리바로정 4mg         11         11      0.919          1      0.995      0.895\n",
            "            리피로우정 20mg          4          4      0.462      0.655      0.703      0.689\n",
            "             리피토정 20mg         11         11      0.306      0.727       0.57      0.509\n",
            "                  마도파정          6          6      0.966      0.833      0.972      0.849\n",
            "         맥시부펜이알정 300mg          2          2      0.388          1      0.828      0.745\n",
            "          메가파워정 90mg/병          2          2      0.312          1      0.663      0.622\n",
            "     무코스타정(레바미피드)(비매품)         10         10      0.487          1      0.972      0.885\n",
            "           뮤테란캡슐 100mg         24         24      0.931          1      0.995      0.893\n",
            "            보령부스파정 5mg         33         33      0.886          1      0.992      0.816\n",
            "         비모보정 500/20mg          7          7          1      0.887      0.995      0.941\n",
            "         비타비백정 100mg/병          5          5      0.385      0.509      0.553      0.462\n",
            "      삐콤씨에프정 618.6mg/병          4          4          1      0.734      0.856      0.715\n",
            "         삼남건조수산화알루미늄겔정          3          3     0.0697      0.333      0.178       0.16\n",
            "          세비카정 10/40mg          3          3      0.493          1      0.995      0.895\n",
            "             스토가정 10mg          4          4      0.295       0.25      0.294      0.279\n",
            "                  신바로정          3          3      0.751          1      0.995       0.83\n",
            "     써스펜8시간이알서방정 650mg         10         10       0.58          1      0.986      0.887\n",
            "            쎄로켈정 100mg          5          5      0.831        0.4      0.632      0.589\n",
            "         아모잘탄정 5/100mg          5          5      0.416          1      0.995      0.915\n",
            "           아빌리파이정 10mg          4          4          1          0     0.0331     0.0317\n",
            "       아질렉트정(라사길린메실산염)          4          4          1          0      0.816      0.743\n",
            "            아토르바정 10mg          4          4      0.152       0.75      0.403      0.368\n",
            "          아토젯정 10/40mg         15         15      0.638          1      0.995      0.857\n",
            "                  알드린정          6          6      0.475          1      0.972      0.915\n",
            "     에빅사정(메만틴염산염)(비매품)          6          6          1          0      0.494      0.481\n",
            "          에어탈정(아세클로페낙)          4          4          1          0      0.115      0.112\n",
            "         엑스포지정 5/160mg          8          8      0.736          1      0.995      0.895\n",
            "오마코연질캡슐(오메가-3-산에틸에스테르90)          2          2          1          0      0.103     0.0933\n",
            "             울트라셋이알서방정         12         12      0.779          1      0.984      0.872\n",
            "           일양하이트린정 2mg         44         44      0.931      0.977      0.967      0.888\n",
            " 자누메트엑스알서방정 100/1000mg         10         10      0.744          1      0.995      0.886\n",
            "        자누메트정 50/850mg         12         12      0.755          1      0.995      0.925\n",
            "            자누비아정 50mg          4          4      0.165          1      0.299      0.262\n",
            "          자이프렉사정 2.5mg          1          1          1          0    0.00995    0.00995\n",
            "     제미메트서방정 50/1000mg          5          5      0.664          1      0.995      0.883\n",
            "            조인스정 200mg          2          2      0.318          1      0.995       0.92\n",
            "종근당글리아티린연질캡슐(콜린알포세레이트)           5          5          1          0       0.22      0.201\n",
            "             카나브정 60mg          6          6      0.552          1      0.995        0.9\n",
            "            카발린캡슐 25mg          7          7          1        0.2      0.675      0.611\n",
            "             케이캡정 50mg          9          9      0.497      0.222      0.269      0.254\n",
            "       콜리네이트연질캡슐 400mg          7          7          0          0      0.379      0.323\n",
            "       큐시드정 31.5mg/PTP         15         15      0.618          1      0.995      0.923\n",
            "            크레스토정 20mg          9          9      0.682          1      0.984      0.884\n",
            "타이레놀이알서방정(아세트아미노펜)(수출용)          3          3      0.397          1      0.497       0.42\n",
            "            타이레놀정500mg          6          6          1          0      0.269      0.251\n",
            "     트라젠타듀오정 2.5/850mg          5          5      0.639      0.367      0.456      0.425\n",
            "          트라젠타정(리나글립틴)          4          4      0.428          1      0.995       0.87\n",
            "          트루비타정 60mg/병          7          7       0.89          1      0.995      0.903\n",
            "          트윈스타정 40/5mg          8          8      0.781      0.875      0.876      0.792\n",
            "          펠루비정(펠루비프로펜)          6          6      0.337      0.333      0.455      0.403\n",
            "            플라빅스정 75mg          6          6      0.622      0.556      0.707      0.585\n",
            "Speed: 0.5ms preprocess, 43.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34\u001b[0m\n",
            "모델3 학습 완료: /content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model3/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델들로 앙상블."
      ],
      "metadata": {
        "id": "w9KSyLnJ9uvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FWR2q5CJA0pJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380e778f-753c-46e6-a8d0-b60a8179b147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ensemble-boxes in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.203)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ensemble-boxes) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ensemble-boxes) (2.2.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from ensemble-boxes) (0.60.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->ensemble-boxes) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ensemble-boxes) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ensemble-boxes) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "=== 모델 확인 ===\n",
            "1. ensemble_model1: True\n",
            "2. ensemble_model2: True\n",
            "3. ensemble_model34: True\n",
            "\n",
            "=== 테스트 예측 ===\n",
            "이미지: /content/drive/MyDrive/pill_project/test_images/1.png\n",
            "앙상블 결과: 5개 객체 검출\n",
            "평균 confidence: 0.625\n"
          ]
        }
      ],
      "source": [
        "!pip install ensemble-boxes ultralytics\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "from ensemble_boxes import weighted_boxes_fusion\n",
        "from ultralytics import YOLO\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 3개 모델 모두 사용\n",
        "ensemble_models = [\n",
        "    '/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model1/weights/best.pt',\n",
        "    '/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model2/weights/best.pt',\n",
        "    '/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34/weights/best.pt'\n",
        "]\n",
        "\n",
        "# 모델 존재 확인\n",
        "print(\"=== 모델 확인 ===\")\n",
        "for i, model_path in enumerate(ensemble_models):\n",
        "    exists = os.path.exists(model_path)\n",
        "    print(f\"{i+1}. {os.path.basename(os.path.dirname(os.path.dirname(model_path)))}: {exists}\")\n",
        "\n",
        "\n",
        "def ensemble_predict_wbf(models, image_path, iou_thr=0.5, skip_box_thr=0.25, weights=None):\n",
        "    \"\"\"여러 모델의 예측을 WBF로 결합\"\"\"\n",
        "    all_boxes = []\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "\n",
        "    # 각 모델로 예측\n",
        "    for model_path in models:\n",
        "        model = YOLO(model_path)\n",
        "        results = model.predict(\n",
        "            image_path,\n",
        "            conf=0.001,  # 낮은 threshold\n",
        "            verbose=False,\n",
        "            augment=False  # TTA 끄기 (효과 없었음)\n",
        "        )\n",
        "\n",
        "        boxes_list = []\n",
        "        scores_list = []\n",
        "        labels_list = []\n",
        "\n",
        "        for result in results:\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                boxes = result.boxes.xyxyn.cpu().numpy()  # normalized\n",
        "                scores = result.boxes.conf.cpu().numpy()\n",
        "                labels = result.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "                boxes_list.append(boxes)\n",
        "                scores_list.append(scores)\n",
        "                labels_list.append(labels)\n",
        "\n",
        "        if boxes_list:\n",
        "            all_boxes.append(np.vstack(boxes_list))\n",
        "            all_scores.append(np.concatenate(scores_list))\n",
        "            all_labels.append(np.concatenate(labels_list))\n",
        "        else:\n",
        "            # 빈 배열 추가\n",
        "            all_boxes.append(np.array([]).reshape(0, 4))\n",
        "            all_scores.append(np.array([]))\n",
        "            all_labels.append(np.array([]))\n",
        "\n",
        "    # WBF 적용\n",
        "    if weights is None:\n",
        "        weights = [1.0] * len(models)\n",
        "\n",
        "    boxes, scores, labels = weighted_boxes_fusion(\n",
        "        all_boxes,\n",
        "        all_scores,\n",
        "        all_labels,\n",
        "        weights=weights,\n",
        "        iou_thr=iou_thr,\n",
        "        skip_box_thr=skip_box_thr\n",
        "    )\n",
        "\n",
        "    return boxes, scores, labels\n",
        "\n",
        "# 테스트 이미지로 확인\n",
        "test_image = '/content/drive/MyDrive/pill_project/test_images/1.png'\n",
        "\n",
        "print(f\"\\n=== 테스트 예측 ===\")\n",
        "print(f\"이미지: {test_image}\")\n",
        "\n",
        "if os.path.exists(test_image):\n",
        "    boxes, scores, labels = ensemble_predict_wbf(ensemble_models, test_image)\n",
        "    print(f\"앙상블 결과: {len(boxes)}개 객체 검출\")\n",
        "    print(f\"평균 confidence: {scores.mean():.3f}\")\n",
        "else:\n",
        "    print(\"테스트 이미지가 없습니다. 경로를 확인하세요.\")\n",
        "    # 다른 이미지 시도\n",
        "    import glob\n",
        "    test_images = glob.glob('/content/drive/MyDrive/pill_project/test_images/*.png')[:1]\n",
        "    if test_images:\n",
        "        test_image = test_images[0]\n",
        "        print(f\"대체 이미지 사용: {test_image}\")\n",
        "        boxes, scores, labels = ensemble_predict_wbf(ensemble_models, test_image)\n",
        "        print(f\"앙상블 결과: {len(boxes)}개 객체 검출\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 3개를 앙상블로 했음 <font size = '3'> ( 모델 3개 :  </font>"
      ],
      "metadata": {
        "id": "iJzfblco8g2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리\n",
        "import pandas as pd\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from ensemble_boxes import weighted_boxes_fusion\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 모델 경로\n",
        "ensemble_models = [\n",
        "    '/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model1/weights/best.pt',\n",
        "    '/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model2/weights/best.pt',\n",
        "    '/content/drive/MyDrive/pill_project/ensemble_clean/ensemble_model34/weights/best.pt'  # 추가\n",
        "]\n",
        "# WBF 앙상블 함수\n",
        "def ensemble_predict_wbf(models, image_path, iou_thr=0.5, skip_box_thr=0.25, weights=None):\n",
        "    \"\"\"여러 모델의 예측을 WBF로 결합\"\"\"\n",
        "    all_boxes = []\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "\n",
        "    for model_path in models:\n",
        "        model = YOLO(model_path)\n",
        "        results = model.predict(image_path, conf=0.001, verbose=False, augment=False)\n",
        "\n",
        "        boxes_list = []\n",
        "        scores_list = []\n",
        "        labels_list = []\n",
        "\n",
        "        for result in results:\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                boxes = result.boxes.xyxyn.cpu().numpy()\n",
        "                scores = result.boxes.conf.cpu().numpy()\n",
        "                labels = result.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "                boxes_list.append(boxes)\n",
        "                scores_list.append(scores)\n",
        "                labels_list.append(labels)\n",
        "\n",
        "        if boxes_list:\n",
        "            all_boxes.append(np.vstack(boxes_list))\n",
        "            all_scores.append(np.concatenate(scores_list))\n",
        "            all_labels.append(np.concatenate(labels_list))\n",
        "        else:\n",
        "            all_boxes.append(np.array([]).reshape(0, 4))\n",
        "            all_scores.append(np.array([]))\n",
        "            all_labels.append(np.array([]))\n",
        "\n",
        "    if weights is None:\n",
        "        weights = [1.0] * len(models)\n",
        "\n",
        "    boxes, scores, labels = weighted_boxes_fusion(\n",
        "        all_boxes, all_scores, all_labels,\n",
        "        weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr\n",
        "    )\n",
        "\n",
        "    return boxes, scores, labels\n",
        "\n",
        "# 제출 파일 생성 함수\n",
        "def create_submission_with_ensemble(models, test_dir, mapping_path, output_csv='submission_ensemble1.csv'):\n",
        "    with open(mapping_path, 'r') as f:\n",
        "        yolo_idx_to_cat_id = json.load(f)\n",
        "        yolo_idx_to_cat_id = {int(k): int(v) for k, v in yolo_idx_to_cat_id.items()}\n",
        "\n",
        "    test_images = sorted(glob.glob(os.path.join(test_dir, '*.png')))\n",
        "    print(f\"테스트 이미지: {len(test_images)}장\")\n",
        "\n",
        "    predictions = []\n",
        "    annotation_id = 1\n",
        "\n",
        "    for img_path in tqdm(test_images, desc=\"앙상블 추론 중\"):\n",
        "        image_id = int(os.path.splitext(os.path.basename(img_path))[0])\n",
        "\n",
        "        boxes, scores, labels = ensemble_predict_wbf(models, img_path, iou_thr=0.5, skip_box_thr=0.25)\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        img_width, img_height = img.size\n",
        "\n",
        "        for box, score, label in zip(boxes, scores, labels):\n",
        "            x1 = box[0] * img_width\n",
        "            y1 = box[1] * img_height\n",
        "            x2 = box[2] * img_width\n",
        "            y2 = box[3] * img_height\n",
        "\n",
        "            category_id = yolo_idx_to_cat_id.get(int(label), int(label))\n",
        "\n",
        "            predictions.append([\n",
        "                annotation_id, image_id, category_id,\n",
        "                x1, y1, x2-x1, y2-y1, score\n",
        "            ])\n",
        "            annotation_id += 1\n",
        "\n",
        "    df = pd.DataFrame(predictions, columns=[\n",
        "        'annotation_id', 'image_id', 'category_id',\n",
        "        'bbox_x', 'bbox_y', 'bbox_w', 'bbox_h', 'score'\n",
        "    ])\n",
        "\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"제출 파일 생성: {output_csv}\")\n",
        "    print(f\"총 예측 수: {len(predictions)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# 실행\n",
        "test_dir = '/content/drive/MyDrive/pill_project/test_images'\n",
        "mapping_path = '/content/drive/MyDrive/pill_project/class_mapping.json'\n",
        "\n",
        "df_submission = create_submission_with_ensemble(ensemble_models, test_dir, mapping_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('submission_ensemble1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "NfMDmSrsERiD",
        "outputId": "da61cff7-b995-4bff-d45a-af9a3f46a296"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 이미지: 843장\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "앙상블 추론 중: 100%|██████████| 843/843 [10:41<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "제출 파일 생성: submission_ensemble1.csv\n",
            "총 예측 수: 4229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bc7d9aed-2716-42a9-a879-e46caa1f5e76\", \"submission_ensemble1.csv\", 452865)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단일 모델에 TTA만 적용한 것 <font size = '3'>( 단일모델 :  YOLOv8n ) </font>\n",
        "\n",
        "-> 역시 성능이 좋지 않았음."
      ],
      "metadata": {
        "id": "62pPbVsQ7yVR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9ny3nCjwA4E_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a06e2ea2-d579-4b88-8919-c14791aa09f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 이미지: 843장\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA 추론 중: 100%|██████████| 843/843 [18:01<00:00,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TTA 제출 파일 생성: submission_tta.csv\n",
            "총 예측 수: 3329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2d07ab8a-6333-4ef0-b40f-9bf263a1c4a3\", \"submission_tta.csv\", 355726)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 단일 모델 + TTA\n",
        "best_model = YOLO(ensemble_models[1])  # model2 사용\n",
        "\n",
        "def create_submission_with_tta(model, test_dir, mapping_path, output_csv='submission_tta.csv'):\n",
        "    \"\"\"단일 모델 + TTA로 제출 파일 생성\"\"\"\n",
        "\n",
        "    # 클래스 매핑 로드 (전체 경로 사용)\n",
        "    with open(mapping_path, 'r') as f:\n",
        "        yolo_idx_to_cat_id = json.load(f)\n",
        "        yolo_idx_to_cat_id = {int(k): int(v) for k, v in yolo_idx_to_cat_id.items()}\n",
        "\n",
        "    test_images = sorted(glob.glob(os.path.join(test_dir, '*.png')))\n",
        "    print(f\"테스트 이미지: {len(test_images)}장\")\n",
        "\n",
        "    predictions = []\n",
        "    annotation_id = 1\n",
        "\n",
        "    for img_path in tqdm(test_images, desc=\"TTA 추론 중\"):\n",
        "        image_id = int(os.path.splitext(os.path.basename(img_path))[0])\n",
        "\n",
        "        # TTA 활성화\n",
        "        preds = model.predict(\n",
        "            img_path,\n",
        "            conf=0.25,\n",
        "            iou=0.45,\n",
        "            augment=True,  # TTA\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # 이미지 크기\n",
        "        img = Image.open(img_path)\n",
        "        img_width, img_height = img.size\n",
        "\n",
        "        for result in preds:\n",
        "            if result.boxes is not None:\n",
        "                for box in result.boxes:\n",
        "                    x1, y1, x2, y2 = box.xyxyn[0].tolist()\n",
        "                    score = box.conf[0].item()\n",
        "                    label = int(box.cls[0].item())\n",
        "\n",
        "                    # pixel 좌표로 변환\n",
        "                    x1_px = x1 * img_width\n",
        "                    y1_px = y1 * img_height\n",
        "                    x2_px = x2 * img_width\n",
        "                    y2_px = y2 * img_height\n",
        "\n",
        "                    category_id = yolo_idx_to_cat_id.get(label, label)\n",
        "\n",
        "                    predictions.append([\n",
        "                        annotation_id, image_id, category_id,\n",
        "                        x1_px, y1_px, x2_px-x1_px, y2_px-y1_px, score\n",
        "                    ])\n",
        "                    annotation_id += 1\n",
        "\n",
        "    df = pd.DataFrame(predictions, columns=[\n",
        "        'annotation_id', 'image_id', 'category_id',\n",
        "        'bbox_x', 'bbox_y', 'bbox_w', 'bbox_h', 'score'\n",
        "    ])\n",
        "\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"TTA 제출 파일 생성: {output_csv}\")\n",
        "    print(f\"총 예측 수: {len(predictions)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# 실행\n",
        "mapping_path = '/content/drive/MyDrive/pill_project/class_mapping.json'\n",
        "df_tta = create_submission_with_tta(best_model, test_dir, mapping_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('submission_tta.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수도 라벨링"
      ],
      "metadata": {
        "id": "B1sZMeGg7t2x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHod9yXXi8S6",
        "outputId": "8ca1e2ce-3208-4ba0-919d-b6b320a6cbb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "작업 디렉토리: /content/drive/MyDrive/pill_project\n",
            "JSON 디렉토리 존재: True\n",
            "이미지 디렉토리 존재: True\n",
            "클래스 매핑 완료: 73개 클래스\n",
            "YAML 파일 생성: /content/drive/MyDrive/pill_project/pill_dataset.yaml\n",
            "YOLO 데이터셋 생성 중: /content/drive/MyDrive/pill_project/pill_dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLO 데이터셋 생성: 100%|██████████| 639/639 [03:40<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 이미지: 511장, 검증 이미지: 128장\n",
            "=== 앙상블 모델 학습 시작 ===\n",
            "모델 1: YOLOv8n 기본 설정 학습 중...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 69.8MB/s 0.1s\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/pill_project/pill_dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=model1_basic, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/pill_project/ensemble_models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/pill_project/ensemble_models/model1_basic, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf': 100% ━━━━━━━━━━━━ 22.2MB 62.3MB/s 0.4s\n",
            "Overriding model.yaml nc=80 with nc=73\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    837205  ultralytics.nn.modules.head.Detect           [73, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,096,741 parameters, 3,096,725 gradients, 8.6 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 1.4±1.1 ms, read: 170.5±152.2 MB/s, size: 1699.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/train/labels... 534 images, 0 backgrounds, 1 corrupt: 100% ━━━━━━━━━━━━ 534/534 20.5it/s 26.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/pill_project/pill_dataset/train/images/K-003351-016262-018357_0_2_0_2_75_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.8878]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/pill_project/pill_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 11.9±25.2 ms, read: 42.9±78.5 MB/s, size: 1757.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/val/labels... 151 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 151/151 19.4it/s 7.8s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/pill_project/pill_dataset/val/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/pill_project/ensemble_models/model1_basic/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00013, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_models/model1_basic\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 45.7MB/s 0.0s\n",
            "\u001b[K       1/15         0G      0.891      4.738      1.061         27        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 9:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.4s\n",
            "                   all        151        560          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15         0G     0.5954      4.234     0.9392         32        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.2s\n",
            "                   all        151        560     0.0248     0.0489     0.0218     0.0205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15         0G     0.5504      3.752     0.9347         41        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 45.8s\n",
            "                   all        151        560     0.0253      0.575     0.0821     0.0775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15         0G     0.5232      3.282     0.9362         44        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:42\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 45.1s\n",
            "                   all        151        560      0.752      0.145      0.168      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15         0G     0.5099      2.939     0.9474         38        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.8s\n",
            "                   all        151        560      0.813      0.187      0.247      0.234\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15         0G     0.3941      2.578      0.898         18        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.6s\n",
            "                   all        151        560      0.721      0.306      0.371      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15         0G     0.3654       2.22     0.8812         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 45.6s\n",
            "                   all        151        560      0.757      0.319       0.42      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/15         0G     0.3517      2.013     0.8789         18        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:43\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.8s\n",
            "                   all        151        560      0.661      0.456      0.571      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/15         0G     0.3457       1.82     0.8693         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.5s\n",
            "                   all        151        560      0.777      0.441      0.625      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/15         0G     0.3294      1.687      0.863         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:42\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.6s\n",
            "                   all        151        560      0.807      0.479      0.688      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/15         0G     0.3187      1.602     0.8574         18        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.6s\n",
            "                   all        151        560      0.595      0.676      0.711      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/15         0G     0.3149      1.527     0.8589         20        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.1s\n",
            "                   all        151        560      0.603       0.72      0.755      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/15         0G     0.3076      1.452     0.8543         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 45.9s\n",
            "                   all        151        560      0.624      0.735      0.774      0.754\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/15         0G     0.3044       1.39     0.8512         20        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:43\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.1s\n",
            "                   all        151        560      0.663      0.741      0.781      0.759\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/15         0G     0.2989      1.364     0.8553         20        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.9s\n",
            "                   all        151        560       0.65      0.746      0.788      0.768\n",
            "\n",
            "15 epochs completed in 2.378 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_models/model1_basic/weights/last.pt, 6.4MB\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_models/model1_basic/weights/best.pt, 6.4MB\n",
            "\n",
            "Validating /content/drive/MyDrive/pill_project/ensemble_models/model1_basic/weights/best.pt...\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,091,487 parameters, 0 gradients, 8.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 44.9s\n",
            "                   all        151        560      0.649      0.749      0.787      0.767\n",
            "Speed: 1.9ms preprocess, 235.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_models/model1_basic\u001b[0m\n",
            "모델 2: YOLOv8s 학습 중...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ━━━━━━━━━━━━ 21.5MB 91.9MB/s 0.2s\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/pill_project/pill_dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=model2_large, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/pill_project/ensemble_models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/pill_project/ensemble_models/model2_large, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=73\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2144299  ultralytics.nn.modules.head.Detect           [73, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,163,851 parameters, 11,163,835 gradients, 28.8 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.8±0.4 ms, read: 311.5±32.8 MB/s, size: 1728.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/train/labels.cache... 534 images, 0 backgrounds, 1 corrupt: 100% ━━━━━━━━━━━━ 534/534 744.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/pill_project/pill_dataset/train/images/K-003351-016262-018357_0_2_0_2_75_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.8878]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.3 ms, read: 142.8±119.1 MB/s, size: 1764.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/val/labels.cache... 151 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 151/151 131.5Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/pill_project/ensemble_models/model2_large/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00013, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00046875), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_models/model2_large\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15         0G      1.059      4.668        1.2         38        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 22:48\n",
            "WARNING ⚠️ NMS time limit 3.200s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 14% ━╸────────── 1/7 0.0it/s 20.0s<6:40WARNING ⚠️ NMS time limit 3.200s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 29% ━━━───────── 2/7 0.0it/s 39.8s<3:15WARNING ⚠️ NMS time limit 3.200s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 57% ━━━━━━╸───── 4/7 0.0it/s 1:18<1:16WARNING ⚠️ NMS time limit 3.200s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 2:02\n",
            "                   all        151        560      0.635     0.0997     0.0992     0.0888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15         0G     0.5999      2.625     0.9684         37        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 22:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:45\n",
            "                   all        151        560      0.595      0.384        0.4      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15         0G     0.5034      1.812     0.9239         29        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 22:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:44\n",
            "                   all        151        560      0.579      0.619      0.629      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15         0G     0.4524      1.356     0.9014         32        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 22:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:48\n",
            "                   all        151        560       0.84      0.683      0.822       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15         0G     0.4275      1.112     0.8804         44        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 22:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:46\n",
            "                   all        151        560      0.808      0.793       0.89      0.852\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15         0G     0.3322     0.9367     0.8308         18        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 22:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:47\n",
            "                   all        151        560      0.824      0.844      0.916      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15         0G     0.3146     0.7848     0.8257         19        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 23:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:45\n",
            "                   all        151        560      0.855      0.897      0.958      0.927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/15         0G     0.2987     0.6782     0.8124         18        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 22:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:43\n",
            "                   all        151        560      0.919      0.915      0.964      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/15         0G     0.2896     0.6012     0.8098         19        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 21:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:43\n",
            "                   all        151        560      0.904      0.951      0.974      0.946\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/15         0G     0.2726     0.5342     0.8085         19        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 21:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:45\n",
            "                   all        151        560      0.934      0.961      0.975      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/15         0G     0.2715     0.5063     0.8086         18        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 21:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:44\n",
            "                   all        151        560      0.959      0.956      0.977      0.955\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/15         0G     0.2587     0.4675     0.8028         20        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 21:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:42\n",
            "                   all        151        560      0.959      0.949      0.978      0.957\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/15         0G     0.2556      0.446     0.8016         19        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 21:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:47\n",
            "                   all        151        560      0.958      0.969      0.978      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/15         0G     0.2483     0.4351     0.8015         20        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 21:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:44\n",
            "                   all        151        560      0.953      0.974      0.991      0.975\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/15         0G     0.2453     0.4246     0.8039         20        640: 100% ━━━━━━━━━━━━ 45/45 0.0it/s 21:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:45\n",
            "                   all        151        560      0.976      0.955       0.99      0.973\n",
            "\n",
            "15 epochs completed in 5.980 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_models/model2_large/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_models/model2_large/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/pill_project/ensemble_models/model2_large/weights/best.pt...\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 11,153,835 parameters, 0 gradients, 28.6 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.1it/s 1:39\n",
            "                   all        151        560      0.953      0.974      0.991      0.975\n",
            "Speed: 1.9ms preprocess, 585.7ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_models/model2_large\u001b[0m\n",
            "모델 3: YOLOv8n 강한 증강 학습 중...\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/pill_project/pill_dataset.yaml, degrees=15, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.7, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02, hsv_s=0.8, hsv_v=0.5, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.3, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=model3_augmented, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/pill_project/ensemble_models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/pill_project/ensemble_models/model3_augmented, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.7, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.15, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=73\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    837205  ultralytics.nn.modules.head.Detect           [73, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,096,741 parameters, 3,096,725 gradients, 8.6 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.7±0.3 ms, read: 142.1±34.8 MB/s, size: 1728.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/train/labels.cache... 534 images, 0 backgrounds, 1 corrupt: 100% ━━━━━━━━━━━━ 534/534 535.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/pill_project/pill_dataset/train/images/K-003351-016262-018357_0_2_0_2_75_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.8878]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.7±0.3 ms, read: 182.8±105.9 MB/s, size: 1764.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/pill_project/pill_dataset/val/labels.cache... 151 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 151/151 140.8Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/pill_project/ensemble_models/model3_augmented/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00013, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_models/model3_augmented\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15         0G       1.69      4.899      1.544         60        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 9:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.5s\n",
            "                   all        151        560          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15         0G      1.005      4.501      1.149         27        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 44.9s\n",
            "                   all        151        560    0.00098    0.00098    0.00142   0.000991\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15         0G     0.9345      4.078      1.105         46        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.1s\n",
            "                   all        151        560     0.0171      0.394     0.0565     0.0371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15         0G      0.914      3.771      1.107         38        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.8s\n",
            "                   all        151        560      0.843     0.0559      0.106      0.074\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15         0G     0.8848      3.478        1.1         62        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.0s\n",
            "                   all        151        560      0.653      0.137       0.15     0.0922\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15         0G     0.7342      3.172      1.096         18        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 48.2s\n",
            "                   all        151        560      0.692        0.2      0.213      0.128\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15         0G     0.7015      2.863      1.098         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.0s\n",
            "                   all        151        560      0.612      0.271      0.258      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/15         0G     0.6912      2.659      1.093         18        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.9s\n",
            "                   all        151        560      0.706      0.263      0.299      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/15         0G     0.6901       2.52      1.097         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 48.2s\n",
            "                   all        151        560      0.615      0.315      0.325      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/15         0G     0.6699      2.381      1.099         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.2s\n",
            "                   all        151        560      0.661      0.372      0.379      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/15         0G     0.6691      2.311      1.098         18        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.7s\n",
            "                   all        151        560      0.713      0.368      0.414      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/15         0G     0.6475      2.199      1.088         20        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 46.7s\n",
            "                   all        151        560      0.789      0.348      0.446       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/15         0G     0.6319      2.136       1.07         19        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 48.0s\n",
            "                   all        151        560      0.751      0.366       0.46      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/15         0G     0.6246      2.071      1.064         20        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:42\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 49.3s\n",
            "                   all        151        560      0.748      0.393      0.488      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/15         0G     0.6335      2.051       1.08         20        640: 100% ━━━━━━━━━━━━ 34/34 0.1it/s 8:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 47.2s\n",
            "                   all        151        560      0.715      0.412      0.504      0.437\n",
            "\n",
            "15 epochs completed in 2.372 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_models/model3_augmented/weights/last.pt, 6.4MB\n",
            "Optimizer stripped from /content/drive/MyDrive/pill_project/ensemble_models/model3_augmented/weights/best.pt, 6.4MB\n",
            "\n",
            "Validating /content/drive/MyDrive/pill_project/ensemble_models/model3_augmented/weights/best.pt...\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,091,487 parameters, 0 gradients, 8.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.1it/s 42.0s\n",
            "                   all        151        560      0.719      0.413      0.503      0.437\n",
            "Speed: 1.9ms preprocess, 216.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/pill_project/ensemble_models/model3_augmented\u001b[0m\n",
            "\n",
            "=== 수도 라벨링 시작 ===\n",
            "대상 이미지: 850장\n",
            "모델 로드 중: /content/drive/MyDrive/pill_project/ensemble_models/model1_basic/weights/best.pt\n",
            "모델 로드 중: /content/drive/MyDrive/pill_project/ensemble_models/model2_large/weights/best.pt\n",
            "모델 로드 중: /content/drive/MyDrive/pill_project/ensemble_models/model3_augmented/weights/best.pt\n",
            "불완전한 850장 이미지에 수도 라벨링 시작...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "수도 라벨링 중: 100%|██████████| 850/850 [17:43<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 2162개의 수도 라벨이 생성되었습니다.\n",
            "\n",
            "=== 수도 라벨링 결과 ===\n",
            "수도 라벨 생성된 이미지: 849장\n",
            "총 수도 라벨 개수: 2162개\n",
            "수도 라벨 신뢰도 - 평균: 0.943, 최소: 0.740, 최대: 0.995\n",
            "  2개 모델 합의: 979개 라벨\n",
            "  3개 모델 합의: 1183개 라벨\n",
            "수도 라벨이 /content/drive/MyDrive/pill_project/pill_dataset/pseudo에 저장되었습니다.\n",
            "\n",
            "=== 최종 결과 ===\n",
            "완전한 어노테이션 데이터: 2406개\n",
            "생성된 수도 라벨: 2162개\n",
            "전체 사용 가능한 데이터: 4568개\n",
            "데이터 증가율: 89.9%\n",
            "모든 결과가 Drive에 저장되었습니다: /content/drive/MyDrive/pill_project\n"
          ]
        }
      ],
      "source": [
        "# Google Drive 마운트 및 앙상블 기반 수도 라벨링 구현\n",
        "\n",
        "# 1. Google Drive 마운트\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Drive 내 작업 디렉토리 설정 (필요시 경로 수정)\n",
        "DRIVE_BASE = '/content/drive/MyDrive/pill_project'  # 본인의 Drive 폴더로 변경\n",
        "os.makedirs(DRIVE_BASE, exist_ok=True)\n",
        "os.chdir(DRIVE_BASE)\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import shutil\n",
        "import yaml\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import glob\n",
        "import json\n",
        "\n",
        "print(f\"작업 디렉토리: {os.getcwd()}\")\n",
        "\n",
        "# 2. 데이터 경로 확인 (Drive 내) - 수정된 경로\n",
        "train_json_dir = os.path.join(DRIVE_BASE, 'train_annotations')  # data 제거\n",
        "train_image_dir = os.path.join(DRIVE_BASE, 'train_images')      # data 제거\n",
        "\n",
        "print(f\"JSON 디렉토리 존재: {os.path.exists(train_json_dir)}\")\n",
        "print(f\"이미지 디렉토리 존재: {os.path.exists(train_image_dir)}\")\n",
        "\n",
        "# df_complete가 없으면 로드 (Drive에서)\n",
        "if 'df_complete' not in globals():\n",
        "    print(\"df_complete 로드 중...\")\n",
        "    # 간단한 로드 함수\n",
        "    def quick_load_complete_data():\n",
        "        json_files = glob.glob(os.path.join(train_json_dir, '**', '*.json'), recursive=True)\n",
        "        data = []\n",
        "\n",
        "        for json_file in tqdm(json_files, desc=\"JSON 로딩 중\"):\n",
        "            with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                json_data = json.load(f)\n",
        "\n",
        "            if not json_data.get('images') or not json_data.get('annotations'):\n",
        "                continue\n",
        "\n",
        "            image_info = json_data['images'][0]\n",
        "\n",
        "            # 기대 객체 수 계산\n",
        "            prefix_part = image_info['file_name'].split('_')[0]\n",
        "            required_count = len(prefix_part.split('-')[1:])\n",
        "\n",
        "            # 실제 어노테이션 수\n",
        "            actual_count = len(json_data['annotations'])\n",
        "\n",
        "            # 완전한 어노테이션만 선택\n",
        "            if required_count == actual_count:\n",
        "                for anno in json_data['annotations']:\n",
        "                    if 'bbox' in anno and anno['bbox'] and len(anno['bbox']) == 4:\n",
        "                        data.append({\n",
        "                            'file_name': image_info['file_name'],\n",
        "                            'image_path': os.path.join(train_image_dir, image_info['file_name']),\n",
        "                            'width': image_info['width'],\n",
        "                            'height': image_info['height'],\n",
        "                            'dl_name': image_info['dl_name'],\n",
        "                            'category_id': anno['category_id'],\n",
        "                            'bbox': anno['bbox'],\n",
        "                            'has_annotation': True\n",
        "                        })\n",
        "\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    df_complete = quick_load_complete_data()\n",
        "    print(f\"df_complete 로드 완료: {len(df_complete)}개\")\n",
        "\n",
        "# 불완전한 이미지 리스트도 로드 (필요시)\n",
        "if 'incomplete_image_list' not in globals():\n",
        "    # 전체 이미지에서 완전한 이미지 제외\n",
        "    all_images = set([os.path.basename(f) for f in glob.glob(os.path.join(train_image_dir, '*.png'))])\n",
        "    complete_images = set(df_complete['file_name'].unique())\n",
        "    incomplete_image_list = list(all_images - complete_images)\n",
        "    print(f\"불완전한 이미지: {len(incomplete_image_list)}장\")\n",
        "\n",
        "# 3. 클래스 매핑 생성 (완전한 데이터 기준)\n",
        "class_names = sorted(df_complete['dl_name'].unique())\n",
        "name_to_cat_id_map = df_complete.drop_duplicates('dl_name').set_index('dl_name')['category_id'].to_dict()\n",
        "idx_to_class = {i: name for i, name in enumerate(class_names)}\n",
        "yolo_idx_to_original_cat_id = {i: name_to_cat_id_map[name] for i, name in idx_to_class.items()}\n",
        "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "print(f\"클래스 매핑 완료: {len(class_names)}개 클래스\")\n",
        "\n",
        "# 4. YAML 파일 생성 (Drive 내)\n",
        "dataset_info = {\n",
        "    'path': os.path.join(DRIVE_BASE, 'pill_dataset'),\n",
        "    'train': 'train/images',\n",
        "    'val': 'val/images',\n",
        "    'names': idx_to_class\n",
        "}\n",
        "\n",
        "yaml_path = os.path.join(DRIVE_BASE, 'pill_dataset.yaml')\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(dataset_info, f)\n",
        "\n",
        "print(f\"YAML 파일 생성: {yaml_path}\")\n",
        "\n",
        "# 5. 완전한 데이터로 YOLO 데이터셋 생성 (Drive 내)\n",
        "def create_yolo_dataset_from_complete(df_complete, output_dir, class_to_idx):\n",
        "    \"\"\"완전한 어노테이션 데이터로 YOLO 데이터셋 생성\"\"\"\n",
        "    print(f\"YOLO 데이터셋 생성 중: {output_dir}\")\n",
        "\n",
        "    # 디렉토리 생성\n",
        "    os.makedirs(os.path.join(output_dir, 'train', 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'train', 'labels'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'val', 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'val', 'labels'), exist_ok=True)\n",
        "\n",
        "    # 이미지별로 그룹화\n",
        "    unique_images = df_complete['file_name'].unique()\n",
        "    train_images, val_images = train_test_split(unique_images, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_set = set(train_images)\n",
        "    val_set = set(val_images)\n",
        "\n",
        "    # 이미지별로 처리\n",
        "    for file_name in tqdm(unique_images, desc=\"YOLO 데이터셋 생성\"):\n",
        "        # 해당 이미지의 모든 어노테이션 가져오기\n",
        "        img_annotations = df_complete[df_complete['file_name'] == file_name]\n",
        "\n",
        "        # train/val 결정\n",
        "        subset = 'train' if file_name in train_set else 'val'\n",
        "\n",
        "        # 이미지 복사\n",
        "        src_path = img_annotations.iloc[0]['image_path']\n",
        "        dst_path = os.path.join(output_dir, subset, 'images', file_name)\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "\n",
        "        # 라벨 파일 생성\n",
        "        label_path = os.path.join(output_dir, subset, 'labels', os.path.splitext(file_name)[0] + '.txt')\n",
        "\n",
        "        with open(label_path, 'w') as f:\n",
        "            for _, row in img_annotations.iterrows():\n",
        "                class_id = class_to_idx[row['dl_name']]\n",
        "                bbox = row['bbox']\n",
        "\n",
        "                # YOLO 형식으로 변환\n",
        "                x_center = (bbox[0] + bbox[2] / 2) / row['width']\n",
        "                y_center = (bbox[1] + bbox[3] / 2) / row['height']\n",
        "                width = bbox[2] / row['width']\n",
        "                height = bbox[3] / row['height']\n",
        "\n",
        "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    print(f\"학습 이미지: {len(train_images)}장, 검증 이미지: {len(val_images)}장\")\n",
        "\n",
        "# YOLO 데이터셋 생성 (Drive 내)\n",
        "yolo_dataset_dir = os.path.join(DRIVE_BASE, 'pill_dataset')\n",
        "create_yolo_dataset_from_complete(df_complete, yolo_dataset_dir, class_to_idx)\n",
        "\n",
        "# 6. 앙상블 모델 학습 (Drive에 저장) - 절대 경로 수정\n",
        "def train_ensemble_models(yaml_path, base_dir, num_models=3):\n",
        "    \"\"\"서로 다른 설정으로 여러 모델 학습\"\"\"\n",
        "    models = []\n",
        "\n",
        "    print(\"=== 앙상블 모델 학습 시작 ===\")\n",
        "\n",
        "    ensemble_dir = os.path.join(base_dir, 'ensemble_models')\n",
        "\n",
        "    # 모델 1: YOLOv8n (기본)\n",
        "    print(\"모델 1: YOLOv8n 기본 설정 학습 중...\")\n",
        "    model1 = YOLO('yolov8n.pt')\n",
        "    model1.train(\n",
        "        data=yaml_path,\n",
        "        epochs=15,\n",
        "        batch=16,\n",
        "        imgsz=640,\n",
        "        project=ensemble_dir,\n",
        "        name='model1_basic',\n",
        "        verbose=False\n",
        "    )\n",
        "    # 절대 경로로 수정\n",
        "    model1_path = os.path.join(ensemble_dir, 'model1_basic', 'weights', 'best.pt')\n",
        "    models.append((model1_path, 'basic'))\n",
        "\n",
        "    # 모델 2: YOLOv8s (더 큰 모델)\n",
        "    print(\"모델 2: YOLOv8s 학습 중...\")\n",
        "    model2 = YOLO('yolov8s.pt')\n",
        "    model2.train(\n",
        "        data=yaml_path,\n",
        "        epochs=15,\n",
        "        batch=12,\n",
        "        imgsz=640,\n",
        "        project=ensemble_dir,\n",
        "        name='model2_large',\n",
        "        verbose=False\n",
        "    )\n",
        "    model2_path = os.path.join(ensemble_dir, 'model2_large', 'weights', 'best.pt')\n",
        "    models.append((model2_path, 'large'))\n",
        "\n",
        "    # 모델 3: YOLOv8n (강한 증강)\n",
        "    print(\"모델 3: YOLOv8n 강한 증강 학습 중...\")\n",
        "    model3 = YOLO('yolov8n.pt')\n",
        "    model3.train(\n",
        "        data=yaml_path,\n",
        "        epochs=15,\n",
        "        batch=16,\n",
        "        imgsz=640,\n",
        "        hsv_h=0.02,\n",
        "        hsv_s=0.8,\n",
        "        hsv_v=0.5,\n",
        "        degrees=15,\n",
        "        translate=0.15,\n",
        "        scale=0.7,\n",
        "        flipud=0.7,\n",
        "        mosaic=1.0,\n",
        "        mixup=0.3,\n",
        "        project=ensemble_dir,\n",
        "        name='model3_augmented',\n",
        "        verbose=False\n",
        "    )\n",
        "    model3_path = os.path.join(ensemble_dir, 'model3_augmented', 'weights', 'best.pt')\n",
        "    models.append((model3_path, 'augmented'))\n",
        "\n",
        "    return models\n",
        "\n",
        "# 앙상블 모델 학습\n",
        "ensemble_model_paths = train_ensemble_models(yaml_path, DRIVE_BASE)\n",
        "\n",
        "# 7. IoU 계산 함수\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"두 박스 간 IoU 계산 [x1, y1, x2, y2] 형식\"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = (x2 - x1) * (y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - intersection\n",
        "\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "# 8. 앙상블 합의 함수\n",
        "def find_ensemble_agreement(predictions_by_models, iou_threshold=0.5, agreement_threshold=2):\n",
        "    \"\"\"여러 모델의 예측에서 합의된 예측만 추출\"\"\"\n",
        "    if len(predictions_by_models) < agreement_threshold:\n",
        "        return []\n",
        "\n",
        "    # 모든 예측을 하나로 합치기\n",
        "    all_predictions = []\n",
        "    for model_idx, predictions in enumerate(predictions_by_models):\n",
        "        for pred in predictions:\n",
        "            pred['model_id'] = model_idx\n",
        "            all_predictions.append(pred)\n",
        "\n",
        "    if not all_predictions:\n",
        "        return []\n",
        "\n",
        "    agreed_predictions = []\n",
        "    used_indices = set()\n",
        "\n",
        "    # 각 예측에 대해 다른 모델들과의 합의 확인\n",
        "    for i, pred1 in enumerate(all_predictions):\n",
        "        if i in used_indices:\n",
        "            continue\n",
        "\n",
        "        agreements = [pred1]\n",
        "        agreement_models = {pred1['model_id']}\n",
        "        current_used = {i}\n",
        "\n",
        "        # 다른 예측들과 비교\n",
        "        for j, pred2 in enumerate(all_predictions[i+1:], i+1):\n",
        "            if j in used_indices or pred2['model_id'] in agreement_models:\n",
        "                continue\n",
        "\n",
        "            # IoU와 클래스 체크\n",
        "            iou = calculate_iou(pred1['bbox'], pred2['bbox'])\n",
        "            same_class = pred1['class'] == pred2['class']\n",
        "\n",
        "            if iou >= iou_threshold and same_class:\n",
        "                agreements.append(pred2)\n",
        "                agreement_models.add(pred2['model_id'])\n",
        "                current_used.add(j)\n",
        "\n",
        "        # 충분한 합의가 있는지 확인\n",
        "        if len(agreement_models) >= agreement_threshold:\n",
        "            # 평균 예측 계산\n",
        "            avg_bbox = [0, 0, 0, 0]\n",
        "            avg_conf = 0\n",
        "\n",
        "            for pred in agreements:\n",
        "                for k in range(4):\n",
        "                    avg_bbox[k] += pred['bbox'][k]\n",
        "                avg_conf += pred['conf']\n",
        "\n",
        "            num_agreements = len(agreements)\n",
        "            avg_bbox = [coord / num_agreements for coord in avg_bbox]\n",
        "            avg_conf = avg_conf / num_agreements\n",
        "\n",
        "            agreed_predictions.append({\n",
        "                'bbox': avg_bbox,\n",
        "                'class': pred1['class'],\n",
        "                'conf': avg_conf,\n",
        "                'agreement_count': len(agreement_models)\n",
        "            })\n",
        "\n",
        "            used_indices.update(current_used)\n",
        "\n",
        "    return agreed_predictions\n",
        "\n",
        "# 9. 수도 라벨 생성\n",
        "def generate_pseudo_labels_for_incomplete(incomplete_image_list, ensemble_model_paths, train_image_dir, confidence_threshold=0.6):\n",
        "    \"\"\"불완전한 이미지들에 대해 수도 라벨 생성\"\"\"\n",
        "\n",
        "    # 모델들 로드\n",
        "    models = []\n",
        "    for model_path, model_type in ensemble_model_paths:\n",
        "        print(f\"모델 로드 중: {model_path}\")\n",
        "        if os.path.exists(model_path):\n",
        "            models.append(YOLO(model_path))\n",
        "        else:\n",
        "            print(f\"모델 파일이 없습니다: {model_path}\")\n",
        "\n",
        "    if not models:\n",
        "        print(\"로드된 모델이 없습니다!\")\n",
        "        return []\n",
        "\n",
        "    pseudo_labels = []\n",
        "\n",
        "    print(f\"불완전한 {len(incomplete_image_list)}장 이미지에 수도 라벨링 시작...\")\n",
        "\n",
        "    for img_name in tqdm(incomplete_image_list, desc=\"수도 라벨링 중\"):\n",
        "        img_path = os.path.join(train_image_dir, img_name)\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            continue\n",
        "\n",
        "        # 각 모델로 예측\n",
        "        predictions_by_models = []\n",
        "\n",
        "        for model in models:\n",
        "            results = model.predict(img_path, conf=confidence_threshold, verbose=False)\n",
        "            model_predictions = []\n",
        "\n",
        "            for result in results:\n",
        "                if result.boxes is not None:\n",
        "                    boxes = result.boxes\n",
        "                    for box in boxes:\n",
        "                        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                        model_predictions.append({\n",
        "                            'bbox': [x1, y1, x2, y2],\n",
        "                            'class': int(box.cls[0]),\n",
        "                            'conf': box.conf[0].item()\n",
        "                        })\n",
        "\n",
        "            predictions_by_models.append(model_predictions)\n",
        "\n",
        "        # 모델들 간 합의된 예측만 선택\n",
        "        agreed_predictions = find_ensemble_agreement(\n",
        "            predictions_by_models,\n",
        "            iou_threshold=0.5,\n",
        "            agreement_threshold=2\n",
        "        )\n",
        "\n",
        "        # 수도 라벨로 저장\n",
        "        for pred in agreed_predictions:\n",
        "            pseudo_labels.append({\n",
        "                'file_name': img_name,\n",
        "                'image_path': img_path,\n",
        "                'bbox': pred['bbox'],\n",
        "                'class': pred['class'],\n",
        "                'confidence': pred['conf'],\n",
        "                'agreement_count': pred['agreement_count']\n",
        "            })\n",
        "\n",
        "    print(f\"총 {len(pseudo_labels)}개의 수도 라벨이 생성되었습니다.\")\n",
        "    return pseudo_labels\n",
        "\n",
        "# 수도 라벨 생성 실행\n",
        "print(f\"\\n=== 수도 라벨링 시작 ===\")\n",
        "print(f\"대상 이미지: {len(incomplete_image_list)}장\")\n",
        "\n",
        "pseudo_labels = generate_pseudo_labels_for_incomplete(\n",
        "    incomplete_image_list,\n",
        "    ensemble_model_paths,\n",
        "    train_image_dir,\n",
        "    confidence_threshold=0.7\n",
        ")\n",
        "\n",
        "# 10. 결과 분석\n",
        "print(f\"\\n=== 수도 라벨링 결과 ===\")\n",
        "print(f\"수도 라벨 생성된 이미지: {len(set([pl['file_name'] for pl in pseudo_labels]))}장\")\n",
        "print(f\"총 수도 라벨 개수: {len(pseudo_labels)}개\")\n",
        "\n",
        "if pseudo_labels:\n",
        "    # 신뢰도별 분포\n",
        "    confidences = [pl['confidence'] for pl in pseudo_labels]\n",
        "    print(f\"수도 라벨 신뢰도 - 평균: {np.mean(confidences):.3f}, 최소: {np.min(confidences):.3f}, 최대: {np.max(confidences):.3f}\")\n",
        "\n",
        "    # 합의 수준별 분포\n",
        "    agreement_counts = [pl['agreement_count'] for pl in pseudo_labels]\n",
        "    for agreement in sorted(set(agreement_counts)):\n",
        "        count = agreement_counts.count(agreement)\n",
        "        print(f\"  {agreement}개 모델 합의: {count}개 라벨\")\n",
        "\n",
        "# 11. 수도 라벨을 YOLO 형식으로 저장 (Drive 내)\n",
        "def save_pseudo_labels_yolo(pseudo_labels, output_dir):\n",
        "    \"\"\"수도 라벨을 YOLO 형식으로 저장\"\"\"\n",
        "    pseudo_dir = os.path.join(output_dir, 'pseudo')\n",
        "    os.makedirs(os.path.join(pseudo_dir, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(pseudo_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "    # 이미지별로 그룹화\n",
        "    labels_by_image = defaultdict(list)\n",
        "    for label in pseudo_labels:\n",
        "        labels_by_image[label['file_name']].append(label)\n",
        "\n",
        "    for img_name, img_labels in labels_by_image.items():\n",
        "        # 이미지 복사\n",
        "        src_path = img_labels[0]['image_path']\n",
        "        dst_path = os.path.join(pseudo_dir, 'images', img_name)\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "\n",
        "        # 라벨 파일 생성\n",
        "        label_path = os.path.join(pseudo_dir, 'labels', os.path.splitext(img_name)[0] + '.txt')\n",
        "\n",
        "        # 이미지 크기 가져오기\n",
        "        img = cv2.imread(src_path)\n",
        "        img_height, img_width = img.shape[:2]\n",
        "\n",
        "        with open(label_path, 'w') as f:\n",
        "            for label in img_labels:\n",
        "                bbox = label['bbox']  # [x1, y1, x2, y2]\n",
        "                class_id = label['class']\n",
        "\n",
        "                # YOLO 형식으로 변환\n",
        "                x_center = (bbox[0] + bbox[2]) / 2 / img_width\n",
        "                y_center = (bbox[1] + bbox[3]) / 2 / img_height\n",
        "                width = (bbox[2] - bbox[0]) / img_width\n",
        "                height = (bbox[3] - bbox[1]) / img_height\n",
        "\n",
        "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    print(f\"수도 라벨이 {pseudo_dir}에 저장되었습니다.\")\n",
        "\n",
        "if pseudo_labels:\n",
        "    save_pseudo_labels_yolo(pseudo_labels, yolo_dataset_dir)\n",
        "\n",
        "print(f\"\\n=== 최종 결과 ===\")\n",
        "print(f\"완전한 어노테이션 데이터: {len(df_complete)}개\")\n",
        "print(f\"생성된 수도 라벨: {len(pseudo_labels)}개\")\n",
        "print(f\"전체 사용 가능한 데이터: {len(df_complete) + len(pseudo_labels)}개\")\n",
        "print(f\"데이터 증가율: {len(pseudo_labels)/len(df_complete)*100:.1f}%\")\n",
        "print(f\"모든 결과가 Drive에 저장되었습니다: {DRIVE_BASE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 수도 라벨링한 데이터로 학습\n",
        "\n",
        "원래는 데이터가 4,500개 가량 되었는데,\n",
        "\n",
        "용량이 조금 문제가 되어서 원래 데이터 에서 700개 줄이고\n",
        "\n",
        "수도 라벨링으로 생성한 데이터에서 700개 줄여서 총 1,700개를 줄인 2,800개의 데이터로 학습함."
      ],
      "metadata": {
        "id": "N21fEeX168oP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB0F3NS8K8Wd",
        "outputId": "be01d41b-40f7-46ef-ea5b-b204a348cd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 올바른 데이터 축소 (700개씩 줄이기) ===\n",
            "현재 df_complete: 2406개\n",
            "원본 완전한 어노테이션 데이터: 2406개\n",
            "원본 이미지 수: 639장\n",
            "이미지당 평균 객체 수: 3.77개\n",
            "제거할 이미지 수: 185장\n",
            "축소 후 데이터: 1708개 (454장 이미지)\n",
            "실제 줄어든 양: 698개\n",
            "클래스 수: 73개\n",
            "현재 축소된 수도 라벨 이미지: 0장\n",
            "현재 총 수도 라벨 수: 0개\n",
            "현재 데이터(0개)가 목표(1445개)보다 적습니다.\n",
            "모든 데이터를 사용합니다.\n",
            "더 큰 YOLO 데이터셋 생성 중...\n",
            "원본 데이터 분할: Train 363장, Val 91장\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "원본 Train 데이터: 100%|██████████| 363/363 [00:10<00:00, 34.42it/s]\n",
            "원본 Val 데이터: 100%|██████████| 91/91 [00:01<00:00, 61.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "더 큰 데이터셋 생성 완료:\n",
            "  Train: 363장\n",
            "  Val: 91장\n",
            "  총합: 454장\n",
            "YAML 파일 생성: ./pill_dataset_larger.yaml\n",
            "\n",
            "=== 더 큰 데이터셋으로 모델 학습 ===\n",
            "Ultralytics 8.3.201 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./pill_dataset_larger.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=final_larger, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=12, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=larger_models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/larger_models/final_larger, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=73\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    837205  ultralytics.nn.modules.head.Detect           [73, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,096,741 parameters, 3,096,725 gradients, 8.6 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1298.5±889.3 MB/s, size: 1745.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/pill_dataset_larger/train/labels... 363 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 363/363 329.7it/s 1.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/pill_dataset_larger/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 944.5±631.9 MB/s, size: 1749.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pill_dataset_larger/val/labels... 91 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 91/91 317.0it/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/pill_dataset_larger/val/labels.cache\n",
            "Plotting labels to /content/larger_models/final_larger/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00013, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000515625), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/larger_models/final_larger\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/25         0G     0.8824      4.771      1.054         22        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 26.0s\n",
            "                   all         91        343          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/25         0G     0.6094      4.349     0.9365         26        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.7s\n",
            "                   all         91        343     0.0223      0.276     0.0396     0.0371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/25         0G     0.5856      3.974     0.9461         18        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 23.8s\n",
            "                   all         91        343     0.0175      0.719     0.0872     0.0809\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/25         0G     0.5646      3.641     0.9545         25        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.5s\n",
            "                   all         91        343      0.675     0.0705      0.116       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/25         0G     0.5418      3.358     0.9518         24        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 23.6s\n",
            "                   all         91        343      0.683      0.151      0.142      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/25         0G     0.5243      3.098     0.9512         20        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 23.7s\n",
            "                   all         91        343      0.725       0.18      0.194      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/25         0G     0.5149      2.901     0.9558         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 23.9s\n",
            "                   all         91        343      0.779      0.195       0.26      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/25         0G      0.497      2.652     0.9529         24        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.6s\n",
            "                   all         91        343      0.805      0.211      0.321      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/25         0G     0.4937      2.568     0.9501         15        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.4s\n",
            "                   all         91        343      0.764      0.283      0.378      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/25         0G      0.489      2.377     0.9527         16        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.3s\n",
            "                   all         91        343      0.576      0.401      0.459      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/25         0G     0.4826      2.275     0.9524         15        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 25.1s\n",
            "                   all         91        343      0.643      0.448      0.487      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/25         0G     0.4798      2.172     0.9635         20        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.3s\n",
            "                   all         91        343      0.655      0.503      0.544      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/25         0G     0.4752      2.081      0.953         15        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.6s\n",
            "                   all         91        343      0.616      0.507      0.595      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/25         0G       0.47      1.954     0.9575         24        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.5s\n",
            "                   all         91        343      0.603      0.583      0.625      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/25         0G     0.4605      1.892     0.9447         12        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.5s\n",
            "                   all         91        343      0.648      0.566      0.656      0.632\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/25         0G     0.3631      1.762     0.9158         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.4s\n",
            "                   all         91        343      0.567      0.643       0.69      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/25         0G     0.3517      1.782     0.8891         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.5s\n",
            "                   all         91        343      0.574      0.673      0.714      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/25         0G     0.3492      1.653     0.8858         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.3s\n",
            "                   all         91        343      0.576      0.695      0.727      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/25         0G     0.3388      1.547     0.8964         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.3s\n",
            "                   all         91        343      0.566      0.788      0.777      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/25         0G     0.3326      1.558     0.8975         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.9s\n",
            "                   all         91        343      0.581      0.773       0.79      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/25         0G     0.3222      1.478     0.8789         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 23.8s\n",
            "                   all         91        343      0.664      0.754      0.789      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/25         0G     0.3222      1.461     0.8748         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 23.8s\n",
            "                   all         91        343      0.689      0.737      0.797      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/25         0G     0.3153      1.444     0.8747         11        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.4s\n",
            "                   all         91        343      0.711       0.73      0.801      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/25         0G     0.3167      1.412     0.8777         12        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.6s\n",
            "                   all         91        343      0.688      0.752        0.8      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/25         0G     0.3139      1.408     0.8671         12        640: 100% ━━━━━━━━━━━━ 61/61 0.2it/s 5:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 24.3s\n",
            "                   all         91        343      0.691      0.743      0.807      0.786\n",
            "\n",
            "25 epochs completed in 2.374 hours.\n",
            "Optimizer stripped from /content/larger_models/final_larger/weights/last.pt, 6.4MB\n",
            "Optimizer stripped from /content/larger_models/final_larger/weights/best.pt, 6.4MB\n",
            "\n",
            "Validating /content/larger_models/final_larger/weights/best.pt...\n",
            "Ultralytics 8.3.201 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,091,487 parameters, 0 gradients, 8.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.4it/s 22.4s\n",
            "                   all         91        343      0.694      0.742      0.813      0.791\n",
            "           가바토파정 100mg         12         12      0.682          1      0.984      0.964\n",
            "        글리틴정(콜린알포세레이트)          4          4      0.655       0.75      0.849      0.833\n",
            "    기넥신에프정(은행엽엑스)(수출용)         32         32      0.978          1      0.995       0.99\n",
            "         낙소졸정 500/20mg          1          1      0.508          1      0.995      0.995\n",
            "             노바스크정 5mg          5          5      0.857          1      0.995      0.995\n",
            "              놀텍정 10mg          1          1          1          0     0.0153     0.0138\n",
            "          뉴로메드정(옥시라세탐)          4          4      0.508       0.75      0.888      0.874\n",
            "         다보타민큐정 10mg/병          3          3      0.488          1      0.995      0.995\n",
            "         동아가바펜틴정 800mg         12         12      0.857      0.917      0.961      0.916\n",
            "            라비에트정 20mg          3          3      0.332      0.222      0.608      0.608\n",
            "        란스톤엘에프디티정 30mg          3          3      0.805          1      0.995      0.962\n",
            "                  레일라정          4          4      0.727          1      0.845      0.845\n",
            "        로수바미브정 10/20mg          1          1      0.456          1      0.995      0.995\n",
            "          로수젯정10/5밀리그램          4          4      0.861          1      0.995       0.97\n",
            "       리렉스펜정 300mg/PTP          4          4          1          0      0.787      0.762\n",
            "           리리카캡슐 150mg          3          3      0.174      0.116      0.423      0.423\n",
            "              리바로정 4mg         12         12      0.934          1      0.995       0.94\n",
            "            리피로우정 20mg          3          3       0.69      0.333      0.753      0.753\n",
            "             리피토정 20mg          5          5      0.484          1      0.938      0.915\n",
            "                  마도파정          2          2      0.779          1      0.995      0.995\n",
            "         맥시부펜이알정 300mg          1          1      0.135          1      0.995      0.995\n",
            "          메가파워정 90mg/병          3          3          1          0      0.273      0.245\n",
            "     무코스타정(레바미피드)(비매품)          8          8      0.708          1      0.995      0.959\n",
            "           뮤테란캡슐 100mg         14         14      0.937          1      0.995      0.929\n",
            "            보령부스파정 5mg         16         16      0.899          1      0.995      0.914\n",
            "         비모보정 500/20mg          5          5      0.954          1      0.995      0.995\n",
            "         비타비백정 100mg/병          3          3          1          0      0.913      0.872\n",
            "      삐콤씨에프정 618.6mg/병          3          3      0.488          1      0.497      0.497\n",
            "         삼남건조수산화알루미늄겔정          3          3      0.424      0.667      0.608       0.57\n",
            "          세비카정 10/40mg          3          3      0.215          1      0.665      0.665\n",
            "             스토가정 10mg          3          3      0.281      0.653      0.332      0.332\n",
            "                  신바로정          1          1      0.177          1      0.995      0.995\n",
            "     써스펜8시간이알서방정 650mg          3          3          1          0      0.232      0.214\n",
            "            쎄로켈정 100mg          3          3      0.916          1      0.995      0.995\n",
            "         아모잘탄정 5/100mg          8          8      0.895          1      0.995      0.995\n",
            "           아빌리파이정 10mg          2          2          1          0     0.0417     0.0401\n",
            "       아질렉트정(라사길린메실산염)          2          2      0.481        0.5      0.572      0.572\n",
            "            아토르바정 10mg          1          1       0.68          1      0.995      0.995\n",
            "          아토젯정 10/40mg         10         10      0.715          1      0.986      0.963\n",
            "                  알드린정          3          3      0.644          1      0.995       0.94\n",
            "           에스원엠프정 20mg          3          3          1      0.534      0.806      0.806\n",
            "          에어탈정(아세클로페낙)          3          3      0.918          1      0.995      0.995\n",
            "         엑스포지정 5/160mg          4          4      0.785       0.75      0.945      0.885\n",
            "             울트라셋이알서방정          3          3      0.282          1      0.995      0.951\n",
            "           일양하이트린정 2mg         21         21      0.855          1      0.995      0.966\n",
            " 자누메트엑스알서방정 100/1000mg          3          3      0.574          1      0.995      0.995\n",
            "        자누메트정 50/850mg         10         10      0.923          1      0.995      0.995\n",
            "            자누비아정 50mg          5          5      0.465          1      0.995      0.967\n",
            "          자이프렉사정 2.5mg          2          2          1          0     0.0995     0.0995\n",
            "     제미메트서방정 50/1000mg          5          5      0.882          1      0.995      0.995\n",
            "            조인스정 200mg          3          3      0.988          1      0.995      0.995\n",
            "종근당글리아티린연질캡슐(콜린알포세레이트)           1          1      0.144          1      0.995      0.995\n",
            "             카나브정 60mg          4          4      0.568          1      0.995      0.995\n",
            "            카발린캡슐 25mg          3          3          1       0.67      0.995      0.907\n",
            "             케이캡정 50mg          3          3          1          0      0.679      0.646\n",
            "       콜리네이트연질캡슐 400mg          2          2      0.478        0.5      0.497      0.311\n",
            "            쿠에타핀정 25mg          1          1          1          0      0.199      0.179\n",
            "       큐시드정 31.5mg/PTP          8          8      0.782          1      0.995      0.995\n",
            "            크레스토정 20mg          6          6      0.487          1      0.845      0.845\n",
            "타이레놀이알서방정(아세트아미노펜)(수출용)          3          3          1          0      0.426      0.389\n",
            "            타이레놀정500mg          3          3      0.299          1      0.913       0.83\n",
            "     트라젠타듀오정 2.5/850mg          2          2      0.173        0.5      0.548      0.548\n",
            "          트라젠타정(리나글립틴)          7          7      0.631      0.857      0.883      0.883\n",
            "          트루비타정 60mg/병          2          2      0.254          1      0.995      0.895\n",
            "          트윈스타정 40/5mg          8          8      0.757          1      0.995      0.952\n",
            "          펠루비정(펠루비프로펜)          4          4          1          0       0.62      0.589\n",
            "            플라빅스정 75mg         11         11      0.931          1      0.995      0.995\n",
            "Speed: 1.9ms preprocess, 188.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/larger_models/final_larger\u001b[0m\n",
            "\n",
            "=== mAP 측정 ===\n",
            "Ultralytics 8.3.201 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,091,487 parameters, 0 gradients, 8.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2345.8±107.6 MB/s, size: 1763.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pill_dataset_larger/val/labels.cache... 91 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 91/91 87.2Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 23/23 1.0it/s 22.7s\n",
            "                   all         91        343      0.585      0.765      0.745      0.729\n",
            "           가바토파정 100mg         12         12      0.672          1      0.984      0.968\n",
            "        글리틴정(콜린알포세레이트)          4          4      0.633       0.75      0.761      0.761\n",
            "    기넥신에프정(은행엽엑스)(수출용)         32         32          1          1      0.995      0.992\n",
            "         낙소졸정 500/20mg          1          1      0.436          1      0.995      0.995\n",
            "             노바스크정 5mg          5          5          1          1      0.995      0.995\n",
            "              놀텍정 10mg          1          1          0          0          0          0\n",
            "          뉴로메드정(옥시라세탐)          4          4      0.571          1      0.888      0.879\n",
            "         다보타민큐정 10mg/병          3          3        0.5          1      0.995      0.995\n",
            "         동아가바펜틴정 800mg         12         12      0.834      0.917      0.949      0.914\n",
            "            라비에트정 20mg          3          3      0.667      0.667      0.556      0.556\n",
            "        란스톤엘에프디티정 30mg          3          3          1          1      0.995      0.973\n",
            "                  레일라정          4          4        0.8          1      0.845      0.845\n",
            "        로수바미브정 10/20mg          1          1        0.5          1      0.995      0.995\n",
            "          로수젯정10/5밀리그램          4          4          1          1      0.995       0.98\n",
            "       리렉스펜정 300mg/PTP          4          4          1          0      0.625      0.625\n",
            "           리리카캡슐 150mg          3          3          0          0          0          0\n",
            "              리바로정 4mg         12         12      0.926          1      0.995      0.949\n",
            "            리피로우정 20mg          3          3          1      0.333      0.667      0.667\n",
            "             리피토정 20mg          5          5      0.467          1      0.938      0.918\n",
            "                  마도파정          2          2          1          1      0.995      0.995\n",
            "         맥시부펜이알정 300mg          1          1      0.127          1      0.995      0.995\n",
            "          메가파워정 90mg/병          3          3          0          0          0          0\n",
            "     무코스타정(레바미피드)(비매품)          8          8      0.727          1      0.995      0.966\n",
            "           뮤테란캡슐 100mg         14         14      0.934          1      0.995      0.939\n",
            "            보령부스파정 5mg         16         16      0.892          1      0.995      0.925\n",
            "         비모보정 500/20mg          5          5          1          1      0.995      0.995\n",
            "         비타비백정 100mg/병          3          3          0          0          0          0\n",
            "      삐콤씨에프정 618.6mg/병          3          3        0.5          1      0.497      0.497\n",
            "         삼남건조수산화알루미늄겔정          3          3      0.468      0.892      0.608      0.575\n",
            "          세비카정 10/40mg          3          3      0.214          1      0.665      0.665\n",
            "             스토가정 10mg          3          3      0.314      0.922      0.332      0.332\n",
            "                  신바로정          1          1        0.2          1      0.995      0.995\n",
            "     써스펜8시간이알서방정 650mg          3          3          0          0          0          0\n",
            "            쎄로켈정 100mg          3          3          1          1      0.995      0.995\n",
            "         아모잘탄정 5/100mg          8          8       0.89          1      0.995      0.995\n",
            "           아빌리파이정 10mg          2          2          0          0          0          0\n",
            "       아질렉트정(라사길린메실산염)          2          2        0.5        0.5      0.622      0.622\n",
            "            아토르바정 10mg          1          1          1          1      0.995      0.995\n",
            "          아토젯정 10/40mg         10         10      0.692          1      0.986      0.968\n",
            "                  알드린정          3          3      0.616          1      0.995      0.947\n",
            "           에스원엠프정 20mg          3          3          1      0.636      0.732      0.732\n",
            "          에어탈정(아세클로페낙)          3          3       0.75          1      0.995      0.995\n",
            "         엑스포지정 5/160mg          4          4          1       0.75      0.875      0.825\n",
            "             울트라셋이알서방정          3          3      0.268          1      0.995      0.954\n",
            "           일양하이트린정 2mg         21         21      0.846          1      0.995      0.972\n",
            " 자누메트엑스알서방정 100/1000mg          3          3      0.533          1      0.995      0.995\n",
            "        자누메트정 50/850mg         10         10      0.916          1      0.995      0.995\n",
            "            자누비아정 50mg          5          5      0.432          1      0.995       0.97\n",
            "          자이프렉사정 2.5mg          2          2          0          0          0          0\n",
            "     제미메트서방정 50/1000mg          5          5          1          1      0.995      0.995\n",
            "            조인스정 200mg          3          3          1          1      0.995      0.995\n",
            "종근당글리아티린연질캡슐(콜린알포세레이트)           1          1      0.132          1      0.995      0.995\n",
            "             카나브정 60mg          4          4      0.571          1      0.995      0.995\n",
            "            카발린캡슐 25mg          3          3          1      0.946      0.995      0.918\n",
            "             케이캡정 50mg          3          3          0          0          0          0\n",
            "       콜리네이트연질캡슐 400mg          2          2        0.5        0.5      0.375      0.188\n",
            "            쿠에타핀정 25mg          1          1          0          0          0          0\n",
            "       큐시드정 31.5mg/PTP          8          8        0.8          1      0.995      0.995\n",
            "            크레스토정 20mg          6          6      0.473          1      0.845      0.845\n",
            "타이레놀이알서방정(아세트아미노펜)(수출용)          3          3          1          0          0          0\n",
            "            타이레놀정500mg          3          3      0.266          1      0.913      0.832\n",
            "     트라젠타듀오정 2.5/850mg          2          2       0.15        0.5      0.527      0.527\n",
            "          트라젠타정(리나글립틴)          7          7      0.625      0.956      0.883      0.883\n",
            "          트루비타정 60mg/병          2          2      0.251          1      0.995      0.895\n",
            "          트윈스타정 40/5mg          8          8      0.733          1      0.995      0.957\n",
            "          펠루비정(펠루비프로펜)          4          4          0          0          0          0\n",
            "            플라빅스정 75mg         11         11      0.861          1      0.995      0.995\n",
            "Speed: 1.5ms preprocess, 198.7ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "\n",
            "=== 최종 성능 결과 ===\n",
            "mAP@0.5: 0.7448\n",
            "mAP@0.5:0.95: 0.7293\n",
            "Precision: 0.5849\n",
            "Recall: 0.7652\n",
            "\n",
            "=== 데이터셋 요약 ===\n",
            "완전한 어노테이션: 2,406개 → 1708개 (700개 줄임)\n",
            "수도 라벨 데이터: 약 1,445개 사용\n",
            "총 학습 데이터: 약 3153개\n",
            "이전 결과(1,400개): mAP@0.5 = 44.52%\n",
            "현재 결과(3153개): mAP@0.5 = 74.48%\n",
            "성능 향상: +30.0%p\n",
            "\n",
            "완료!\n"
          ]
        }
      ],
      "source": [
        "# 올바른 데이터 축소: 700개씩 줄여서 더 많은 데이터로 학습\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "def clear_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"=== 올바른 데이터 축소 (700개씩 줄이기) ===\")\n",
        "clear_memory()\n",
        "\n",
        "# 1. df_complete에서 700개 줄이기 (2,406 → 1,706개)\n",
        "def reduce_original_by_amount(df_complete, reduce_count=700):\n",
        "    \"\"\"완전한 어노테이션 데이터에서 지정한 개수만큼 줄이기\"\"\"\n",
        "    print(f\"원본 완전한 어노테이션 데이터: {len(df_complete)}개\")\n",
        "\n",
        "    # 이미지별로 그룹화\n",
        "    unique_images = df_complete['file_name'].unique()\n",
        "    print(f\"원본 이미지 수: {len(unique_images)}장\")\n",
        "\n",
        "    # 평균 객체 수 계산\n",
        "    avg_objects_per_image = len(df_complete) / len(unique_images)\n",
        "    print(f\"이미지당 평균 객체 수: {avg_objects_per_image:.2f}개\")\n",
        "\n",
        "    # 줄일 이미지 수 계산\n",
        "    images_to_remove = int(reduce_count / avg_objects_per_image)\n",
        "    print(f\"제거할 이미지 수: {images_to_remove}장\")\n",
        "\n",
        "    # 랜덤하게 이미지 선택해서 제거\n",
        "    random.seed(42)\n",
        "    images_to_keep = random.sample(list(unique_images), len(unique_images) - images_to_remove)\n",
        "\n",
        "    # 선택된 이미지의 모든 어노테이션 유지\n",
        "    df_reduced = df_complete[df_complete['file_name'].isin(images_to_keep)].copy()\n",
        "\n",
        "    print(f\"축소 후 데이터: {len(df_reduced)}개 ({len(images_to_keep)}장 이미지)\")\n",
        "    print(f\"실제 줄어든 양: {len(df_complete) - len(df_reduced)}개\")\n",
        "    return df_reduced\n",
        "\n",
        "# 2. 수도 라벨에서 700개 줄이기 (2,145 → 1,445개)\n",
        "def reduce_pseudo_by_amount(pseudo_reduced_dir, target_final_count=1445):\n",
        "    \"\"\"축소된 수도 라벨에서 더 많이 선택 (현재보다 늘리기)\"\"\"\n",
        "\n",
        "    if not os.path.exists(pseudo_reduced_dir):\n",
        "        print(f\"축소된 수도 라벨 디렉토리가 없습니다: {pseudo_reduced_dir}\")\n",
        "        return []\n",
        "\n",
        "    # 현재 축소된 데이터 확인\n",
        "    pseudo_images = glob.glob(os.path.join(pseudo_reduced_dir, 'images', '*'))\n",
        "    print(f\"현재 축소된 수도 라벨 이미지: {len(pseudo_images)}장\")\n",
        "\n",
        "    # 각 이미지별 라벨 수 계산\n",
        "    image_label_counts = {}\n",
        "    total_labels = 0\n",
        "\n",
        "    for img_path in pseudo_images:\n",
        "        img_name = os.path.basename(img_path)\n",
        "        label_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "        label_path = os.path.join(pseudo_reduced_dir, 'labels', label_name)\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                label_count = len([line for line in f if line.strip()])\n",
        "            image_label_counts[img_name] = label_count\n",
        "            total_labels += label_count\n",
        "\n",
        "    print(f\"현재 총 수도 라벨 수: {total_labels}개\")\n",
        "\n",
        "    if total_labels < target_final_count:\n",
        "        print(f\"현재 데이터({total_labels}개)가 목표({target_final_count}개)보다 적습니다.\")\n",
        "        print(\"모든 데이터를 사용합니다.\")\n",
        "        return list(image_label_counts.keys())\n",
        "\n",
        "    # 랜덤하게 이미지 선택해서 목표 개수에 맞추기\n",
        "    selected_images = []\n",
        "    selected_labels = 0\n",
        "\n",
        "    image_list = list(image_label_counts.keys())\n",
        "    random.shuffle(image_list)\n",
        "\n",
        "    for img_name in image_list:\n",
        "        if selected_labels + image_label_counts[img_name] <= target_final_count:\n",
        "            selected_images.append(img_name)\n",
        "            selected_labels += image_label_counts[img_name]\n",
        "        elif selected_labels < target_final_count:\n",
        "            selected_images.append(img_name)\n",
        "            selected_labels += image_label_counts[img_name]\n",
        "            break\n",
        "\n",
        "    print(f\"선택된 수도 라벨: {len(selected_images)}장 이미지 ({selected_labels}개 라벨)\")\n",
        "    return selected_images\n",
        "\n",
        "# 실행\n",
        "random.seed(42)\n",
        "\n",
        "# df_complete 확인 및 축소\n",
        "if 'df_complete' not in globals():\n",
        "    print(\"df_complete가 없습니다. 세션 복원 코드를 먼저 실행하세요.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"현재 df_complete: {len(df_complete)}개\")\n",
        "df_larger = reduce_original_by_amount(df_complete, 700)\n",
        "\n",
        "# 클래스 매핑 생성\n",
        "class_names = sorted(df_larger['dl_name'].unique())\n",
        "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "idx_to_class = {i: name for i, name in enumerate(class_names)}\n",
        "print(f\"클래스 수: {len(class_names)}개\")\n",
        "\n",
        "# 수도 라벨 선택\n",
        "pseudo_reduced_dir = './pill_dataset/pseudo_reduced'\n",
        "selected_pseudo_images = reduce_pseudo_by_amount(pseudo_reduced_dir, 1445)\n",
        "\n",
        "# 3. 더 큰 YOLO 데이터셋 생성\n",
        "def create_larger_yolo_dataset(df_larger, selected_pseudo_images, pseudo_reduced_dir, output_dir, class_to_idx):\n",
        "    \"\"\"더 많은 데이터로 YOLO 데이터셋 생성\"\"\"\n",
        "\n",
        "    print(\"더 큰 YOLO 데이터셋 생성 중...\")\n",
        "\n",
        "    # 디렉토리 생성\n",
        "    os.makedirs(os.path.join(output_dir, 'train', 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'train', 'labels'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'val', 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'val', 'labels'), exist_ok=True)\n",
        "\n",
        "    # 1) 완전한 어노테이션 데이터 처리\n",
        "    original_images = df_larger['file_name'].unique()\n",
        "    orig_train, orig_val = train_test_split(original_images, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"원본 데이터 분할: Train {len(orig_train)}장, Val {len(orig_val)}장\")\n",
        "\n",
        "    # 원본 train 데이터\n",
        "    for file_name in tqdm(orig_train, desc=\"원본 Train 데이터\"):\n",
        "        img_annotations = df_larger[df_larger['file_name'] == file_name]\n",
        "\n",
        "        # 이미지 복사\n",
        "        src_path = img_annotations.iloc[0]['image_path']\n",
        "        dst_path = os.path.join(output_dir, 'train', 'images', file_name)\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "\n",
        "        # 라벨 파일 생성\n",
        "        label_path = os.path.join(output_dir, 'train', 'labels', os.path.splitext(file_name)[0] + '.txt')\n",
        "        with open(label_path, 'w') as f:\n",
        "            for _, row in img_annotations.iterrows():\n",
        "                class_id = class_to_idx[row['dl_name']]\n",
        "                bbox = row['bbox']\n",
        "\n",
        "                # YOLO 형식으로 변환\n",
        "                x_center = (bbox[0] + bbox[2] / 2) / row['width']\n",
        "                y_center = (bbox[1] + bbox[3] / 2) / row['height']\n",
        "                width = bbox[2] / row['width']\n",
        "                height = bbox[3] / row['height']\n",
        "\n",
        "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    # 원본 val 데이터\n",
        "    for file_name in tqdm(orig_val, desc=\"원본 Val 데이터\"):\n",
        "        img_annotations = df_larger[df_larger['file_name'] == file_name]\n",
        "\n",
        "        # 이미지 복사\n",
        "        src_path = img_annotations.iloc[0]['image_path']\n",
        "        dst_path = os.path.join(output_dir, 'val', 'images', file_name)\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "\n",
        "        # 라벨 파일 생성\n",
        "        label_path = os.path.join(output_dir, 'val', 'labels', os.path.splitext(file_name)[0] + '.txt')\n",
        "        with open(label_path, 'w') as f:\n",
        "            for _, row in img_annotations.iterrows():\n",
        "                class_id = class_to_idx[row['dl_name']]\n",
        "                bbox = row['bbox']\n",
        "\n",
        "                # YOLO 형식으로 변환\n",
        "                x_center = (bbox[0] + bbox[2] / 2) / row['width']\n",
        "                y_center = (bbox[1] + bbox[3] / 2) / row['height']\n",
        "                width = bbox[2] / row['width']\n",
        "                height = bbox[3] / row['height']\n",
        "\n",
        "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    # 2) 수도 라벨 데이터를 train에 추가 (대부분)\n",
        "    if selected_pseudo_images:\n",
        "        pseudo_train, pseudo_val = train_test_split(selected_pseudo_images, test_size=0.1, random_state=42)\n",
        "\n",
        "        print(f\"수도 라벨 분할: Train {len(pseudo_train)}장, Val {len(pseudo_val)}장\")\n",
        "\n",
        "        # 수도 라벨 train 데이터\n",
        "        for img_name in tqdm(pseudo_train, desc=\"수도라벨 Train\"):\n",
        "            # 이미지 복사\n",
        "            src_img = os.path.join(pseudo_reduced_dir, 'images', img_name)\n",
        "            dst_img = os.path.join(output_dir, 'train', 'images', img_name)\n",
        "            if os.path.exists(src_img) and not os.path.exists(dst_img):\n",
        "                shutil.copy2(src_img, dst_img)\n",
        "\n",
        "            # 라벨 복사\n",
        "            label_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "            src_label = os.path.join(pseudo_reduced_dir, 'labels', label_name)\n",
        "            dst_label = os.path.join(output_dir, 'train', 'labels', label_name)\n",
        "            if os.path.exists(src_label) and not os.path.exists(dst_label):\n",
        "                shutil.copy2(src_label, dst_label)\n",
        "\n",
        "        # 수도 라벨 val 데이터\n",
        "        for img_name in tqdm(pseudo_val, desc=\"수도라벨 Val\"):\n",
        "            # 이미지 복사\n",
        "            src_img = os.path.join(pseudo_reduced_dir, 'images', img_name)\n",
        "            dst_img = os.path.join(output_dir, 'val', 'images', img_name)\n",
        "            if os.path.exists(src_img) and not os.path.exists(dst_img):\n",
        "                shutil.copy2(src_img, dst_img)\n",
        "\n",
        "            # 라벨 복사\n",
        "            label_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "            src_label = os.path.join(pseudo_reduced_dir, 'labels', label_name)\n",
        "            dst_label = os.path.join(output_dir, 'val', 'labels', label_name)\n",
        "            if os.path.exists(src_label) and not os.path.exists(dst_label):\n",
        "                shutil.copy2(src_label, dst_label)\n",
        "\n",
        "    # 최종 통계\n",
        "    train_images = len(glob.glob(os.path.join(output_dir, 'train', 'images', '*')))\n",
        "    val_images = len(glob.glob(os.path.join(output_dir, 'val', 'images', '*')))\n",
        "\n",
        "    print(f\"더 큰 데이터셋 생성 완료:\")\n",
        "    print(f\"  Train: {train_images}장\")\n",
        "    print(f\"  Val: {val_images}장\")\n",
        "    print(f\"  총합: {train_images + val_images}장\")\n",
        "\n",
        "# 더 큰 YOLO 데이터셋 생성\n",
        "larger_dataset_dir = './pill_dataset_larger'\n",
        "create_larger_yolo_dataset(df_larger, selected_pseudo_images, pseudo_reduced_dir, larger_dataset_dir, class_to_idx)\n",
        "\n",
        "# YAML 파일 생성\n",
        "dataset_info = {\n",
        "    'path': os.path.abspath(larger_dataset_dir),\n",
        "    'train': 'train/images',\n",
        "    'val': 'val/images',\n",
        "    'names': idx_to_class\n",
        "}\n",
        "\n",
        "yaml_path = './pill_dataset_larger.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(dataset_info, f)\n",
        "\n",
        "print(f\"YAML 파일 생성: {yaml_path}\")\n",
        "clear_memory()\n",
        "\n",
        "# 4. 더 큰 데이터로 모델 학습\n",
        "print(\"\\n=== 더 큰 데이터셋으로 모델 학습 ===\")\n",
        "model = YOLO('yolov8n.pt')\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=25,        # 더 많은 에포크\n",
        "    patience=12,\n",
        "    batch=6,          # CPU를 고려해 조금 작게\n",
        "    imgsz=640,        # 더 높은 해상도\n",
        "    workers=2,\n",
        "    lr0=0.01,         # 학습률 조정\n",
        "    project='larger_models',\n",
        "    name='final_larger',\n",
        "    verbose=True,\n",
        "    save_period=5\n",
        ")\n",
        "\n",
        "# 학습 후 메모리 정리\n",
        "del model\n",
        "clear_memory()\n",
        "\n",
        "# 5. mAP 측정\n",
        "print(\"\\n=== mAP 측정 ===\")\n",
        "trained_model = YOLO('larger_models/final_larger/weights/best.pt')\n",
        "\n",
        "results = trained_model.val(\n",
        "    data=yaml_path,\n",
        "    imgsz=640,\n",
        "    conf=0.25,\n",
        "    iou=0.5,\n",
        "    batch=4,\n",
        "    verbose=True,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "print(\"\\n=== 최종 성능 결과 ===\")\n",
        "print(f\"mAP@0.5: {results.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {results.box.map:.4f}\")\n",
        "print(f\"Precision: {results.box.mp:.4f}\")\n",
        "print(f\"Recall: {results.box.mr:.4f}\")\n",
        "\n",
        "# 데이터셋 요약\n",
        "print(f\"\\n=== 데이터셋 요약 ===\")\n",
        "print(f\"완전한 어노테이션: 2,406개 → {len(df_larger)}개 (700개 줄임)\")\n",
        "print(f\"수도 라벨 데이터: 약 1,445개 사용\")\n",
        "print(f\"총 학습 데이터: 약 {len(df_larger) + 1445}개\")\n",
        "print(f\"이전 결과(1,400개): mAP@0.5 = 44.52%\")\n",
        "print(f\"현재 결과({len(df_larger) + 1445}개): mAP@0.5 = {results.box.map50:.2%}\")\n",
        "\n",
        "improvement = (results.box.map50 - 0.4452) * 100\n",
        "if improvement > 0:\n",
        "    print(f\"성능 향상: +{improvement:.1f}%p\")\n",
        "else:\n",
        "    print(f\"성능 변화: {improvement:.1f}%p\")\n",
        "\n",
        "del trained_model\n",
        "clear_memory()\n",
        "print(\"\\n완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 매핑"
      ],
      "metadata": {
        "id": "FpvwsaQ47pKf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "TVLp13GAcBON",
        "outputId": "0413c16d-a821-4d15-a367-4a5048c7f948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "모델 클래스 개수: 73\n",
            "총 4526개 JSON 파일 검사 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 4262/4526 [00:06<00:00, 621.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "발견된 클래스: 73개\n",
            "\n",
            "최종 매핑: 73개\n",
            "누락된 클래스: 0개\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_025ac469-ca91-4eb8-a609-fd976a18230a\", \"class_mapping.json\", 926)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델의 클래스 개수: 73\n",
            "매핑된 클래스 개수: 73\n",
            "모델 클래스 범위: 0 ~ 72\n",
            "매핑 키 범위: 0 ~ 72\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "import json\n",
        "from ultralytics import YOLO\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 모델 로드\n",
        "model_path = '/content/drive/MyDrive/pill_project/ensemble_models/model2_large/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# 모델의 클래스 이름\n",
        "class_names = model.names\n",
        "print(f\"모델 클래스 개수: {len(class_names)}\")\n",
        "\n",
        "# JSON에서 dl_name -> category_id 매핑 추출 (모든 파일 검사!)\n",
        "json_dir = '/content/drive/MyDrive/pill_project/train_annotations'\n",
        "json_files = glob.glob(json_dir + '/**/*.json', recursive=True)\n",
        "\n",
        "print(f\"총 {len(json_files)}개 JSON 파일 검사 중...\")\n",
        "\n",
        "name_to_cat_id = {}\n",
        "for json_file in tqdm(json_files):  # 모든 파일 검사\n",
        "    try:\n",
        "        with open(json_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        if 'images' in data and data['images']:\n",
        "            img_info = data['images'][0]\n",
        "            if 'dl_name' in img_info and 'annotations' in data and data['annotations']:\n",
        "                name = img_info['dl_name']\n",
        "                cat_id = data['annotations'][0]['category_id']\n",
        "                name_to_cat_id[name] = cat_id\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    # 충분히 모았으면 중단\n",
        "    if len(name_to_cat_id) >= 73:\n",
        "        break\n",
        "\n",
        "print(f\"발견된 클래스: {len(name_to_cat_id)}개\")\n",
        "\n",
        "# YOLO 인덱스 -> category_id 매핑\n",
        "yolo_idx_to_original_cat_id = {i: name_to_cat_id[name] for i, name in class_names.items() if name in name_to_cat_id}\n",
        "\n",
        "print(f\"\\n최종 매핑: {len(yolo_idx_to_original_cat_id)}개\")\n",
        "print(f\"누락된 클래스: {73 - len(yolo_idx_to_original_cat_id)}개\")\n",
        "\n",
        "# 저장\n",
        "with open('class_mapping.json', 'w') as f:\n",
        "    json.dump(yolo_idx_to_original_cat_id, f)\n",
        "\n",
        "files.download('class_mapping.json')\n",
        "\n",
        "# 이 코드로 확인\n",
        "print(f\"모델의 클래스 개수: {len(model.names)}\")\n",
        "print(f\"매핑된 클래스 개수: {len(yolo_idx_to_original_cat_id)}\")\n",
        "print(f\"모델 클래스 범위: 0 ~ {len(model.names)-1}\")\n",
        "print(f\"매핑 키 범위: {min(yolo_idx_to_original_cat_id.keys())} ~ {max(yolo_idx_to_original_cat_id.keys())}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}